; ModuleID = 'Project_CodeNet_C++1400/p02840/s552422795.cpp'
source_filename = "Project_CodeNet_C++1400/p02840/s552422795.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

$_ZSt5__gcdIxET_S0_S0_ = comdat any

$_ZSt3absx = comdat any

$_ZSt3maxIxERKT_S2_S2_ = comdat any

$_ZSt3minIxERKT_S2_S2_ = comdat any

@maeA = global [100001 x i64] zeroinitializer, align 16
@maeB = global [100001 x i64] zeroinitializer, align 16
@.str = private unnamed_addr constant [15 x i8] c"%lld %lld %lld\00", align 1
@.str.1 = private unnamed_addr constant [2 x i8] c"1\00", align 1
@.str.2 = private unnamed_addr constant [5 x i8] c"%lld\00", align 1
@x = common global i32 0
@y = common global i32 0
@x.3 = common global i32 0
@y.4 = common global i32 0
@x.5 = common global i32 0
@y.6 = common global i32 0
@x.7 = common global i32 0
@y.8 = common global i32 0
@x.9 = common global i32 0
@y.10 = common global i32 0

; Function Attrs: noinline norecurse uwtable
define i32 @main() #0 {
  %1 = alloca i64
  %2 = alloca i1
  %3 = alloca i1
  %4 = alloca i1
  %5 = alloca i64
  %6 = alloca i1
  %7 = alloca i1
  %8 = alloca i1
  %9 = alloca i64*
  %10 = alloca i64*
  %11 = alloca i64*
  %12 = alloca i64*
  %13 = alloca i64*
  %14 = alloca i32*
  %15 = alloca i64*
  %16 = alloca i64*
  %17 = alloca i32*
  %18 = alloca i32*
  %19 = alloca i64*
  %20 = alloca i64*
  %21 = alloca i64*
  %22 = alloca i32*
  %23 = alloca i64*
  %24 = alloca i64*
  %25 = alloca i64*
  %26 = alloca i64*
  %27 = alloca i64*
  %28 = alloca i64*
  %29 = alloca i64*
  %30 = alloca i64*
  %31 = alloca i32*
  %32 = alloca i1
  %33 = alloca i1
  %34 = load i32, i32* @x
  %35 = load i32, i32* @y
  %36 = add i32 %34, 1558358507
  %37 = sub i32 %36, 1
  %38 = sub i32 %37, 1558358507
  %39 = sub i32 %34, 1
  %40 = mul i32 %34, %38
  %41 = urem i32 %40, 2
  %42 = icmp eq i32 %41, 0
  store i1 %42, i1* %33
  %43 = icmp slt i32 %35, 10
  store i1 %43, i1* %32
  %44 = alloca i32
  store i32 -2016448157, i32* %44
  %45 = alloca i64
  %46 = alloca i64
  br label %47

; <label>:47:                                     ; preds = %0, %2013
  %48 = load i32, i32* %44
  switch i32 %48, label %49 [
    i32 -2016448157, label %50
    i32 1446528539, label %70
    i32 -32679233, label %117
    i32 1389932950, label %120
    i32 -1185891267, label %125
    i32 1013144226, label %127
    i32 854201233, label %135
    i32 1339328659, label %137
    i32 -482383820, label %153
    i32 708747318, label %184
    i32 1058175580, label %187
    i32 1679300617, label %196
    i32 -2001713038, label %212
    i32 -1681620673, label %231
    i32 1952500359, label %234
    i32 1218903675, label %262
    i32 -229480788, label %299
    i32 1261807819, label %301
    i32 428021496, label %302
    i32 1186553324, label %309
    i32 663806630, label %319
    i32 273408191, label %320
    i32 -846670456, label %337
    i32 -398672915, label %392
    i32 -1617342377, label %393
    i32 548758500, label %401
    i32 1899847412, label %461
    i32 -1672313881, label %488
    i32 1894951131, label %523
    i32 616246701, label %524
    i32 1889360105, label %529
    i32 1145199678, label %546
    i32 807533729, label %562
    i32 -1648684969, label %638
    i32 -1732140573, label %639
    i32 -1706940861, label %647
    i32 -6601509, label %664
    i32 -470506056, label %672
    i32 -2022974862, label %700
    i32 -1463668077, label %742
    i32 -1023245940, label %745
    i32 -2079181266, label %761
    i32 2037851716, label %797
    i32 591756122, label %800
    i32 1546089194, label %815
    i32 1904603543, label %863
    i32 -814989297, label %864
    i32 -746803904, label %874
    i32 -1636866103, label %884
    i32 -1564762492, label %900
    i32 -534144619, label %928
    i32 -2028235373, label %929
    i32 996015168, label %939
    i32 -1450975315, label %967
    i32 1641398664, label %1012
    i32 355951850, label %1013
    i32 943205942, label %1045
    i32 -1802702319, label %1046
    i32 2022825276, label %1074
    i32 -196071927, label %1102
    i32 -1676459113, label %1103
    i32 135338129, label %1131
    i32 -735520934, label %1209
    i32 -1060306491, label %1212
    i32 -716424494, label %1222
    i32 140786374, label %1238
    i32 379333070, label %1253
    i32 -1784720018, label %1254
    i32 1676701250, label %1262
    i32 -1967569987, label %1278
    i32 1660879980, label %1309
    i32 1508763345, label %1310
    i32 1310867849, label %1313
    i32 679813164, label %1340
    i32 -2102939860, label %1344
    i32 616279114, label %1348
    i32 -1171944271, label %1384
    i32 -602671072, label %1477
    i32 -202905386, label %1490
    i32 -497263913, label %1579
    i32 1853524160, label %1639
    i32 521164590, label %1648
    i32 568334053, label %1762
    i32 -987685099, label %1763
    i32 -1748985601, label %1870
    i32 -1184945770, label %1871
    i32 -208846915, label %2007
    i32 -721019237, label %2008
  ]

; <label>:49:                                     ; preds = %47
  br label %2013

; <label>:50:                                     ; preds = %47
  %51 = load volatile i1, i1* %33
  %52 = load volatile i1, i1* %32
  %53 = xor i1 %51, true
  %54 = xor i1 %52, true
  %55 = xor i1 false, true
  %56 = and i1 %53, false
  %57 = and i1 %51, %55
  %58 = and i1 %54, false
  %59 = and i1 %52, %55
  %60 = or i1 %56, %57
  %61 = or i1 %58, %59
  %62 = xor i1 %60, %61
  %63 = or i1 %53, %54
  %64 = xor i1 %63, true
  %65 = or i1 false, %55
  %66 = and i1 %64, %65
  %67 = or i1 %62, %66
  %68 = or i1 %51, %52
  %69 = select i1 %67, i32 1446528539, i32 1310867849
  store i32 %69, i32* %44
  br label %2013

; <label>:70:                                     ; preds = %47
  %71 = alloca i32, align 4
  store i32* %71, i32** %31
  %72 = alloca i64, align 8
  store i64* %72, i64** %30
  %73 = alloca i64, align 8
  store i64* %73, i64** %29
  %74 = alloca i64, align 8
  store i64* %74, i64** %28
  %75 = alloca i64, align 8
  store i64* %75, i64** %27
  %76 = alloca i64, align 8
  store i64* %76, i64** %26
  %77 = alloca i64, align 8
  store i64* %77, i64** %25
  %78 = alloca i64, align 8
  store i64* %78, i64** %24
  %79 = alloca i64, align 8
  store i64* %79, i64** %23
  %80 = alloca i32, align 4
  store i32* %80, i32** %22
  %81 = alloca i64, align 8
  store i64* %81, i64** %21
  %82 = alloca i64, align 8
  store i64* %82, i64** %20
  %83 = alloca i64, align 8
  store i64* %83, i64** %19
  %84 = alloca i32, align 4
  store i32* %84, i32** %18
  %85 = alloca i32, align 4
  store i32* %85, i32** %17
  %86 = alloca i64, align 8
  store i64* %86, i64** %16
  %87 = alloca i64, align 8
  store i64* %87, i64** %15
  %88 = alloca i32, align 4
  store i32* %88, i32** %14
  %89 = alloca i64, align 8
  store i64* %89, i64** %13
  %90 = alloca i64, align 8
  store i64* %90, i64** %12
  %91 = alloca i64, align 8
  store i64* %91, i64** %11
  %92 = alloca i64, align 8
  store i64* %92, i64** %10
  %93 = alloca i64, align 8
  store i64* %93, i64** %9
  %94 = load volatile i32*, i32** %31
  store i32 0, i32* %94, align 4
  %95 = load volatile i64*, i64** %30
  %96 = load volatile i64*, i64** %29
  %97 = load volatile i64*, i64** %28
  %98 = call i32 (i8*, ...) @scanf(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str, i32 0, i32 0), i64* %95, i64* %96, i64* %97)
  %99 = load volatile i64*, i64** %28
  %100 = load i64, i64* %99, align 8
  %101 = icmp eq i64 %100, 0
  store i1 %101, i1* %8
  %102 = load i32, i32* @x
  %103 = load i32, i32* @y
  %104 = add i32 %102, -535741409
  %105 = sub i32 %104, 1
  %106 = sub i32 %105, -535741409
  %107 = sub i32 %102, 1
  %108 = mul i32 %102, %106
  %109 = urem i32 %108, 2
  %110 = icmp eq i32 %109, 0
  %111 = icmp slt i32 %103, 10
  %112 = and i1 %110, %111
  %113 = xor i1 %110, %111
  %114 = or i1 %112, %113
  %115 = or i1 %110, %111
  %116 = select i1 %114, i32 -32679233, i32 1310867849
  store i32 %116, i32* %44
  br label %2013

; <label>:117:                                    ; preds = %47
  %118 = load volatile i1, i1* %8
  %119 = select i1 %118, i32 1389932950, i32 1339328659
  store i32 %119, i32* %44
  br label %2013

; <label>:120:                                    ; preds = %47
  %121 = load volatile i64*, i64** %29
  %122 = load i64, i64* %121, align 8
  %123 = icmp eq i64 %122, 0
  %124 = select i1 %123, i32 -1185891267, i32 1013144226
  store i32 %124, i32* %44
  br label %2013

; <label>:125:                                    ; preds = %47
  %126 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.1, i32 0, i32 0))
  store i32 854201233, i32* %44
  br label %2013

; <label>:127:                                    ; preds = %47
  %128 = load volatile i64*, i64** %30
  %129 = load i64, i64* %128, align 8
  %130 = sub i64 %129, 8281557382079938593
  %131 = add i64 %130, 1
  %132 = add i64 %131, 8281557382079938593
  %133 = add nsw i64 %129, 1
  %134 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i32 0, i32 0), i64 %132)
  store i32 854201233, i32* %44
  br label %2013

; <label>:135:                                    ; preds = %47
  %136 = load volatile i32*, i32** %31
  store i32 0, i32* %136, align 4
  store i32 1508763345, i32* %44
  br label %2013

; <label>:137:                                    ; preds = %47
  %138 = load i32, i32* @x
  %139 = load i32, i32* @y
  %140 = add i32 %138, -224584972
  %141 = sub i32 %140, 1
  %142 = sub i32 %141, -224584972
  %143 = sub i32 %138, 1
  %144 = mul i32 %138, %142
  %145 = urem i32 %144, 2
  %146 = icmp eq i32 %145, 0
  %147 = icmp slt i32 %139, 10
  %148 = and i1 %146, %147
  %149 = xor i1 %146, %147
  %150 = or i1 %148, %149
  %151 = or i1 %146, %147
  %152 = select i1 %150, i32 -482383820, i32 679813164
  store i32 %152, i32* %44
  br label %2013

; <label>:153:                                    ; preds = %47
  %154 = load volatile i64*, i64** %28
  %155 = load i64, i64* %154, align 8
  %156 = icmp slt i64 %155, 0
  store i1 %156, i1* %7
  %157 = load i32, i32* @x
  %158 = load i32, i32* @y
  %159 = add i32 %157, 277845446
  %160 = sub i32 %159, 1
  %161 = sub i32 %160, 277845446
  %162 = sub i32 %157, 1
  %163 = mul i32 %157, %161
  %164 = urem i32 %163, 2
  %165 = icmp eq i32 %164, 0
  %166 = icmp slt i32 %158, 10
  %167 = xor i1 %165, true
  %168 = xor i1 %166, true
  %169 = xor i1 true, true
  %170 = and i1 %167, true
  %171 = and i1 %165, %169
  %172 = and i1 %168, true
  %173 = and i1 %166, %169
  %174 = or i1 %170, %171
  %175 = or i1 %172, %173
  %176 = xor i1 %174, %175
  %177 = or i1 %167, %168
  %178 = xor i1 %177, true
  %179 = or i1 true, %169
  %180 = and i1 %178, %179
  %181 = or i1 %176, %180
  %182 = or i1 %165, %166
  %183 = select i1 %181, i32 708747318, i32 679813164
  store i32 %183, i32* %44
  br label %2013

; <label>:184:                                    ; preds = %47
  %185 = load volatile i1, i1* %7
  %186 = select i1 %185, i32 1058175580, i32 1679300617
  store i32 %186, i32* %44
  br label %2013

; <label>:187:                                    ; preds = %47
  %188 = load volatile i64*, i64** %28
  %189 = load i64, i64* %188, align 8
  %190 = mul nsw i64 %189, -1
  %191 = load volatile i64*, i64** %28
  store i64 %190, i64* %191, align 8
  %192 = load volatile i64*, i64** %29
  %193 = load i64, i64* %192, align 8
  %194 = mul nsw i64 %193, -1
  %195 = load volatile i64*, i64** %29
  store i64 %194, i64* %195, align 8
  store i32 1679300617, i32* %44
  br label %2013

; <label>:196:                                    ; preds = %47
  %197 = load i32, i32* @x
  %198 = load i32, i32* @y
  %199 = add i32 %197, 584449022
  %200 = sub i32 %199, 1
  %201 = sub i32 %200, 584449022
  %202 = sub i32 %197, 1
  %203 = mul i32 %197, %201
  %204 = urem i32 %203, 2
  %205 = icmp eq i32 %204, 0
  %206 = icmp slt i32 %198, 10
  %207 = and i1 %205, %206
  %208 = xor i1 %205, %206
  %209 = or i1 %207, %208
  %210 = or i1 %205, %206
  %211 = select i1 %209, i32 -2001713038, i32 -2102939860
  store i32 %211, i32* %44
  br label %2013

; <label>:212:                                    ; preds = %47
  %213 = load volatile i64*, i64** %29
  %214 = load i64, i64* %213, align 8
  %215 = icmp ne i64 %214, 0
  store i1 %215, i1* %6
  %216 = load i32, i32* @x
  %217 = load i32, i32* @y
  %218 = sub i32 %216, -982916498
  %219 = sub i32 %218, 1
  %220 = add i32 %219, -982916498
  %221 = sub i32 %216, 1
  %222 = mul i32 %216, %220
  %223 = urem i32 %222, 2
  %224 = icmp eq i32 %223, 0
  %225 = icmp slt i32 %217, 10
  %226 = and i1 %224, %225
  %227 = xor i1 %224, %225
  %228 = or i1 %226, %227
  %229 = or i1 %224, %225
  %230 = select i1 %228, i32 -1681620673, i32 -2102939860
  store i32 %230, i32* %44
  br label %2013

; <label>:231:                                    ; preds = %47
  %232 = load volatile i1, i1* %6
  %233 = select i1 %232, i32 1952500359, i32 1261807819
  store i32 %233, i32* %44
  br label %2013

; <label>:234:                                    ; preds = %47
  %235 = load i32, i32* @x
  %236 = load i32, i32* @y
  %237 = add i32 %235, 2137273319
  %238 = sub i32 %237, 1
  %239 = sub i32 %238, 2137273319
  %240 = sub i32 %235, 1
  %241 = mul i32 %235, %239
  %242 = urem i32 %241, 2
  %243 = icmp eq i32 %242, 0
  %244 = icmp slt i32 %236, 10
  %245 = xor i1 %243, true
  %246 = xor i1 %244, true
  %247 = xor i1 false, true
  %248 = and i1 %245, false
  %249 = and i1 %243, %247
  %250 = and i1 %246, false
  %251 = and i1 %244, %247
  %252 = or i1 %248, %249
  %253 = or i1 %250, %251
  %254 = xor i1 %252, %253
  %255 = or i1 %245, %246
  %256 = xor i1 %255, true
  %257 = or i1 false, %247
  %258 = and i1 %256, %257
  %259 = or i1 %254, %258
  %260 = or i1 %243, %244
  %261 = select i1 %259, i32 1218903675, i32 616279114
  store i32 %261, i32* %44
  br label %2013

; <label>:262:                                    ; preds = %47
  %263 = load volatile i64*, i64** %28
  %264 = load i64, i64* %263, align 8
  %265 = load volatile i64*, i64** %29
  %266 = load i64, i64* %265, align 8
  %267 = call i64 @_ZSt3absx(i64 %266)
  %268 = load volatile i64*, i64** %28
  %269 = load i64, i64* %268, align 8
  %270 = call i64 @_ZSt5__gcdIxET_S0_S0_(i64 %267, i64 %269)
  %271 = sdiv i64 %264, %270
  store i64 %271, i64* %5
  %272 = load i32, i32* @x
  %273 = load i32, i32* @y
  %274 = add i32 %272, 1089215280
  %275 = sub i32 %274, 1
  %276 = sub i32 %275, 1089215280
  %277 = sub i32 %272, 1
  %278 = mul i32 %272, %276
  %279 = urem i32 %278, 2
  %280 = icmp eq i32 %279, 0
  %281 = icmp slt i32 %273, 10
  %282 = xor i1 %280, true
  %283 = xor i1 %281, true
  %284 = xor i1 false, true
  %285 = and i1 %282, false
  %286 = and i1 %280, %284
  %287 = and i1 %283, false
  %288 = and i1 %281, %284
  %289 = or i1 %285, %286
  %290 = or i1 %287, %288
  %291 = xor i1 %289, %290
  %292 = or i1 %282, %283
  %293 = xor i1 %292, true
  %294 = or i1 false, %284
  %295 = and i1 %293, %294
  %296 = or i1 %291, %295
  %297 = or i1 %280, %281
  %298 = select i1 %296, i32 -229480788, i32 616279114
  store i32 %298, i32* %44
  br label %2013

; <label>:299:                                    ; preds = %47
  store i32 428021496, i32* %44
  %300 = load volatile i64, i64* %5
  store i64 %300, i64* %45
  br label %2013

; <label>:301:                                    ; preds = %47
  store i32 428021496, i32* %44
  store i64 1, i64* %45
  br label %2013

; <label>:302:                                    ; preds = %47
  %303 = load i64, i64* %45
  %304 = load volatile i64*, i64** %27
  store i64 %303, i64* %304, align 8
  %305 = load volatile i64*, i64** %29
  %306 = load i64, i64* %305, align 8
  %307 = icmp ne i64 %306, 0
  %308 = select i1 %307, i32 1186553324, i32 663806630
  store i32 %308, i32* %44
  br label %2013

; <label>:309:                                    ; preds = %47
  %310 = load volatile i64*, i64** %29
  %311 = load i64, i64* %310, align 8
  %312 = load volatile i64*, i64** %29
  %313 = load i64, i64* %312, align 8
  %314 = call i64 @_ZSt3absx(i64 %313)
  %315 = load volatile i64*, i64** %28
  %316 = load i64, i64* %315, align 8
  %317 = call i64 @_ZSt5__gcdIxET_S0_S0_(i64 %314, i64 %316)
  %318 = sdiv i64 %311, %317
  store i32 273408191, i32* %44
  store i64 %318, i64* %46
  br label %2013

; <label>:319:                                    ; preds = %47
  store i32 273408191, i32* %44
  store i64 0, i64* %46
  br label %2013

; <label>:320:                                    ; preds = %47
  %321 = load i64, i64* %46
  store i64 %321, i64* %1
  %322 = load i32, i32* @x
  %323 = load i32, i32* @y
  %324 = add i32 %322, -888338067
  %325 = sub i32 %324, 1
  %326 = sub i32 %325, -888338067
  %327 = sub i32 %322, 1
  %328 = mul i32 %322, %326
  %329 = urem i32 %328, 2
  %330 = icmp eq i32 %329, 0
  %331 = icmp slt i32 %323, 10
  %332 = and i1 %330, %331
  %333 = xor i1 %330, %331
  %334 = or i1 %332, %333
  %335 = or i1 %330, %331
  %336 = select i1 %334, i32 -846670456, i32 -1171944271
  store i32 %336, i32* %44
  br label %2013

; <label>:337:                                    ; preds = %47
  %338 = load volatile i64*, i64** %26
  %339 = load volatile i64, i64* %1
  store i64 %339, i64* %338, align 8
  %340 = load volatile i64*, i64** %24
  store i64 0, i64* %340, align 8
  %341 = load volatile i64*, i64** %30
  %342 = load i64, i64* %341, align 8
  %343 = sub i64 0, 1
  %344 = sub i64 %342, %343
  %345 = add nsw i64 %342, 1
  %346 = load volatile i64*, i64** %27
  %347 = load i64, i64* %346, align 8
  %348 = sub i64 %344, 6435244157718289593
  %349 = sub i64 %348, %347
  %350 = add i64 %349, 6435244157718289593
  %351 = sub nsw i64 %344, %347
  %352 = load volatile i64*, i64** %23
  store i64 %350, i64* %352, align 8
  %353 = load volatile i64*, i64** %27
  %354 = load volatile i64*, i64** %23
  %355 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %354, i64* dereferenceable(8) %353)
  %356 = load volatile i64*, i64** %24
  %357 = call dereferenceable(8) i64* @_ZSt3maxIxERKT_S2_S2_(i64* dereferenceable(8) %356, i64* dereferenceable(8) %355)
  %358 = load i64, i64* %357, align 8
  %359 = load volatile i64*, i64** %25
  store i64 %358, i64* %359, align 8
  %360 = load volatile i32*, i32** %22
  store i32 0, i32* %360, align 4
  %361 = load volatile i64*, i64** %21
  store i64 0, i64* %361, align 8
  %362 = load volatile i64*, i64** %20
  store i64 0, i64* %362, align 8
  %363 = load volatile i64*, i64** %19
  store i64 0, i64* %363, align 8
  %364 = load volatile i32*, i32** %18
  store i32 0, i32* %364, align 4
  %365 = load i32, i32* @x
  %366 = load i32, i32* @y
  %367 = sub i32 %365, -739298342
  %368 = sub i32 %367, 1
  %369 = add i32 %368, -739298342
  %370 = sub i32 %365, 1
  %371 = mul i32 %365, %369
  %372 = urem i32 %371, 2
  %373 = icmp eq i32 %372, 0
  %374 = icmp slt i32 %366, 10
  %375 = xor i1 %373, true
  %376 = xor i1 %374, true
  %377 = xor i1 false, true
  %378 = and i1 %375, false
  %379 = and i1 %373, %377
  %380 = and i1 %376, false
  %381 = and i1 %374, %377
  %382 = or i1 %378, %379
  %383 = or i1 %380, %381
  %384 = xor i1 %382, %383
  %385 = or i1 %375, %376
  %386 = xor i1 %385, true
  %387 = or i1 false, %377
  %388 = and i1 %386, %387
  %389 = or i1 %384, %388
  %390 = or i1 %373, %374
  %391 = select i1 %389, i32 -398672915, i32 -1171944271
  store i32 %391, i32* %44
  br label %2013

; <label>:392:                                    ; preds = %47
  store i32 -1617342377, i32* %44
  br label %2013

; <label>:393:                                    ; preds = %47
  %394 = load volatile i32*, i32** %18
  %395 = load i32, i32* %394, align 4
  %396 = sext i32 %395 to i64
  %397 = load volatile i64*, i64** %25
  %398 = load i64, i64* %397, align 8
  %399 = icmp slt i64 %396, %398
  %400 = select i1 %399, i32 548758500, i32 616246701
  store i32 %400, i32* %44
  br label %2013

; <label>:401:                                    ; preds = %47
  %402 = load volatile i64*, i64** %21
  %403 = load i64, i64* %402, align 8
  %404 = load volatile i32*, i32** %18
  %405 = load i32, i32* %404, align 4
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %406
  store i64 %403, i64* %407, align 8
  %408 = load volatile i64*, i64** %20
  %409 = load i64, i64* %408, align 8
  %410 = load volatile i32*, i32** %18
  %411 = load i32, i32* %410, align 4
  %412 = sext i32 %411 to i64
  %413 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %412
  store i64 %409, i64* %413, align 8
  %414 = load volatile i64*, i64** %20
  %415 = load i64, i64* %414, align 8
  %416 = load volatile i64*, i64** %21
  %417 = load i64, i64* %416, align 8
  %418 = add i64 %415, -4890832468521159943
  %419 = sub i64 %418, %417
  %420 = sub i64 %419, -4890832468521159943
  %421 = sub nsw i64 %415, %417
  %422 = sub i64 0, %420
  %423 = sub i64 0, 1
  %424 = add i64 %422, %423
  %425 = sub i64 0, %424
  %426 = add nsw i64 %420, 1
  %427 = load volatile i64*, i64** %19
  %428 = load i64, i64* %427, align 8
  %429 = sub i64 0, %425
  %430 = sub i64 %428, %429
  %431 = add nsw i64 %428, %425
  %432 = load volatile i64*, i64** %19
  store i64 %430, i64* %432, align 8
  %433 = load volatile i32*, i32** %18
  %434 = load i32, i32* %433, align 4
  %435 = sext i32 %434 to i64
  %436 = load volatile i64*, i64** %21
  %437 = load i64, i64* %436, align 8
  %438 = sub i64 0, %435
  %439 = sub i64 %437, %438
  %440 = add nsw i64 %437, %435
  %441 = load volatile i64*, i64** %21
  store i64 %439, i64* %441, align 8
  %442 = load volatile i64*, i64** %30
  %443 = load i64, i64* %442, align 8
  %444 = load volatile i32*, i32** %18
  %445 = load i32, i32* %444, align 4
  %446 = sext i32 %445 to i64
  %447 = sub i64 0, %446
  %448 = add i64 %443, %447
  %449 = sub nsw i64 %443, %446
  %450 = sub i64 0, 1
  %451 = add i64 %448, %450
  %452 = sub nsw i64 %448, 1
  %453 = load volatile i64*, i64** %20
  %454 = load i64, i64* %453, align 8
  %455 = sub i64 0, %454
  %456 = sub i64 0, %451
  %457 = add i64 %455, %456
  %458 = sub i64 0, %457
  %459 = add nsw i64 %454, %451
  %460 = load volatile i64*, i64** %20
  store i64 %458, i64* %460, align 8
  store i32 1899847412, i32* %44
  br label %2013

; <label>:461:                                    ; preds = %47
  %462 = load i32, i32* @x
  %463 = load i32, i32* @y
  %464 = sub i32 0, 1
  %465 = add i32 %462, %464
  %466 = sub i32 %462, 1
  %467 = mul i32 %462, %465
  %468 = urem i32 %467, 2
  %469 = icmp eq i32 %468, 0
  %470 = icmp slt i32 %463, 10
  %471 = xor i1 %469, true
  %472 = xor i1 %470, true
  %473 = xor i1 false, true
  %474 = and i1 %471, false
  %475 = and i1 %469, %473
  %476 = and i1 %472, false
  %477 = and i1 %470, %473
  %478 = or i1 %474, %475
  %479 = or i1 %476, %477
  %480 = xor i1 %478, %479
  %481 = or i1 %471, %472
  %482 = xor i1 %481, true
  %483 = or i1 false, %473
  %484 = and i1 %482, %483
  %485 = or i1 %480, %484
  %486 = or i1 %469, %470
  %487 = select i1 %485, i32 -1672313881, i32 -602671072
  store i32 %487, i32* %44
  br label %2013

; <label>:488:                                    ; preds = %47
  %489 = load volatile i32*, i32** %18
  %490 = load i32, i32* %489, align 4
  %491 = sub i32 0, %490
  %492 = sub i32 0, 1
  %493 = add i32 %491, %492
  %494 = sub i32 0, %493
  %495 = add nsw i32 %490, 1
  %496 = load volatile i32*, i32** %18
  store i32 %494, i32* %496, align 4
  %497 = load i32, i32* @x
  %498 = load i32, i32* @y
  %499 = sub i32 0, 1
  %500 = add i32 %497, %499
  %501 = sub i32 %497, 1
  %502 = mul i32 %497, %500
  %503 = urem i32 %502, 2
  %504 = icmp eq i32 %503, 0
  %505 = icmp slt i32 %498, 10
  %506 = xor i1 %504, true
  %507 = xor i1 %505, true
  %508 = xor i1 false, true
  %509 = and i1 %506, false
  %510 = and i1 %504, %508
  %511 = and i1 %507, false
  %512 = and i1 %505, %508
  %513 = or i1 %509, %510
  %514 = or i1 %511, %512
  %515 = xor i1 %513, %514
  %516 = or i1 %506, %507
  %517 = xor i1 %516, true
  %518 = or i1 false, %508
  %519 = and i1 %517, %518
  %520 = or i1 %515, %519
  %521 = or i1 %504, %505
  %522 = select i1 %520, i32 1894951131, i32 -602671072
  store i32 %522, i32* %44
  br label %2013

; <label>:523:                                    ; preds = %47
  store i32 -1617342377, i32* %44
  br label %2013

; <label>:524:                                    ; preds = %47
  %525 = load volatile i64*, i64** %25
  %526 = load i64, i64* %525, align 8
  %527 = trunc i64 %526 to i32
  %528 = load volatile i32*, i32** %17
  store i32 %527, i32* %528, align 4
  store i32 1889360105, i32* %44
  br label %2013

; <label>:529:                                    ; preds = %47
  %530 = load volatile i32*, i32** %17
  %531 = load i32, i32* %530, align 4
  %532 = sext i32 %531 to i64
  %533 = load volatile i64*, i64** %30
  %534 = load i64, i64* %533, align 8
  %535 = add i64 %534, -305606708887429090
  %536 = add i64 %535, 1
  %537 = sub i64 %536, -305606708887429090
  %538 = add nsw i64 %534, 1
  %539 = load volatile i64*, i64** %16
  store i64 %537, i64* %539, align 8
  %540 = load volatile i64*, i64** %27
  %541 = load volatile i64*, i64** %16
  %542 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %541, i64* dereferenceable(8) %540)
  %543 = load i64, i64* %542, align 8
  %544 = icmp slt i64 %532, %543
  %545 = select i1 %544, i32 1145199678, i32 -1706940861
  store i32 %545, i32* %44
  br label %2013

; <label>:546:                                    ; preds = %47
  %547 = load i32, i32* @x
  %548 = load i32, i32* @y
  %549 = add i32 %547, 453317108
  %550 = sub i32 %549, 1
  %551 = sub i32 %550, 453317108
  %552 = sub i32 %547, 1
  %553 = mul i32 %547, %551
  %554 = urem i32 %553, 2
  %555 = icmp eq i32 %554, 0
  %556 = icmp slt i32 %548, 10
  %557 = and i1 %555, %556
  %558 = xor i1 %555, %556
  %559 = or i1 %557, %558
  %560 = or i1 %555, %556
  %561 = select i1 %559, i32 807533729, i32 -202905386
  store i32 %561, i32* %44
  br label %2013

; <label>:562:                                    ; preds = %47
  %563 = load volatile i64*, i64** %20
  %564 = load i64, i64* %563, align 8
  %565 = load volatile i64*, i64** %21
  %566 = load i64, i64* %565, align 8
  %567 = add i64 %564, -1242588409145725060
  %568 = sub i64 %567, %566
  %569 = sub i64 %568, -1242588409145725060
  %570 = sub nsw i64 %564, %566
  %571 = sub i64 0, 1
  %572 = sub i64 %569, %571
  %573 = add nsw i64 %569, 1
  %574 = load volatile i64*, i64** %19
  %575 = load i64, i64* %574, align 8
  %576 = sub i64 %575, -802333513316816095
  %577 = add i64 %576, %572
  %578 = add i64 %577, -802333513316816095
  %579 = add nsw i64 %575, %572
  %580 = load volatile i64*, i64** %19
  store i64 %578, i64* %580, align 8
  %581 = load volatile i32*, i32** %17
  %582 = load i32, i32* %581, align 4
  %583 = sext i32 %582 to i64
  %584 = load volatile i64*, i64** %21
  %585 = load i64, i64* %584, align 8
  %586 = sub i64 0, %585
  %587 = sub i64 0, %583
  %588 = add i64 %586, %587
  %589 = sub i64 0, %588
  %590 = add nsw i64 %585, %583
  %591 = load volatile i64*, i64** %21
  store i64 %589, i64* %591, align 8
  %592 = load volatile i64*, i64** %30
  %593 = load i64, i64* %592, align 8
  %594 = load volatile i32*, i32** %17
  %595 = load i32, i32* %594, align 4
  %596 = sext i32 %595 to i64
  %597 = add i64 %593, 4972664693164714813
  %598 = sub i64 %597, %596
  %599 = sub i64 %598, 4972664693164714813
  %600 = sub nsw i64 %593, %596
  %601 = sub i64 0, 1
  %602 = add i64 %599, %601
  %603 = sub nsw i64 %599, 1
  %604 = load volatile i64*, i64** %20
  %605 = load i64, i64* %604, align 8
  %606 = add i64 %605, 6213613682255738751
  %607 = add i64 %606, %602
  %608 = sub i64 %607, 6213613682255738751
  %609 = add nsw i64 %605, %602
  %610 = load volatile i64*, i64** %20
  store i64 %608, i64* %610, align 8
  %611 = load i32, i32* @x
  %612 = load i32, i32* @y
  %613 = sub i32 %611, -578018491
  %614 = sub i32 %613, 1
  %615 = add i32 %614, -578018491
  %616 = sub i32 %611, 1
  %617 = mul i32 %611, %615
  %618 = urem i32 %617, 2
  %619 = icmp eq i32 %618, 0
  %620 = icmp slt i32 %612, 10
  %621 = xor i1 %619, true
  %622 = xor i1 %620, true
  %623 = xor i1 true, true
  %624 = and i1 %621, true
  %625 = and i1 %619, %623
  %626 = and i1 %622, true
  %627 = and i1 %620, %623
  %628 = or i1 %624, %625
  %629 = or i1 %626, %627
  %630 = xor i1 %628, %629
  %631 = or i1 %621, %622
  %632 = xor i1 %631, true
  %633 = or i1 true, %623
  %634 = and i1 %632, %633
  %635 = or i1 %630, %634
  %636 = or i1 %619, %620
  %637 = select i1 %635, i32 -1648684969, i32 -202905386
  store i32 %637, i32* %44
  br label %2013

; <label>:638:                                    ; preds = %47
  store i32 -1732140573, i32* %44
  br label %2013

; <label>:639:                                    ; preds = %47
  %640 = load volatile i32*, i32** %17
  %641 = load i32, i32* %640, align 4
  %642 = sub i32 %641, -153792710
  %643 = add i32 %642, 1
  %644 = add i32 %643, -153792710
  %645 = add nsw i32 %641, 1
  %646 = load volatile i32*, i32** %17
  store i32 %644, i32* %646, align 4
  store i32 1889360105, i32* %44
  br label %2013

; <label>:647:                                    ; preds = %47
  %648 = load volatile i64*, i64** %26
  %649 = load i64, i64* %648, align 8
  %650 = load volatile i64*, i64** %15
  store i64 %649, i64* %650, align 8
  %651 = load volatile i64*, i64** %30
  %652 = load i64, i64* %651, align 8
  %653 = sub i64 %652, -3158700884194725169
  %654 = add i64 %653, 1
  %655 = add i64 %654, -3158700884194725169
  %656 = add nsw i64 %652, 1
  %657 = load volatile i64*, i64** %13
  store i64 %655, i64* %657, align 8
  %658 = load volatile i64*, i64** %27
  %659 = load volatile i64*, i64** %13
  %660 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %659, i64* dereferenceable(8) %658)
  %661 = load i64, i64* %660, align 8
  %662 = trunc i64 %661 to i32
  %663 = load volatile i32*, i32** %14
  store i32 %662, i32* %663, align 4
  store i32 -6601509, i32* %44
  br label %2013

; <label>:664:                                    ; preds = %47
  %665 = load volatile i32*, i32** %14
  %666 = load i32, i32* %665, align 4
  %667 = sext i32 %666 to i64
  %668 = load volatile i64*, i64** %30
  %669 = load i64, i64* %668, align 8
  %670 = icmp sle i64 %667, %669
  %671 = select i1 %670, i32 -470506056, i32 1676701250
  store i32 %671, i32* %44
  br label %2013

; <label>:672:                                    ; preds = %47
  %673 = load i32, i32* @x
  %674 = load i32, i32* @y
  %675 = add i32 %673, -1394615394
  %676 = sub i32 %675, 1
  %677 = sub i32 %676, -1394615394
  %678 = sub i32 %673, 1
  %679 = mul i32 %673, %677
  %680 = urem i32 %679, 2
  %681 = icmp eq i32 %680, 0
  %682 = icmp slt i32 %674, 10
  %683 = xor i1 %681, true
  %684 = xor i1 %682, true
  %685 = xor i1 false, true
  %686 = and i1 %683, false
  %687 = and i1 %681, %685
  %688 = and i1 %684, false
  %689 = and i1 %682, %685
  %690 = or i1 %686, %687
  %691 = or i1 %688, %689
  %692 = xor i1 %690, %691
  %693 = or i1 %683, %684
  %694 = xor i1 %693, true
  %695 = or i1 false, %685
  %696 = and i1 %694, %695
  %697 = or i1 %692, %696
  %698 = or i1 %681, %682
  %699 = select i1 %697, i32 -2022974862, i32 -497263913
  store i32 %699, i32* %44
  br label %2013

; <label>:700:                                    ; preds = %47
  %701 = load volatile i64*, i64** %21
  %702 = load i64, i64* %701, align 8
  %703 = load volatile i64*, i64** %15
  %704 = load i64, i64* %703, align 8
  %705 = sub i64 0, %704
  %706 = sub i64 %702, %705
  %707 = add nsw i64 %702, %704
  %708 = load volatile i64*, i64** %12
  store i64 %706, i64* %708, align 8
  %709 = load volatile i64*, i64** %20
  %710 = load i64, i64* %709, align 8
  %711 = load volatile i64*, i64** %15
  %712 = load i64, i64* %711, align 8
  %713 = sub i64 0, %710
  %714 = sub i64 0, %712
  %715 = add i64 %713, %714
  %716 = sub i64 0, %715
  %717 = add nsw i64 %710, %712
  %718 = load volatile i64*, i64** %11
  store i64 %716, i64* %718, align 8
  %719 = load volatile i32*, i32** %22
  %720 = load i32, i32* %719, align 4
  %721 = sext i32 %720 to i64
  %722 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %721
  %723 = load i64, i64* %722, align 8
  %724 = load volatile i64*, i64** %12
  %725 = load i64, i64* %724, align 8
  %726 = icmp sge i64 %723, %725
  store i1 %726, i1* %4
  %727 = load i32, i32* @x
  %728 = load i32, i32* @y
  %729 = add i32 %727, -33764604
  %730 = sub i32 %729, 1
  %731 = sub i32 %730, -33764604
  %732 = sub i32 %727, 1
  %733 = mul i32 %727, %731
  %734 = urem i32 %733, 2
  %735 = icmp eq i32 %734, 0
  %736 = icmp slt i32 %728, 10
  %737 = and i1 %735, %736
  %738 = xor i1 %735, %736
  %739 = or i1 %737, %738
  %740 = or i1 %735, %736
  %741 = select i1 %739, i32 -1463668077, i32 -497263913
  store i32 %741, i32* %44
  br label %2013

; <label>:742:                                    ; preds = %47
  %743 = load volatile i1, i1* %4
  %744 = select i1 %743, i32 -1023245940, i32 -814989297
  store i32 %744, i32* %44
  br label %2013

; <label>:745:                                    ; preds = %47
  %746 = load i32, i32* @x
  %747 = load i32, i32* @y
  %748 = sub i32 %746, -815686155
  %749 = sub i32 %748, 1
  %750 = add i32 %749, -815686155
  %751 = sub i32 %746, 1
  %752 = mul i32 %746, %750
  %753 = urem i32 %752, 2
  %754 = icmp eq i32 %753, 0
  %755 = icmp slt i32 %747, 10
  %756 = and i1 %754, %755
  %757 = xor i1 %754, %755
  %758 = or i1 %756, %757
  %759 = or i1 %754, %755
  %760 = select i1 %758, i32 -2079181266, i32 1853524160
  store i32 %760, i32* %44
  br label %2013

; <label>:761:                                    ; preds = %47
  %762 = load volatile i32*, i32** %22
  %763 = load i32, i32* %762, align 4
  %764 = sext i32 %763 to i64
  %765 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %764
  %766 = load i64, i64* %765, align 8
  %767 = load volatile i64*, i64** %11
  %768 = load i64, i64* %767, align 8
  %769 = icmp sle i64 %766, %768
  store i1 %769, i1* %3
  %770 = load i32, i32* @x
  %771 = load i32, i32* @y
  %772 = sub i32 %770, -1002266417
  %773 = sub i32 %772, 1
  %774 = add i32 %773, -1002266417
  %775 = sub i32 %770, 1
  %776 = mul i32 %770, %774
  %777 = urem i32 %776, 2
  %778 = icmp eq i32 %777, 0
  %779 = icmp slt i32 %771, 10
  %780 = xor i1 %778, true
  %781 = xor i1 %779, true
  %782 = xor i1 false, true
  %783 = and i1 %780, false
  %784 = and i1 %778, %782
  %785 = and i1 %781, false
  %786 = and i1 %779, %782
  %787 = or i1 %783, %784
  %788 = or i1 %785, %786
  %789 = xor i1 %787, %788
  %790 = or i1 %780, %781
  %791 = xor i1 %790, true
  %792 = or i1 false, %782
  %793 = and i1 %791, %792
  %794 = or i1 %789, %793
  %795 = or i1 %778, %779
  %796 = select i1 %794, i32 2037851716, i32 1853524160
  store i32 %796, i32* %44
  br label %2013

; <label>:797:                                    ; preds = %47
  %798 = load volatile i1, i1* %3
  %799 = select i1 %798, i32 591756122, i32 -814989297
  store i32 %799, i32* %44
  br label %2013

; <label>:800:                                    ; preds = %47
  %801 = load i32, i32* @x
  %802 = load i32, i32* @y
  %803 = sub i32 0, 1
  %804 = add i32 %801, %803
  %805 = sub i32 %801, 1
  %806 = mul i32 %801, %804
  %807 = urem i32 %806, 2
  %808 = icmp eq i32 %807, 0
  %809 = icmp slt i32 %802, 10
  %810 = and i1 %808, %809
  %811 = xor i1 %808, %809
  %812 = or i1 %810, %811
  %813 = or i1 %808, %809
  %814 = select i1 %812, i32 1546089194, i32 521164590
  store i32 %814, i32* %44
  br label %2013

; <label>:815:                                    ; preds = %47
  %816 = load volatile i64*, i64** %11
  %817 = load i64, i64* %816, align 8
  %818 = load volatile i32*, i32** %22
  %819 = load i32, i32* %818, align 4
  %820 = sext i32 %819 to i64
  %821 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %820
  %822 = load i64, i64* %821, align 8
  %823 = sub i64 %817, -1934040143880232353
  %824 = add i64 %823, %822
  %825 = add i64 %824, -1934040143880232353
  %826 = add nsw i64 %817, %822
  %827 = load volatile i64*, i64** %12
  %828 = load i64, i64* %827, align 8
  %829 = sub i64 0, %828
  %830 = add i64 %825, %829
  %831 = sub nsw i64 %825, %828
  %832 = load volatile i32*, i32** %22
  %833 = load i32, i32* %832, align 4
  %834 = sext i32 %833 to i64
  %835 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %834
  %836 = load i64, i64* %835, align 8
  %837 = sub i64 %830, -7318364574308228568
  %838 = sub i64 %837, %836
  %839 = add i64 %838, -7318364574308228568
  %840 = sub nsw i64 %830, %836
  %841 = load volatile i64*, i64** %19
  %842 = load i64, i64* %841, align 8
  %843 = add i64 %842, 8164805996730495070
  %844 = add i64 %843, %839
  %845 = sub i64 %844, 8164805996730495070
  %846 = add nsw i64 %842, %839
  %847 = load volatile i64*, i64** %19
  store i64 %845, i64* %847, align 8
  %848 = load i32, i32* @x
  %849 = load i32, i32* @y
  %850 = add i32 %848, -1833547731
  %851 = sub i32 %850, 1
  %852 = sub i32 %851, -1833547731
  %853 = sub i32 %848, 1
  %854 = mul i32 %848, %852
  %855 = urem i32 %854, 2
  %856 = icmp eq i32 %855, 0
  %857 = icmp slt i32 %849, 10
  %858 = and i1 %856, %857
  %859 = xor i1 %856, %857
  %860 = or i1 %858, %859
  %861 = or i1 %856, %857
  %862 = select i1 %860, i32 1904603543, i32 521164590
  store i32 %862, i32* %44
  br label %2013

; <label>:863:                                    ; preds = %47
  store i32 -1676459113, i32* %44
  br label %2013

; <label>:864:                                    ; preds = %47
  %865 = load volatile i32*, i32** %22
  %866 = load i32, i32* %865, align 4
  %867 = sext i32 %866 to i64
  %868 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %867
  %869 = load i64, i64* %868, align 8
  %870 = load volatile i64*, i64** %12
  %871 = load i64, i64* %870, align 8
  %872 = icmp sle i64 %869, %871
  %873 = select i1 %872, i32 -746803904, i32 -2028235373
  store i32 %873, i32* %44
  br label %2013

; <label>:874:                                    ; preds = %47
  %875 = load volatile i32*, i32** %22
  %876 = load i32, i32* %875, align 4
  %877 = sext i32 %876 to i64
  %878 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %877
  %879 = load i64, i64* %878, align 8
  %880 = load volatile i64*, i64** %11
  %881 = load i64, i64* %880, align 8
  %882 = icmp sge i64 %879, %881
  %883 = select i1 %882, i32 -1636866103, i32 -2028235373
  store i32 %883, i32* %44
  br label %2013

; <label>:884:                                    ; preds = %47
  %885 = load i32, i32* @x
  %886 = load i32, i32* @y
  %887 = add i32 %885, 1161506234
  %888 = sub i32 %887, 1
  %889 = sub i32 %888, 1161506234
  %890 = sub i32 %885, 1
  %891 = mul i32 %885, %889
  %892 = urem i32 %891, 2
  %893 = icmp eq i32 %892, 0
  %894 = icmp slt i32 %886, 10
  %895 = and i1 %893, %894
  %896 = xor i1 %893, %894
  %897 = or i1 %895, %896
  %898 = or i1 %893, %894
  %899 = select i1 %897, i32 -1564762492, i32 568334053
  store i32 %899, i32* %44
  br label %2013

; <label>:900:                                    ; preds = %47
  %901 = load i32, i32* @x
  %902 = load i32, i32* @y
  %903 = sub i32 %901, 2020724029
  %904 = sub i32 %903, 1
  %905 = add i32 %904, 2020724029
  %906 = sub i32 %901, 1
  %907 = mul i32 %901, %905
  %908 = urem i32 %907, 2
  %909 = icmp eq i32 %908, 0
  %910 = icmp slt i32 %902, 10
  %911 = xor i1 %909, true
  %912 = xor i1 %910, true
  %913 = xor i1 false, true
  %914 = and i1 %911, false
  %915 = and i1 %909, %913
  %916 = and i1 %912, false
  %917 = and i1 %910, %913
  %918 = or i1 %914, %915
  %919 = or i1 %916, %917
  %920 = xor i1 %918, %919
  %921 = or i1 %911, %912
  %922 = xor i1 %921, true
  %923 = or i1 false, %913
  %924 = and i1 %922, %923
  %925 = or i1 %920, %924
  %926 = or i1 %909, %910
  %927 = select i1 %925, i32 -534144619, i32 568334053
  store i32 %927, i32* %44
  br label %2013

; <label>:928:                                    ; preds = %47
  store i32 1676701250, i32* %44
  br label %2013

; <label>:929:                                    ; preds = %47
  %930 = load volatile i32*, i32** %22
  %931 = load i32, i32* %930, align 4
  %932 = sext i32 %931 to i64
  %933 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %932
  %934 = load i64, i64* %933, align 8
  %935 = load volatile i64*, i64** %12
  %936 = load i64, i64* %935, align 8
  %937 = icmp sle i64 %934, %936
  %938 = select i1 %937, i32 996015168, i32 355951850
  store i32 %938, i32* %44
  br label %2013

; <label>:939:                                    ; preds = %47
  %940 = load i32, i32* @x
  %941 = load i32, i32* @y
  %942 = add i32 %940, 1649735316
  %943 = sub i32 %942, 1
  %944 = sub i32 %943, 1649735316
  %945 = sub i32 %940, 1
  %946 = mul i32 %940, %944
  %947 = urem i32 %946, 2
  %948 = icmp eq i32 %947, 0
  %949 = icmp slt i32 %941, 10
  %950 = xor i1 %948, true
  %951 = xor i1 %949, true
  %952 = xor i1 false, true
  %953 = and i1 %950, false
  %954 = and i1 %948, %952
  %955 = and i1 %951, false
  %956 = and i1 %949, %952
  %957 = or i1 %953, %954
  %958 = or i1 %955, %956
  %959 = xor i1 %957, %958
  %960 = or i1 %950, %951
  %961 = xor i1 %960, true
  %962 = or i1 false, %952
  %963 = and i1 %961, %962
  %964 = or i1 %959, %963
  %965 = or i1 %948, %949
  %966 = select i1 %964, i32 -1450975315, i32 -987685099
  store i32 %966, i32* %44
  br label %2013

; <label>:967:                                    ; preds = %47
  %968 = load volatile i64*, i64** %11
  %969 = load i64, i64* %968, align 8
  %970 = load volatile i32*, i32** %22
  %971 = load i32, i32* %970, align 4
  %972 = sext i32 %971 to i64
  %973 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %972
  %974 = load i64, i64* %973, align 8
  %975 = sub i64 0, 1
  %976 = sub i64 %974, %975
  %977 = add nsw i64 %974, 1
  %978 = load volatile i64*, i64** %10
  store i64 %976, i64* %978, align 8
  %979 = load volatile i64*, i64** %12
  %980 = load volatile i64*, i64** %10
  %981 = call dereferenceable(8) i64* @_ZSt3maxIxERKT_S2_S2_(i64* dereferenceable(8) %980, i64* dereferenceable(8) %979)
  %982 = load i64, i64* %981, align 8
  %983 = add i64 %969, -3344050842092470648
  %984 = sub i64 %983, %982
  %985 = sub i64 %984, -3344050842092470648
  %986 = sub nsw i64 %969, %982
  %987 = sub i64 0, 1
  %988 = sub i64 %985, %987
  %989 = add nsw i64 %985, 1
  %990 = load volatile i64*, i64** %19
  %991 = load i64, i64* %990, align 8
  %992 = add i64 %991, 7360286253118827771
  %993 = add i64 %992, %988
  %994 = sub i64 %993, 7360286253118827771
  %995 = add nsw i64 %991, %988
  %996 = load volatile i64*, i64** %19
  store i64 %994, i64* %996, align 8
  %997 = load i32, i32* @x
  %998 = load i32, i32* @y
  %999 = add i32 %997, 686982067
  %1000 = sub i32 %999, 1
  %1001 = sub i32 %1000, 686982067
  %1002 = sub i32 %997, 1
  %1003 = mul i32 %997, %1001
  %1004 = urem i32 %1003, 2
  %1005 = icmp eq i32 %1004, 0
  %1006 = icmp slt i32 %998, 10
  %1007 = and i1 %1005, %1006
  %1008 = xor i1 %1005, %1006
  %1009 = or i1 %1007, %1008
  %1010 = or i1 %1005, %1006
  %1011 = select i1 %1009, i32 1641398664, i32 -987685099
  store i32 %1011, i32* %44
  br label %2013

; <label>:1012:                                   ; preds = %47
  store i32 943205942, i32* %44
  br label %2013

; <label>:1013:                                   ; preds = %47
  %1014 = load volatile i32*, i32** %22
  %1015 = load i32, i32* %1014, align 4
  %1016 = sext i32 %1015 to i64
  %1017 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %1016
  %1018 = load i64, i64* %1017, align 8
  %1019 = sub i64 %1018, -532260885518333991
  %1020 = sub i64 %1019, 1
  %1021 = add i64 %1020, -532260885518333991
  %1022 = sub nsw i64 %1018, 1
  %1023 = load volatile i64*, i64** %9
  store i64 %1021, i64* %1023, align 8
  %1024 = load volatile i64*, i64** %11
  %1025 = load volatile i64*, i64** %9
  %1026 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %1025, i64* dereferenceable(8) %1024)
  %1027 = load i64, i64* %1026, align 8
  %1028 = load volatile i64*, i64** %12
  %1029 = load i64, i64* %1028, align 8
  %1030 = sub i64 %1027, -536367490138722150
  %1031 = sub i64 %1030, %1029
  %1032 = add i64 %1031, -536367490138722150
  %1033 = sub nsw i64 %1027, %1029
  %1034 = sub i64 %1032, -4829803105716005270
  %1035 = add i64 %1034, 1
  %1036 = add i64 %1035, -4829803105716005270
  %1037 = add nsw i64 %1032, 1
  %1038 = load volatile i64*, i64** %19
  %1039 = load i64, i64* %1038, align 8
  %1040 = add i64 %1039, -6972195329731427473
  %1041 = add i64 %1040, %1036
  %1042 = sub i64 %1041, -6972195329731427473
  %1043 = add nsw i64 %1039, %1036
  %1044 = load volatile i64*, i64** %19
  store i64 %1042, i64* %1044, align 8
  store i32 943205942, i32* %44
  br label %2013

; <label>:1045:                                   ; preds = %47
  store i32 -1802702319, i32* %44
  br label %2013

; <label>:1046:                                   ; preds = %47
  %1047 = load i32, i32* @x
  %1048 = load i32, i32* @y
  %1049 = add i32 %1047, -67475286
  %1050 = sub i32 %1049, 1
  %1051 = sub i32 %1050, -67475286
  %1052 = sub i32 %1047, 1
  %1053 = mul i32 %1047, %1051
  %1054 = urem i32 %1053, 2
  %1055 = icmp eq i32 %1054, 0
  %1056 = icmp slt i32 %1048, 10
  %1057 = xor i1 %1055, true
  %1058 = xor i1 %1056, true
  %1059 = xor i1 false, true
  %1060 = and i1 %1057, false
  %1061 = and i1 %1055, %1059
  %1062 = and i1 %1058, false
  %1063 = and i1 %1056, %1059
  %1064 = or i1 %1060, %1061
  %1065 = or i1 %1062, %1063
  %1066 = xor i1 %1064, %1065
  %1067 = or i1 %1057, %1058
  %1068 = xor i1 %1067, true
  %1069 = or i1 false, %1059
  %1070 = and i1 %1068, %1069
  %1071 = or i1 %1066, %1070
  %1072 = or i1 %1055, %1056
  %1073 = select i1 %1071, i32 2022825276, i32 -1748985601
  store i32 %1073, i32* %44
  br label %2013

; <label>:1074:                                   ; preds = %47
  %1075 = load i32, i32* @x
  %1076 = load i32, i32* @y
  %1077 = sub i32 %1075, 1895703206
  %1078 = sub i32 %1077, 1
  %1079 = add i32 %1078, 1895703206
  %1080 = sub i32 %1075, 1
  %1081 = mul i32 %1075, %1079
  %1082 = urem i32 %1081, 2
  %1083 = icmp eq i32 %1082, 0
  %1084 = icmp slt i32 %1076, 10
  %1085 = xor i1 %1083, true
  %1086 = xor i1 %1084, true
  %1087 = xor i1 false, true
  %1088 = and i1 %1085, false
  %1089 = and i1 %1083, %1087
  %1090 = and i1 %1086, false
  %1091 = and i1 %1084, %1087
  %1092 = or i1 %1088, %1089
  %1093 = or i1 %1090, %1091
  %1094 = xor i1 %1092, %1093
  %1095 = or i1 %1085, %1086
  %1096 = xor i1 %1095, true
  %1097 = or i1 false, %1087
  %1098 = and i1 %1096, %1097
  %1099 = or i1 %1094, %1098
  %1100 = or i1 %1083, %1084
  %1101 = select i1 %1099, i32 -196071927, i32 -1748985601
  store i32 %1101, i32* %44
  br label %2013

; <label>:1102:                                   ; preds = %47
  store i32 -1676459113, i32* %44
  br label %2013

; <label>:1103:                                   ; preds = %47
  %1104 = load i32, i32* @x
  %1105 = load i32, i32* @y
  %1106 = add i32 %1104, 214509427
  %1107 = sub i32 %1106, 1
  %1108 = sub i32 %1107, 214509427
  %1109 = sub i32 %1104, 1
  %1110 = mul i32 %1104, %1108
  %1111 = urem i32 %1110, 2
  %1112 = icmp eq i32 %1111, 0
  %1113 = icmp slt i32 %1105, 10
  %1114 = xor i1 %1112, true
  %1115 = xor i1 %1113, true
  %1116 = xor i1 true, true
  %1117 = and i1 %1114, true
  %1118 = and i1 %1112, %1116
  %1119 = and i1 %1115, true
  %1120 = and i1 %1113, %1116
  %1121 = or i1 %1117, %1118
  %1122 = or i1 %1119, %1120
  %1123 = xor i1 %1121, %1122
  %1124 = or i1 %1114, %1115
  %1125 = xor i1 %1124, true
  %1126 = or i1 true, %1116
  %1127 = and i1 %1125, %1126
  %1128 = or i1 %1123, %1127
  %1129 = or i1 %1112, %1113
  %1130 = select i1 %1128, i32 135338129, i32 -1184945770
  store i32 %1130, i32* %44
  br label %2013

; <label>:1131:                                   ; preds = %47
  %1132 = load volatile i64*, i64** %12
  %1133 = load i64, i64* %1132, align 8
  %1134 = load volatile i32*, i32** %22
  %1135 = load i32, i32* %1134, align 4
  %1136 = sext i32 %1135 to i64
  %1137 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %1136
  store i64 %1133, i64* %1137, align 8
  %1138 = load volatile i64*, i64** %11
  %1139 = load i64, i64* %1138, align 8
  %1140 = load volatile i32*, i32** %22
  %1141 = load i32, i32* %1140, align 4
  %1142 = sext i32 %1141 to i64
  %1143 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %1142
  store i64 %1139, i64* %1143, align 8
  %1144 = load volatile i32*, i32** %14
  %1145 = load i32, i32* %1144, align 4
  %1146 = sext i32 %1145 to i64
  %1147 = load volatile i64*, i64** %21
  %1148 = load i64, i64* %1147, align 8
  %1149 = sub i64 0, %1146
  %1150 = sub i64 %1148, %1149
  %1151 = add nsw i64 %1148, %1146
  %1152 = load volatile i64*, i64** %21
  store i64 %1150, i64* %1152, align 8
  %1153 = load volatile i64*, i64** %30
  %1154 = load i64, i64* %1153, align 8
  %1155 = load volatile i32*, i32** %14
  %1156 = load i32, i32* %1155, align 4
  %1157 = sext i32 %1156 to i64
  %1158 = sub i64 %1154, 5720219396881510673
  %1159 = sub i64 %1158, %1157
  %1160 = add i64 %1159, 5720219396881510673
  %1161 = sub nsw i64 %1154, %1157
  %1162 = sub i64 0, 1
  %1163 = add i64 %1160, %1162
  %1164 = sub nsw i64 %1160, 1
  %1165 = load volatile i64*, i64** %20
  %1166 = load i64, i64* %1165, align 8
  %1167 = sub i64 0, %1163
  %1168 = sub i64 %1166, %1167
  %1169 = add nsw i64 %1166, %1163
  %1170 = load volatile i64*, i64** %20
  store i64 %1168, i64* %1170, align 8
  %1171 = load volatile i32*, i32** %22
  %1172 = load i32, i32* %1171, align 4
  %1173 = sub i32 %1172, -876828352
  %1174 = add i32 %1173, 1
  %1175 = add i32 %1174, -876828352
  %1176 = add nsw i32 %1172, 1
  %1177 = load volatile i32*, i32** %22
  store i32 %1175, i32* %1177, align 4
  %1178 = sext i32 %1175 to i64
  %1179 = load volatile i64*, i64** %27
  %1180 = load i64, i64* %1179, align 8
  %1181 = icmp sge i64 %1178, %1180
  store i1 %1181, i1* %2
  %1182 = load i32, i32* @x
  %1183 = load i32, i32* @y
  %1184 = add i32 %1182, -1421859769
  %1185 = sub i32 %1184, 1
  %1186 = sub i32 %1185, -1421859769
  %1187 = sub i32 %1182, 1
  %1188 = mul i32 %1182, %1186
  %1189 = urem i32 %1188, 2
  %1190 = icmp eq i32 %1189, 0
  %1191 = icmp slt i32 %1183, 10
  %1192 = xor i1 %1190, true
  %1193 = xor i1 %1191, true
  %1194 = xor i1 true, true
  %1195 = and i1 %1192, true
  %1196 = and i1 %1190, %1194
  %1197 = and i1 %1193, true
  %1198 = and i1 %1191, %1194
  %1199 = or i1 %1195, %1196
  %1200 = or i1 %1197, %1198
  %1201 = xor i1 %1199, %1200
  %1202 = or i1 %1192, %1193
  %1203 = xor i1 %1202, true
  %1204 = or i1 true, %1194
  %1205 = and i1 %1203, %1204
  %1206 = or i1 %1201, %1205
  %1207 = or i1 %1190, %1191
  %1208 = select i1 %1206, i32 -735520934, i32 -1184945770
  store i32 %1208, i32* %44
  br label %2013

; <label>:1209:                                   ; preds = %47
  %1210 = load volatile i1, i1* %2
  %1211 = select i1 %1210, i32 -1060306491, i32 -716424494
  store i32 %1211, i32* %44
  br label %2013

; <label>:1212:                                   ; preds = %47
  %1213 = load volatile i32*, i32** %22
  store i32 0, i32* %1213, align 4
  %1214 = load volatile i64*, i64** %26
  %1215 = load i64, i64* %1214, align 8
  %1216 = load volatile i64*, i64** %15
  %1217 = load i64, i64* %1216, align 8
  %1218 = sub i64 0, %1215
  %1219 = sub i64 %1217, %1218
  %1220 = add nsw i64 %1217, %1215
  %1221 = load volatile i64*, i64** %15
  store i64 %1219, i64* %1221, align 8
  store i32 -716424494, i32* %44
  br label %2013

; <label>:1222:                                   ; preds = %47
  %1223 = load i32, i32* @x
  %1224 = load i32, i32* @y
  %1225 = add i32 %1223, -1311913857
  %1226 = sub i32 %1225, 1
  %1227 = sub i32 %1226, -1311913857
  %1228 = sub i32 %1223, 1
  %1229 = mul i32 %1223, %1227
  %1230 = urem i32 %1229, 2
  %1231 = icmp eq i32 %1230, 0
  %1232 = icmp slt i32 %1224, 10
  %1233 = and i1 %1231, %1232
  %1234 = xor i1 %1231, %1232
  %1235 = or i1 %1233, %1234
  %1236 = or i1 %1231, %1232
  %1237 = select i1 %1235, i32 140786374, i32 -208846915
  store i32 %1237, i32* %44
  br label %2013

; <label>:1238:                                   ; preds = %47
  %1239 = load i32, i32* @x
  %1240 = load i32, i32* @y
  %1241 = sub i32 0, 1
  %1242 = add i32 %1239, %1241
  %1243 = sub i32 %1239, 1
  %1244 = mul i32 %1239, %1242
  %1245 = urem i32 %1244, 2
  %1246 = icmp eq i32 %1245, 0
  %1247 = icmp slt i32 %1240, 10
  %1248 = and i1 %1246, %1247
  %1249 = xor i1 %1246, %1247
  %1250 = or i1 %1248, %1249
  %1251 = or i1 %1246, %1247
  %1252 = select i1 %1250, i32 379333070, i32 -208846915
  store i32 %1252, i32* %44
  br label %2013

; <label>:1253:                                   ; preds = %47
  store i32 -1784720018, i32* %44
  br label %2013

; <label>:1254:                                   ; preds = %47
  %1255 = load volatile i32*, i32** %14
  %1256 = load i32, i32* %1255, align 4
  %1257 = add i32 %1256, -176775310
  %1258 = add i32 %1257, 1
  %1259 = sub i32 %1258, -176775310
  %1260 = add nsw i32 %1256, 1
  %1261 = load volatile i32*, i32** %14
  store i32 %1259, i32* %1261, align 4
  store i32 -6601509, i32* %44
  br label %2013

; <label>:1262:                                   ; preds = %47
  %1263 = load i32, i32* @x
  %1264 = load i32, i32* @y
  %1265 = sub i32 %1263, -115991341
  %1266 = sub i32 %1265, 1
  %1267 = add i32 %1266, -115991341
  %1268 = sub i32 %1263, 1
  %1269 = mul i32 %1263, %1267
  %1270 = urem i32 %1269, 2
  %1271 = icmp eq i32 %1270, 0
  %1272 = icmp slt i32 %1264, 10
  %1273 = and i1 %1271, %1272
  %1274 = xor i1 %1271, %1272
  %1275 = or i1 %1273, %1274
  %1276 = or i1 %1271, %1272
  %1277 = select i1 %1275, i32 -1967569987, i32 -721019237
  store i32 %1277, i32* %44
  br label %2013

; <label>:1278:                                   ; preds = %47
  %1279 = load volatile i64*, i64** %19
  %1280 = load i64, i64* %1279, align 8
  %1281 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i32 0, i32 0), i64 %1280)
  %1282 = load volatile i32*, i32** %31
  store i32 0, i32* %1282, align 4
  %1283 = load i32, i32* @x
  %1284 = load i32, i32* @y
  %1285 = sub i32 0, 1
  %1286 = add i32 %1283, %1285
  %1287 = sub i32 %1283, 1
  %1288 = mul i32 %1283, %1286
  %1289 = urem i32 %1288, 2
  %1290 = icmp eq i32 %1289, 0
  %1291 = icmp slt i32 %1284, 10
  %1292 = xor i1 %1290, true
  %1293 = xor i1 %1291, true
  %1294 = xor i1 true, true
  %1295 = and i1 %1292, true
  %1296 = and i1 %1290, %1294
  %1297 = and i1 %1293, true
  %1298 = and i1 %1291, %1294
  %1299 = or i1 %1295, %1296
  %1300 = or i1 %1297, %1298
  %1301 = xor i1 %1299, %1300
  %1302 = or i1 %1292, %1293
  %1303 = xor i1 %1302, true
  %1304 = or i1 true, %1294
  %1305 = and i1 %1303, %1304
  %1306 = or i1 %1301, %1305
  %1307 = or i1 %1290, %1291
  %1308 = select i1 %1306, i32 1660879980, i32 -721019237
  store i32 %1308, i32* %44
  br label %2013

; <label>:1309:                                   ; preds = %47
  store i32 1508763345, i32* %44
  br label %2013

; <label>:1310:                                   ; preds = %47
  %1311 = load volatile i32*, i32** %31
  %1312 = load i32, i32* %1311, align 4
  ret i32 %1312

; <label>:1313:                                   ; preds = %47
  %1314 = alloca i32, align 4
  %1315 = alloca i64, align 8
  %1316 = alloca i64, align 8
  %1317 = alloca i64, align 8
  %1318 = alloca i64, align 8
  %1319 = alloca i64, align 8
  %1320 = alloca i64, align 8
  %1321 = alloca i64, align 8
  %1322 = alloca i64, align 8
  %1323 = alloca i32, align 4
  %1324 = alloca i64, align 8
  %1325 = alloca i64, align 8
  %1326 = alloca i64, align 8
  %1327 = alloca i32, align 4
  %1328 = alloca i32, align 4
  %1329 = alloca i64, align 8
  %1330 = alloca i64, align 8
  %1331 = alloca i32, align 4
  %1332 = alloca i64, align 8
  %1333 = alloca i64, align 8
  %1334 = alloca i64, align 8
  %1335 = alloca i64, align 8
  %1336 = alloca i64, align 8
  store i32 0, i32* %1314, align 4
  %1337 = call i32 (i8*, ...) @scanf(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str, i32 0, i32 0), i64* %1315, i64* %1316, i64* %1317)
  %1338 = load i64, i64* %1317, align 8
  %1339 = icmp eq i64 %1338, 0
  store i32 1446528539, i32* %44
  br label %2013

; <label>:1340:                                   ; preds = %47
  %1341 = load volatile i64*, i64** %28
  %1342 = load i64, i64* %1341, align 8
  %1343 = icmp slt i64 %1342, 0
  store i32 -482383820, i32* %44
  br label %2013

; <label>:1344:                                   ; preds = %47
  %1345 = load volatile i64*, i64** %29
  %1346 = load i64, i64* %1345, align 8
  %1347 = icmp ne i64 %1346, 0
  store i32 -2001713038, i32* %44
  br label %2013

; <label>:1348:                                   ; preds = %47
  %1349 = load volatile i64*, i64** %28
  %1350 = load i64, i64* %1349, align 8
  %1351 = load volatile i64*, i64** %29
  %1352 = load i64, i64* %1351, align 8
  %1353 = call i64 @_ZSt3absx(i64 %1352)
  %1354 = load volatile i64*, i64** %28
  %1355 = load i64, i64* %1354, align 8
  %1356 = call i64 @_ZSt5__gcdIxET_S0_S0_(i64 %1353, i64 %1355)
  %1357 = sub i64 0, %1350
  %1358 = add i64 0, %1357
  %1359 = sub i64 0, %1350
  %1360 = sub i64 %1358, -3583664840270890742
  %1361 = add i64 %1360, %1356
  %1362 = add i64 %1361, -3583664840270890742
  %1363 = add i64 %1358, %1356
  %1364 = add i64 %1350, -7091416917800045178
  %1365 = sub i64 %1364, %1356
  %1366 = sub i64 %1365, -7091416917800045178
  %1367 = sub i64 %1350, %1356
  %1368 = mul i64 %1366, %1356
  %1369 = add i64 %1350, -3076348044015453121
  %1370 = sub i64 %1369, %1356
  %1371 = sub i64 %1370, -3076348044015453121
  %1372 = sub i64 %1350, %1356
  %1373 = mul i64 %1371, %1356
  %1374 = shl i64 %1350, %1356
  %1375 = sub i64 0, 1757979810005729960
  %1376 = sub i64 %1375, %1350
  %1377 = add i64 %1376, 1757979810005729960
  %1378 = sub i64 0, %1350
  %1379 = add i64 %1377, -916218663453628863
  %1380 = add i64 %1379, %1356
  %1381 = sub i64 %1380, -916218663453628863
  %1382 = add i64 %1377, %1356
  %1383 = sdiv i64 %1350, %1356
  store i32 1218903675, i32* %44
  br label %2013

; <label>:1384:                                   ; preds = %47
  %1385 = load volatile i64*, i64** %26
  %1386 = load volatile i64, i64* %1
  store i64 %1386, i64* %1385, align 8
  %1387 = load volatile i64*, i64** %24
  store i64 0, i64* %1387, align 8
  %1388 = load volatile i64*, i64** %30
  %1389 = load i64, i64* %1388, align 8
  %1390 = add i64 0, -3590720406221050176
  %1391 = sub i64 %1390, %1389
  %1392 = sub i64 %1391, -3590720406221050176
  %1393 = sub i64 0, %1389
  %1394 = sub i64 0, %1392
  %1395 = sub i64 0, 1
  %1396 = add i64 %1394, %1395
  %1397 = sub i64 0, %1396
  %1398 = add i64 %1392, 1
  %1399 = add i64 %1389, -5411180915132616764
  %1400 = sub i64 %1399, 1
  %1401 = sub i64 %1400, -5411180915132616764
  %1402 = sub i64 %1389, 1
  %1403 = mul i64 %1401, 1
  %1404 = shl i64 %1389, 1
  %1405 = sub i64 0, %1389
  %1406 = add i64 0, %1405
  %1407 = sub i64 0, %1389
  %1408 = sub i64 0, %1406
  %1409 = sub i64 0, 1
  %1410 = add i64 %1408, %1409
  %1411 = sub i64 0, %1410
  %1412 = add i64 %1406, 1
  %1413 = add i64 0, -9197922909879061133
  %1414 = sub i64 %1413, %1389
  %1415 = sub i64 %1414, -9197922909879061133
  %1416 = sub i64 0, %1389
  %1417 = sub i64 0, 1
  %1418 = sub i64 %1415, %1417
  %1419 = add i64 %1415, 1
  %1420 = sub i64 0, 7531323998448209083
  %1421 = sub i64 %1420, %1389
  %1422 = add i64 %1421, 7531323998448209083
  %1423 = sub i64 0, %1389
  %1424 = sub i64 0, %1422
  %1425 = sub i64 0, 1
  %1426 = add i64 %1424, %1425
  %1427 = sub i64 0, %1426
  %1428 = add i64 %1422, 1
  %1429 = sub i64 0, 1
  %1430 = sub i64 %1389, %1429
  %1431 = add nsw i64 %1389, 1
  %1432 = load volatile i64*, i64** %27
  %1433 = load i64, i64* %1432, align 8
  %1434 = sub i64 %1430, 3708620345750103828
  %1435 = sub i64 %1434, %1433
  %1436 = add i64 %1435, 3708620345750103828
  %1437 = sub i64 %1430, %1433
  %1438 = mul i64 %1436, %1433
  %1439 = add i64 %1430, -4411086033067630506
  %1440 = sub i64 %1439, %1433
  %1441 = sub i64 %1440, -4411086033067630506
  %1442 = sub i64 %1430, %1433
  %1443 = mul i64 %1441, %1433
  %1444 = add i64 0, -6647502833799455042
  %1445 = sub i64 %1444, %1430
  %1446 = sub i64 %1445, -6647502833799455042
  %1447 = sub i64 0, %1430
  %1448 = sub i64 %1446, 2622553672750319925
  %1449 = add i64 %1448, %1433
  %1450 = add i64 %1449, 2622553672750319925
  %1451 = add i64 %1446, %1433
  %1452 = add i64 0, 6257105802833249077
  %1453 = sub i64 %1452, %1430
  %1454 = sub i64 %1453, 6257105802833249077
  %1455 = sub i64 0, %1430
  %1456 = sub i64 %1454, 4662029595720313861
  %1457 = add i64 %1456, %1433
  %1458 = add i64 %1457, 4662029595720313861
  %1459 = add i64 %1454, %1433
  %1460 = add i64 %1430, 6469252797665670220
  %1461 = sub i64 %1460, %1433
  %1462 = sub i64 %1461, 6469252797665670220
  %1463 = sub nsw i64 %1430, %1433
  %1464 = load volatile i64*, i64** %23
  store i64 %1462, i64* %1464, align 8
  %1465 = load volatile i64*, i64** %27
  %1466 = load volatile i64*, i64** %23
  %1467 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %1466, i64* dereferenceable(8) %1465)
  %1468 = load volatile i64*, i64** %24
  %1469 = call dereferenceable(8) i64* @_ZSt3maxIxERKT_S2_S2_(i64* dereferenceable(8) %1468, i64* dereferenceable(8) %1467)
  %1470 = load i64, i64* %1469, align 8
  %1471 = load volatile i64*, i64** %25
  store i64 %1470, i64* %1471, align 8
  %1472 = load volatile i32*, i32** %22
  store i32 0, i32* %1472, align 4
  %1473 = load volatile i64*, i64** %21
  store i64 0, i64* %1473, align 8
  %1474 = load volatile i64*, i64** %20
  store i64 0, i64* %1474, align 8
  %1475 = load volatile i64*, i64** %19
  store i64 0, i64* %1475, align 8
  %1476 = load volatile i32*, i32** %18
  store i32 0, i32* %1476, align 4
  store i32 -846670456, i32* %44
  br label %2013

; <label>:1477:                                   ; preds = %47
  %1478 = load volatile i32*, i32** %18
  %1479 = load i32, i32* %1478, align 4
  %1480 = shl i32 %1479, 1
  %1481 = shl i32 %1479, 1
  %1482 = shl i32 %1479, 1
  %1483 = shl i32 %1479, 1
  %1484 = sub i32 0, %1479
  %1485 = sub i32 0, 1
  %1486 = add i32 %1484, %1485
  %1487 = sub i32 0, %1486
  %1488 = add nsw i32 %1479, 1
  %1489 = load volatile i32*, i32** %18
  store i32 %1487, i32* %1489, align 4
  store i32 -1672313881, i32* %44
  br label %2013

; <label>:1490:                                   ; preds = %47
  %1491 = load volatile i64*, i64** %20
  %1492 = load i64, i64* %1491, align 8
  %1493 = load volatile i64*, i64** %21
  %1494 = load i64, i64* %1493, align 8
  %1495 = add i64 %1492, 1436020236032800650
  %1496 = sub i64 %1495, %1494
  %1497 = sub i64 %1496, 1436020236032800650
  %1498 = sub i64 %1492, %1494
  %1499 = mul i64 %1497, %1494
  %1500 = sub i64 %1492, -5480555384075054279
  %1501 = sub i64 %1500, %1494
  %1502 = add i64 %1501, -5480555384075054279
  %1503 = sub nsw i64 %1492, %1494
  %1504 = shl i64 %1502, 1
  %1505 = shl i64 %1502, 1
  %1506 = add i64 %1502, 1224902819248395574
  %1507 = add i64 %1506, 1
  %1508 = sub i64 %1507, 1224902819248395574
  %1509 = add nsw i64 %1502, 1
  %1510 = load volatile i64*, i64** %19
  %1511 = load i64, i64* %1510, align 8
  %1512 = sub i64 %1511, 690819697511945818
  %1513 = sub i64 %1512, %1508
  %1514 = add i64 %1513, 690819697511945818
  %1515 = sub i64 %1511, %1508
  %1516 = mul i64 %1514, %1508
  %1517 = shl i64 %1511, %1508
  %1518 = sub i64 %1511, -6249513060218482949
  %1519 = add i64 %1518, %1508
  %1520 = add i64 %1519, -6249513060218482949
  %1521 = add nsw i64 %1511, %1508
  %1522 = load volatile i64*, i64** %19
  store i64 %1520, i64* %1522, align 8
  %1523 = load volatile i32*, i32** %17
  %1524 = load i32, i32* %1523, align 4
  %1525 = sext i32 %1524 to i64
  %1526 = load volatile i64*, i64** %21
  %1527 = load i64, i64* %1526, align 8
  %1528 = shl i64 %1527, %1525
  %1529 = sub i64 0, %1525
  %1530 = sub i64 %1527, %1529
  %1531 = add nsw i64 %1527, %1525
  %1532 = load volatile i64*, i64** %21
  store i64 %1530, i64* %1532, align 8
  %1533 = load volatile i64*, i64** %30
  %1534 = load i64, i64* %1533, align 8
  %1535 = load volatile i32*, i32** %17
  %1536 = load i32, i32* %1535, align 4
  %1537 = sext i32 %1536 to i64
  %1538 = add i64 %1534, -1691509729905909234
  %1539 = sub i64 %1538, %1537
  %1540 = sub i64 %1539, -1691509729905909234
  %1541 = sub i64 %1534, %1537
  %1542 = mul i64 %1540, %1537
  %1543 = sub i64 0, %1537
  %1544 = add i64 %1534, %1543
  %1545 = sub i64 %1534, %1537
  %1546 = mul i64 %1544, %1537
  %1547 = sub i64 0, %1537
  %1548 = add i64 %1534, %1547
  %1549 = sub nsw i64 %1534, %1537
  %1550 = sub i64 0, %1548
  %1551 = add i64 0, %1550
  %1552 = sub i64 0, %1548
  %1553 = sub i64 0, %1551
  %1554 = sub i64 0, 1
  %1555 = add i64 %1553, %1554
  %1556 = sub i64 0, %1555
  %1557 = add i64 %1551, 1
  %1558 = shl i64 %1548, 1
  %1559 = shl i64 %1548, 1
  %1560 = shl i64 %1548, 1
  %1561 = sub i64 %1548, 706690971995842810
  %1562 = sub i64 %1561, 1
  %1563 = add i64 %1562, 706690971995842810
  %1564 = sub nsw i64 %1548, 1
  %1565 = load volatile i64*, i64** %20
  %1566 = load i64, i64* %1565, align 8
  %1567 = sub i64 0, %1566
  %1568 = add i64 0, %1567
  %1569 = sub i64 0, %1566
  %1570 = add i64 %1568, 4096355511688463723
  %1571 = add i64 %1570, %1563
  %1572 = sub i64 %1571, 4096355511688463723
  %1573 = add i64 %1568, %1563
  %1574 = add i64 %1566, -8593942085460506142
  %1575 = add i64 %1574, %1563
  %1576 = sub i64 %1575, -8593942085460506142
  %1577 = add nsw i64 %1566, %1563
  %1578 = load volatile i64*, i64** %20
  store i64 %1576, i64* %1578, align 8
  store i32 807533729, i32* %44
  br label %2013

; <label>:1579:                                   ; preds = %47
  %1580 = load volatile i64*, i64** %21
  %1581 = load i64, i64* %1580, align 8
  %1582 = load volatile i64*, i64** %15
  %1583 = load i64, i64* %1582, align 8
  %1584 = add i64 %1581, 8138402186980795781
  %1585 = sub i64 %1584, %1583
  %1586 = sub i64 %1585, 8138402186980795781
  %1587 = sub i64 %1581, %1583
  %1588 = mul i64 %1586, %1583
  %1589 = shl i64 %1581, %1583
  %1590 = sub i64 0, %1583
  %1591 = add i64 %1581, %1590
  %1592 = sub i64 %1581, %1583
  %1593 = mul i64 %1591, %1583
  %1594 = sub i64 0, %1583
  %1595 = sub i64 %1581, %1594
  %1596 = add nsw i64 %1581, %1583
  %1597 = load volatile i64*, i64** %12
  store i64 %1595, i64* %1597, align 8
  %1598 = load volatile i64*, i64** %20
  %1599 = load i64, i64* %1598, align 8
  %1600 = load volatile i64*, i64** %15
  %1601 = load i64, i64* %1600, align 8
  %1602 = sub i64 0, -5878225583072645871
  %1603 = sub i64 %1602, %1599
  %1604 = add i64 %1603, -5878225583072645871
  %1605 = sub i64 0, %1599
  %1606 = sub i64 0, %1604
  %1607 = sub i64 0, %1601
  %1608 = add i64 %1606, %1607
  %1609 = sub i64 0, %1608
  %1610 = add i64 %1604, %1601
  %1611 = add i64 %1599, -7325966669470055086
  %1612 = sub i64 %1611, %1601
  %1613 = sub i64 %1612, -7325966669470055086
  %1614 = sub i64 %1599, %1601
  %1615 = mul i64 %1613, %1601
  %1616 = sub i64 %1599, -2834994189078361183
  %1617 = sub i64 %1616, %1601
  %1618 = add i64 %1617, -2834994189078361183
  %1619 = sub i64 %1599, %1601
  %1620 = mul i64 %1618, %1601
  %1621 = sub i64 0, %1601
  %1622 = add i64 %1599, %1621
  %1623 = sub i64 %1599, %1601
  %1624 = mul i64 %1622, %1601
  %1625 = sub i64 0, %1599
  %1626 = sub i64 0, %1601
  %1627 = add i64 %1625, %1626
  %1628 = sub i64 0, %1627
  %1629 = add nsw i64 %1599, %1601
  %1630 = load volatile i64*, i64** %11
  store i64 %1628, i64* %1630, align 8
  %1631 = load volatile i32*, i32** %22
  %1632 = load i32, i32* %1631, align 4
  %1633 = sext i32 %1632 to i64
  %1634 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %1633
  %1635 = load i64, i64* %1634, align 8
  %1636 = load volatile i64*, i64** %12
  %1637 = load i64, i64* %1636, align 8
  %1638 = icmp sge i64 %1635, %1637
  store i32 -2022974862, i32* %44
  br label %2013

; <label>:1639:                                   ; preds = %47
  %1640 = load volatile i32*, i32** %22
  %1641 = load i32, i32* %1640, align 4
  %1642 = sext i32 %1641 to i64
  %1643 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %1642
  %1644 = load i64, i64* %1643, align 8
  %1645 = load volatile i64*, i64** %11
  %1646 = load i64, i64* %1645, align 8
  %1647 = icmp sle i64 %1644, %1646
  store i32 -2079181266, i32* %44
  br label %2013

; <label>:1648:                                   ; preds = %47
  %1649 = load volatile i64*, i64** %11
  %1650 = load i64, i64* %1649, align 8
  %1651 = load volatile i32*, i32** %22
  %1652 = load i32, i32* %1651, align 4
  %1653 = sext i32 %1652 to i64
  %1654 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %1653
  %1655 = load i64, i64* %1654, align 8
  %1656 = sub i64 0, %1650
  %1657 = add i64 0, %1656
  %1658 = sub i64 0, %1650
  %1659 = add i64 %1657, 1028178242962730866
  %1660 = add i64 %1659, %1655
  %1661 = sub i64 %1660, 1028178242962730866
  %1662 = add i64 %1657, %1655
  %1663 = shl i64 %1650, %1655
  %1664 = sub i64 %1650, 5445469183284030128
  %1665 = add i64 %1664, %1655
  %1666 = add i64 %1665, 5445469183284030128
  %1667 = add nsw i64 %1650, %1655
  %1668 = load volatile i64*, i64** %12
  %1669 = load i64, i64* %1668, align 8
  %1670 = sub i64 0, -7325597662950762863
  %1671 = sub i64 %1670, %1666
  %1672 = add i64 %1671, -7325597662950762863
  %1673 = sub i64 0, %1666
  %1674 = sub i64 %1672, 7641056005250457458
  %1675 = add i64 %1674, %1669
  %1676 = add i64 %1675, 7641056005250457458
  %1677 = add i64 %1672, %1669
  %1678 = sub i64 0, %1666
  %1679 = add i64 0, %1678
  %1680 = sub i64 0, %1666
  %1681 = add i64 %1679, 5714226613413015766
  %1682 = add i64 %1681, %1669
  %1683 = sub i64 %1682, 5714226613413015766
  %1684 = add i64 %1679, %1669
  %1685 = add i64 0, 3432562061448632476
  %1686 = sub i64 %1685, %1666
  %1687 = sub i64 %1686, 3432562061448632476
  %1688 = sub i64 0, %1666
  %1689 = sub i64 0, %1687
  %1690 = sub i64 0, %1669
  %1691 = add i64 %1689, %1690
  %1692 = sub i64 0, %1691
  %1693 = add i64 %1687, %1669
  %1694 = shl i64 %1666, %1669
  %1695 = add i64 %1666, -4660964393865139240
  %1696 = sub i64 %1695, %1669
  %1697 = sub i64 %1696, -4660964393865139240
  %1698 = sub i64 %1666, %1669
  %1699 = mul i64 %1697, %1669
  %1700 = sub i64 %1666, 336637322587279271
  %1701 = sub i64 %1700, %1669
  %1702 = add i64 %1701, 336637322587279271
  %1703 = sub i64 %1666, %1669
  %1704 = mul i64 %1702, %1669
  %1705 = shl i64 %1666, %1669
  %1706 = sub i64 0, %1669
  %1707 = add i64 %1666, %1706
  %1708 = sub nsw i64 %1666, %1669
  %1709 = load volatile i32*, i32** %22
  %1710 = load i32, i32* %1709, align 4
  %1711 = sext i32 %1710 to i64
  %1712 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %1711
  %1713 = load i64, i64* %1712, align 8
  %1714 = add i64 0, 5717285499189951820
  %1715 = sub i64 %1714, %1707
  %1716 = sub i64 %1715, 5717285499189951820
  %1717 = sub i64 0, %1707
  %1718 = sub i64 0, %1713
  %1719 = sub i64 %1716, %1718
  %1720 = add i64 %1716, %1713
  %1721 = shl i64 %1707, %1713
  %1722 = sub i64 0, 2276689489361921638
  %1723 = sub i64 %1722, %1707
  %1724 = add i64 %1723, 2276689489361921638
  %1725 = sub i64 0, %1707
  %1726 = sub i64 0, %1724
  %1727 = sub i64 0, %1713
  %1728 = add i64 %1726, %1727
  %1729 = sub i64 0, %1728
  %1730 = add i64 %1724, %1713
  %1731 = sub i64 %1707, -7437551863359877731
  %1732 = sub i64 %1731, %1713
  %1733 = add i64 %1732, -7437551863359877731
  %1734 = sub nsw i64 %1707, %1713
  %1735 = load volatile i64*, i64** %19
  %1736 = load i64, i64* %1735, align 8
  %1737 = sub i64 0, %1736
  %1738 = add i64 0, %1737
  %1739 = sub i64 0, %1736
  %1740 = sub i64 0, %1733
  %1741 = sub i64 %1738, %1740
  %1742 = add i64 %1738, %1733
  %1743 = sub i64 0, %1736
  %1744 = add i64 0, %1743
  %1745 = sub i64 0, %1736
  %1746 = sub i64 0, %1733
  %1747 = sub i64 %1744, %1746
  %1748 = add i64 %1744, %1733
  %1749 = add i64 %1736, -1847278391180965311
  %1750 = sub i64 %1749, %1733
  %1751 = sub i64 %1750, -1847278391180965311
  %1752 = sub i64 %1736, %1733
  %1753 = mul i64 %1751, %1733
  %1754 = shl i64 %1736, %1733
  %1755 = shl i64 %1736, %1733
  %1756 = sub i64 0, %1736
  %1757 = sub i64 0, %1733
  %1758 = add i64 %1756, %1757
  %1759 = sub i64 0, %1758
  %1760 = add nsw i64 %1736, %1733
  %1761 = load volatile i64*, i64** %19
  store i64 %1759, i64* %1761, align 8
  store i32 1546089194, i32* %44
  br label %2013

; <label>:1762:                                   ; preds = %47
  store i32 -1564762492, i32* %44
  br label %2013

; <label>:1763:                                   ; preds = %47
  %1764 = load volatile i64*, i64** %11
  %1765 = load i64, i64* %1764, align 8
  %1766 = load volatile i32*, i32** %22
  %1767 = load i32, i32* %1766, align 4
  %1768 = sext i32 %1767 to i64
  %1769 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %1768
  %1770 = load i64, i64* %1769, align 8
  %1771 = sub i64 0, 1
  %1772 = add i64 %1770, %1771
  %1773 = sub i64 %1770, 1
  %1774 = mul i64 %1772, 1
  %1775 = sub i64 0, %1770
  %1776 = add i64 0, %1775
  %1777 = sub i64 0, %1770
  %1778 = sub i64 0, %1776
  %1779 = sub i64 0, 1
  %1780 = add i64 %1778, %1779
  %1781 = sub i64 0, %1780
  %1782 = add i64 %1776, 1
  %1783 = add i64 %1770, -3275609525257418510
  %1784 = add i64 %1783, 1
  %1785 = sub i64 %1784, -3275609525257418510
  %1786 = add nsw i64 %1770, 1
  %1787 = load volatile i64*, i64** %10
  store i64 %1785, i64* %1787, align 8
  %1788 = load volatile i64*, i64** %12
  %1789 = load volatile i64*, i64** %10
  %1790 = call dereferenceable(8) i64* @_ZSt3maxIxERKT_S2_S2_(i64* dereferenceable(8) %1789, i64* dereferenceable(8) %1788)
  %1791 = load i64, i64* %1790, align 8
  %1792 = add i64 %1765, 5844827399626650661
  %1793 = sub i64 %1792, %1791
  %1794 = sub i64 %1793, 5844827399626650661
  %1795 = sub i64 %1765, %1791
  %1796 = mul i64 %1794, %1791
  %1797 = shl i64 %1765, %1791
  %1798 = sub i64 0, %1765
  %1799 = add i64 0, %1798
  %1800 = sub i64 0, %1765
  %1801 = sub i64 %1799, 8261043584926656251
  %1802 = add i64 %1801, %1791
  %1803 = add i64 %1802, 8261043584926656251
  %1804 = add i64 %1799, %1791
  %1805 = add i64 0, 7209418091602105140
  %1806 = sub i64 %1805, %1765
  %1807 = sub i64 %1806, 7209418091602105140
  %1808 = sub i64 0, %1765
  %1809 = sub i64 0, %1807
  %1810 = sub i64 0, %1791
  %1811 = add i64 %1809, %1810
  %1812 = sub i64 0, %1811
  %1813 = add i64 %1807, %1791
  %1814 = add i64 %1765, -1283037497294918863
  %1815 = sub i64 %1814, %1791
  %1816 = sub i64 %1815, -1283037497294918863
  %1817 = sub i64 %1765, %1791
  %1818 = mul i64 %1816, %1791
  %1819 = add i64 0, 6158528165410951941
  %1820 = sub i64 %1819, %1765
  %1821 = sub i64 %1820, 6158528165410951941
  %1822 = sub i64 0, %1765
  %1823 = add i64 %1821, -8887980418058661495
  %1824 = add i64 %1823, %1791
  %1825 = sub i64 %1824, -8887980418058661495
  %1826 = add i64 %1821, %1791
  %1827 = sub i64 0, -4031801524848642521
  %1828 = sub i64 %1827, %1765
  %1829 = add i64 %1828, -4031801524848642521
  %1830 = sub i64 0, %1765
  %1831 = sub i64 0, %1791
  %1832 = sub i64 %1829, %1831
  %1833 = add i64 %1829, %1791
  %1834 = add i64 %1765, -1066111689728295684
  %1835 = sub i64 %1834, %1791
  %1836 = sub i64 %1835, -1066111689728295684
  %1837 = sub nsw i64 %1765, %1791
  %1838 = sub i64 0, -7663970908606606333
  %1839 = sub i64 %1838, %1836
  %1840 = add i64 %1839, -7663970908606606333
  %1841 = sub i64 0, %1836
  %1842 = sub i64 0, 1
  %1843 = sub i64 %1840, %1842
  %1844 = add i64 %1840, 1
  %1845 = shl i64 %1836, 1
  %1846 = sub i64 0, 1
  %1847 = sub i64 %1836, %1846
  %1848 = add nsw i64 %1836, 1
  %1849 = load volatile i64*, i64** %19
  %1850 = load i64, i64* %1849, align 8
  %1851 = sub i64 0, %1850
  %1852 = add i64 0, %1851
  %1853 = sub i64 0, %1850
  %1854 = sub i64 0, %1852
  %1855 = sub i64 0, %1847
  %1856 = add i64 %1854, %1855
  %1857 = sub i64 0, %1856
  %1858 = add i64 %1852, %1847
  %1859 = sub i64 %1850, -414643715603299876
  %1860 = sub i64 %1859, %1847
  %1861 = add i64 %1860, -414643715603299876
  %1862 = sub i64 %1850, %1847
  %1863 = mul i64 %1861, %1847
  %1864 = sub i64 0, %1850
  %1865 = sub i64 0, %1847
  %1866 = add i64 %1864, %1865
  %1867 = sub i64 0, %1866
  %1868 = add nsw i64 %1850, %1847
  %1869 = load volatile i64*, i64** %19
  store i64 %1867, i64* %1869, align 8
  store i32 -1450975315, i32* %44
  br label %2013

; <label>:1870:                                   ; preds = %47
  store i32 2022825276, i32* %44
  br label %2013

; <label>:1871:                                   ; preds = %47
  %1872 = load volatile i64*, i64** %12
  %1873 = load i64, i64* %1872, align 8
  %1874 = load volatile i32*, i32** %22
  %1875 = load i32, i32* %1874, align 4
  %1876 = sext i32 %1875 to i64
  %1877 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeA, i64 0, i64 %1876
  store i64 %1873, i64* %1877, align 8
  %1878 = load volatile i64*, i64** %11
  %1879 = load i64, i64* %1878, align 8
  %1880 = load volatile i32*, i32** %22
  %1881 = load i32, i32* %1880, align 4
  %1882 = sext i32 %1881 to i64
  %1883 = getelementptr inbounds [100001 x i64], [100001 x i64]* @maeB, i64 0, i64 %1882
  store i64 %1879, i64* %1883, align 8
  %1884 = load volatile i32*, i32** %14
  %1885 = load i32, i32* %1884, align 4
  %1886 = sext i32 %1885 to i64
  %1887 = load volatile i64*, i64** %21
  %1888 = load i64, i64* %1887, align 8
  %1889 = add i64 %1888, 5990150534448296341
  %1890 = sub i64 %1889, %1886
  %1891 = sub i64 %1890, 5990150534448296341
  %1892 = sub i64 %1888, %1886
  %1893 = mul i64 %1891, %1886
  %1894 = sub i64 %1888, 7296576506073738699
  %1895 = add i64 %1894, %1886
  %1896 = add i64 %1895, 7296576506073738699
  %1897 = add nsw i64 %1888, %1886
  %1898 = load volatile i64*, i64** %21
  store i64 %1896, i64* %1898, align 8
  %1899 = load volatile i64*, i64** %30
  %1900 = load i64, i64* %1899, align 8
  %1901 = load volatile i32*, i32** %14
  %1902 = load i32, i32* %1901, align 4
  %1903 = sext i32 %1902 to i64
  %1904 = sub i64 0, 6024388645954059065
  %1905 = sub i64 %1904, %1900
  %1906 = add i64 %1905, 6024388645954059065
  %1907 = sub i64 0, %1900
  %1908 = sub i64 0, %1903
  %1909 = sub i64 %1906, %1908
  %1910 = add i64 %1906, %1903
  %1911 = sub i64 0, -7136643392083551195
  %1912 = sub i64 %1911, %1900
  %1913 = add i64 %1912, -7136643392083551195
  %1914 = sub i64 0, %1900
  %1915 = add i64 %1913, -5805152826030271096
  %1916 = add i64 %1915, %1903
  %1917 = sub i64 %1916, -5805152826030271096
  %1918 = add i64 %1913, %1903
  %1919 = add i64 0, 8556805088031898569
  %1920 = sub i64 %1919, %1900
  %1921 = sub i64 %1920, 8556805088031898569
  %1922 = sub i64 0, %1900
  %1923 = sub i64 0, %1903
  %1924 = sub i64 %1921, %1923
  %1925 = add i64 %1921, %1903
  %1926 = shl i64 %1900, %1903
  %1927 = sub i64 %1900, -2375119780223971463
  %1928 = sub i64 %1927, %1903
  %1929 = add i64 %1928, -2375119780223971463
  %1930 = sub i64 %1900, %1903
  %1931 = mul i64 %1929, %1903
  %1932 = sub i64 0, %1903
  %1933 = add i64 %1900, %1932
  %1934 = sub i64 %1900, %1903
  %1935 = mul i64 %1933, %1903
  %1936 = add i64 %1900, -5429712481829718452
  %1937 = sub i64 %1936, %1903
  %1938 = sub i64 %1937, -5429712481829718452
  %1939 = sub nsw i64 %1900, %1903
  %1940 = sub i64 %1938, 3777960233048923731
  %1941 = sub i64 %1940, 1
  %1942 = add i64 %1941, 3777960233048923731
  %1943 = sub i64 %1938, 1
  %1944 = mul i64 %1942, 1
  %1945 = shl i64 %1938, 1
  %1946 = sub i64 0, %1938
  %1947 = add i64 0, %1946
  %1948 = sub i64 0, %1938
  %1949 = sub i64 %1947, -8223002414703104869
  %1950 = add i64 %1949, 1
  %1951 = add i64 %1950, -8223002414703104869
  %1952 = add i64 %1947, 1
  %1953 = shl i64 %1938, 1
  %1954 = shl i64 %1938, 1
  %1955 = sub i64 %1938, -7185952104350646639
  %1956 = sub i64 %1955, 1
  %1957 = add i64 %1956, -7185952104350646639
  %1958 = sub nsw i64 %1938, 1
  %1959 = load volatile i64*, i64** %20
  %1960 = load i64, i64* %1959, align 8
  %1961 = add i64 0, -3792549168397290000
  %1962 = sub i64 %1961, %1960
  %1963 = sub i64 %1962, -3792549168397290000
  %1964 = sub i64 0, %1960
  %1965 = sub i64 0, %1957
  %1966 = sub i64 %1963, %1965
  %1967 = add i64 %1963, %1957
  %1968 = shl i64 %1960, %1957
  %1969 = add i64 0, 2514333338794132871
  %1970 = sub i64 %1969, %1960
  %1971 = sub i64 %1970, 2514333338794132871
  %1972 = sub i64 0, %1960
  %1973 = sub i64 0, %1957
  %1974 = sub i64 %1971, %1973
  %1975 = add i64 %1971, %1957
  %1976 = shl i64 %1960, %1957
  %1977 = shl i64 %1960, %1957
  %1978 = add i64 %1960, -4383290510168974402
  %1979 = sub i64 %1978, %1957
  %1980 = sub i64 %1979, -4383290510168974402
  %1981 = sub i64 %1960, %1957
  %1982 = mul i64 %1980, %1957
  %1983 = shl i64 %1960, %1957
  %1984 = add i64 %1960, 4792172583859095663
  %1985 = sub i64 %1984, %1957
  %1986 = sub i64 %1985, 4792172583859095663
  %1987 = sub i64 %1960, %1957
  %1988 = mul i64 %1986, %1957
  %1989 = add i64 %1960, -3917514309519936325
  %1990 = add i64 %1989, %1957
  %1991 = sub i64 %1990, -3917514309519936325
  %1992 = add nsw i64 %1960, %1957
  %1993 = load volatile i64*, i64** %20
  store i64 %1991, i64* %1993, align 8
  %1994 = load volatile i32*, i32** %22
  %1995 = load i32, i32* %1994, align 4
  %1996 = shl i32 %1995, 1
  %1997 = shl i32 %1995, 1
  %1998 = sub i32 %1995, -746389555
  %1999 = add i32 %1998, 1
  %2000 = add i32 %1999, -746389555
  %2001 = add nsw i32 %1995, 1
  %2002 = load volatile i32*, i32** %22
  store i32 %2000, i32* %2002, align 4
  %2003 = sext i32 %2000 to i64
  %2004 = load volatile i64*, i64** %27
  %2005 = load i64, i64* %2004, align 8
  %2006 = icmp sge i64 %2003, %2005
  store i32 135338129, i32* %44
  br label %2013

; <label>:2007:                                   ; preds = %47
  store i32 140786374, i32* %44
  br label %2013

; <label>:2008:                                   ; preds = %47
  %2009 = load volatile i64*, i64** %19
  %2010 = load i64, i64* %2009, align 8
  %2011 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i32 0, i32 0), i64 %2010)
  %2012 = load volatile i32*, i32** %31
  store i32 0, i32* %2012, align 4
  store i32 -1967569987, i32* %44
  br label %2013

; <label>:2013:                                   ; preds = %2008, %2007, %1871, %1870, %1763, %1762, %1648, %1639, %1579, %1490, %1477, %1384, %1348, %1344, %1340, %1313, %1309, %1278, %1262, %1254, %1253, %1238, %1222, %1212, %1209, %1131, %1103, %1102, %1074, %1046, %1045, %1013, %1012, %967, %939, %929, %928, %900, %884, %874, %864, %863, %815, %800, %797, %761, %745, %742, %700, %672, %664, %647, %639, %638, %562, %546, %529, %524, %523, %488, %461, %401, %393, %392, %337, %320, %319, %309, %302, %301, %299, %262, %234, %231, %212, %196, %187, %184, %153, %137, %135, %127, %125, %120, %117, %70, %50, %49
  br label %47
}

declare i32 @scanf(i8*, ...) #1

declare i32 @printf(i8*, ...) #1

; Function Attrs: noinline nounwind uwtable
define linkonce_odr i64 @_ZSt5__gcdIxET_S0_S0_(i64, i64) #2 comdat {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  %5 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %6 = alloca i32
  store i32 -1161830707, i32* %6
  br label %7

; <label>:7:                                      ; preds = %2, %22
  %8 = load i32, i32* %6
  switch i32 %8, label %9 [
    i32 -1161830707, label %10
    i32 858112408, label %14
    i32 1835636658, label %20
  ]

; <label>:9:                                      ; preds = %7
  br label %22

; <label>:10:                                     ; preds = %7
  %11 = load i64, i64* %4, align 8
  %12 = icmp ne i64 %11, 0
  %13 = select i1 %12, i32 858112408, i32 1835636658
  store i32 %13, i32* %6
  br label %22

; <label>:14:                                     ; preds = %7
  %15 = load i64, i64* %3, align 8
  %16 = load i64, i64* %4, align 8
  %17 = srem i64 %15, %16
  store i64 %17, i64* %5, align 8
  %18 = load i64, i64* %4, align 8
  store i64 %18, i64* %3, align 8
  %19 = load i64, i64* %5, align 8
  store i64 %19, i64* %4, align 8
  store i32 -1161830707, i32* %6
  br label %22

; <label>:20:                                     ; preds = %7
  %21 = load i64, i64* %3, align 8
  ret i64 %21

; <label>:22:                                     ; preds = %14, %10, %9
  br label %7
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr i64 @_ZSt3absx(i64) #2 comdat {
  %2 = alloca i64, align 8
  store i64 %0, i64* %2, align 8
  %3 = load i64, i64* %2, align 8
  %4 = sub i64 0, %3
  %5 = add i64 0, %4
  %6 = sub i64 0, %3
  %7 = icmp sge i64 %3, 0
  %8 = select i1 %7, i64 %3, i64 %5
  ret i64 %8
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr dereferenceable(8) i64* @_ZSt3maxIxERKT_S2_S2_(i64* dereferenceable(8), i64* dereferenceable(8)) #2 comdat {
  %3 = alloca i1
  %4 = alloca i64**
  %5 = alloca i64**
  %6 = alloca i64**
  %7 = alloca i1
  %8 = alloca i1
  %9 = load i32, i32* @x.7
  %10 = load i32, i32* @y.8
  %11 = sub i32 0, 1
  %12 = add i32 %9, %11
  %13 = sub i32 %9, 1
  %14 = mul i32 %9, %12
  %15 = urem i32 %14, 2
  %16 = icmp eq i32 %15, 0
  store i1 %16, i1* %8
  %17 = icmp slt i32 %10, 10
  store i1 %17, i1* %7
  %18 = alloca i32
  store i32 827310912, i32* %18
  br label %19

; <label>:19:                                     ; preds = %2, %93
  %20 = load i32, i32* %18
  switch i32 %20, label %21 [
    i32 827310912, label %22
    i32 -23475634, label %42
    i32 -153178459, label %70
    i32 -739264140, label %73
    i32 672946458, label %77
    i32 -69975093, label %81
    i32 -1804027187, label %84
  ]

; <label>:21:                                     ; preds = %19
  br label %93

; <label>:22:                                     ; preds = %19
  %23 = load volatile i1, i1* %8
  %24 = load volatile i1, i1* %7
  %25 = xor i1 %23, true
  %26 = xor i1 %24, true
  %27 = xor i1 false, true
  %28 = and i1 %25, false
  %29 = and i1 %23, %27
  %30 = and i1 %26, false
  %31 = and i1 %24, %27
  %32 = or i1 %28, %29
  %33 = or i1 %30, %31
  %34 = xor i1 %32, %33
  %35 = or i1 %25, %26
  %36 = xor i1 %35, true
  %37 = or i1 false, %27
  %38 = and i1 %36, %37
  %39 = or i1 %34, %38
  %40 = or i1 %23, %24
  %41 = select i1 %39, i32 -23475634, i32 -1804027187
  store i32 %41, i32* %18
  br label %93

; <label>:42:                                     ; preds = %19
  %43 = alloca i64*, align 8
  store i64** %43, i64*** %6
  %44 = alloca i64*, align 8
  store i64** %44, i64*** %5
  %45 = alloca i64*, align 8
  store i64** %45, i64*** %4
  %46 = load volatile i64**, i64*** %5
  store i64* %0, i64** %46, align 8
  %47 = load volatile i64**, i64*** %4
  store i64* %1, i64** %47, align 8
  %48 = load volatile i64**, i64*** %5
  %49 = load i64*, i64** %48, align 8
  %50 = load i64, i64* %49, align 8
  %51 = load volatile i64**, i64*** %4
  %52 = load i64*, i64** %51, align 8
  %53 = load i64, i64* %52, align 8
  %54 = icmp slt i64 %50, %53
  store i1 %54, i1* %3
  %55 = load i32, i32* @x.7
  %56 = load i32, i32* @y.8
  %57 = sub i32 %55, 873817673
  %58 = sub i32 %57, 1
  %59 = add i32 %58, 873817673
  %60 = sub i32 %55, 1
  %61 = mul i32 %55, %59
  %62 = urem i32 %61, 2
  %63 = icmp eq i32 %62, 0
  %64 = icmp slt i32 %56, 10
  %65 = and i1 %63, %64
  %66 = xor i1 %63, %64
  %67 = or i1 %65, %66
  %68 = or i1 %63, %64
  %69 = select i1 %67, i32 -153178459, i32 -1804027187
  store i32 %69, i32* %18
  br label %93

; <label>:70:                                     ; preds = %19
  %71 = load volatile i1, i1* %3
  %72 = select i1 %71, i32 -739264140, i32 672946458
  store i32 %72, i32* %18
  br label %93

; <label>:73:                                     ; preds = %19
  %74 = load volatile i64**, i64*** %4
  %75 = load i64*, i64** %74, align 8
  %76 = load volatile i64**, i64*** %6
  store i64* %75, i64** %76, align 8
  store i32 -69975093, i32* %18
  br label %93

; <label>:77:                                     ; preds = %19
  %78 = load volatile i64**, i64*** %5
  %79 = load i64*, i64** %78, align 8
  %80 = load volatile i64**, i64*** %6
  store i64* %79, i64** %80, align 8
  store i32 -69975093, i32* %18
  br label %93

; <label>:81:                                     ; preds = %19
  %82 = load volatile i64**, i64*** %6
  %83 = load i64*, i64** %82, align 8
  ret i64* %83

; <label>:84:                                     ; preds = %19
  %85 = alloca i64*, align 8
  %86 = alloca i64*, align 8
  %87 = alloca i64*, align 8
  store i64* %0, i64** %86, align 8
  store i64* %1, i64** %87, align 8
  %88 = load i64*, i64** %86, align 8
  %89 = load i64, i64* %88, align 8
  %90 = load i64*, i64** %87, align 8
  %91 = load i64, i64* %90, align 8
  %92 = icmp slt i64 %89, %91
  store i32 -23475634, i32* %18
  br label %93

; <label>:93:                                     ; preds = %84, %77, %73, %70, %42, %22, %21
  br label %19
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8), i64* dereferenceable(8)) #2 comdat {
  %3 = alloca i1
  %4 = alloca i64**
  %5 = alloca i64**
  %6 = alloca i64**
  %7 = alloca i1
  %8 = alloca i1
  %9 = load i32, i32* @x.9
  %10 = load i32, i32* @y.10
  %11 = add i32 %9, 739396279
  %12 = sub i32 %11, 1
  %13 = sub i32 %12, 739396279
  %14 = sub i32 %9, 1
  %15 = mul i32 %9, %13
  %16 = urem i32 %15, 2
  %17 = icmp eq i32 %16, 0
  store i1 %17, i1* %8
  %18 = icmp slt i32 %10, 10
  store i1 %18, i1* %7
  %19 = alloca i32
  store i32 333594043, i32* %19
  br label %20

; <label>:20:                                     ; preds = %2, %154
  %21 = load i32, i32* %19
  switch i32 %21, label %22 [
    i32 333594043, label %23
    i32 202328639, label %43
    i32 -389870821, label %83
    i32 142179162, label %86
    i32 -1809802456, label %90
    i32 -848721312, label %118
    i32 804645944, label %137
    i32 -1039110441, label %138
    i32 -1025928807, label %141
    i32 1473895465, label %150
  ]

; <label>:22:                                     ; preds = %20
  br label %154

; <label>:23:                                     ; preds = %20
  %24 = load volatile i1, i1* %8
  %25 = load volatile i1, i1* %7
  %26 = xor i1 %24, true
  %27 = xor i1 %25, true
  %28 = xor i1 false, true
  %29 = and i1 %26, false
  %30 = and i1 %24, %28
  %31 = and i1 %27, false
  %32 = and i1 %25, %28
  %33 = or i1 %29, %30
  %34 = or i1 %31, %32
  %35 = xor i1 %33, %34
  %36 = or i1 %26, %27
  %37 = xor i1 %36, true
  %38 = or i1 false, %28
  %39 = and i1 %37, %38
  %40 = or i1 %35, %39
  %41 = or i1 %24, %25
  %42 = select i1 %40, i32 202328639, i32 -1025928807
  store i32 %42, i32* %19
  br label %154

; <label>:43:                                     ; preds = %20
  %44 = alloca i64*, align 8
  store i64** %44, i64*** %6
  %45 = alloca i64*, align 8
  store i64** %45, i64*** %5
  %46 = alloca i64*, align 8
  store i64** %46, i64*** %4
  %47 = load volatile i64**, i64*** %5
  store i64* %0, i64** %47, align 8
  %48 = load volatile i64**, i64*** %4
  store i64* %1, i64** %48, align 8
  %49 = load volatile i64**, i64*** %4
  %50 = load i64*, i64** %49, align 8
  %51 = load i64, i64* %50, align 8
  %52 = load volatile i64**, i64*** %5
  %53 = load i64*, i64** %52, align 8
  %54 = load i64, i64* %53, align 8
  %55 = icmp slt i64 %51, %54
  store i1 %55, i1* %3
  %56 = load i32, i32* @x.9
  %57 = load i32, i32* @y.10
  %58 = sub i32 %56, -1026611636
  %59 = sub i32 %58, 1
  %60 = add i32 %59, -1026611636
  %61 = sub i32 %56, 1
  %62 = mul i32 %56, %60
  %63 = urem i32 %62, 2
  %64 = icmp eq i32 %63, 0
  %65 = icmp slt i32 %57, 10
  %66 = xor i1 %64, true
  %67 = xor i1 %65, true
  %68 = xor i1 false, true
  %69 = and i1 %66, false
  %70 = and i1 %64, %68
  %71 = and i1 %67, false
  %72 = and i1 %65, %68
  %73 = or i1 %69, %70
  %74 = or i1 %71, %72
  %75 = xor i1 %73, %74
  %76 = or i1 %66, %67
  %77 = xor i1 %76, true
  %78 = or i1 false, %68
  %79 = and i1 %77, %78
  %80 = or i1 %75, %79
  %81 = or i1 %64, %65
  %82 = select i1 %80, i32 -389870821, i32 -1025928807
  store i32 %82, i32* %19
  br label %154

; <label>:83:                                     ; preds = %20
  %84 = load volatile i1, i1* %3
  %85 = select i1 %84, i32 142179162, i32 -1809802456
  store i32 %85, i32* %19
  br label %154

; <label>:86:                                     ; preds = %20
  %87 = load volatile i64**, i64*** %4
  %88 = load i64*, i64** %87, align 8
  %89 = load volatile i64**, i64*** %6
  store i64* %88, i64** %89, align 8
  store i32 -1039110441, i32* %19
  br label %154

; <label>:90:                                     ; preds = %20
  %91 = load i32, i32* @x.9
  %92 = load i32, i32* @y.10
  %93 = sub i32 %91, 1211954825
  %94 = sub i32 %93, 1
  %95 = add i32 %94, 1211954825
  %96 = sub i32 %91, 1
  %97 = mul i32 %91, %95
  %98 = urem i32 %97, 2
  %99 = icmp eq i32 %98, 0
  %100 = icmp slt i32 %92, 10
  %101 = xor i1 %99, true
  %102 = xor i1 %100, true
  %103 = xor i1 true, true
  %104 = and i1 %101, true
  %105 = and i1 %99, %103
  %106 = and i1 %102, true
  %107 = and i1 %100, %103
  %108 = or i1 %104, %105
  %109 = or i1 %106, %107
  %110 = xor i1 %108, %109
  %111 = or i1 %101, %102
  %112 = xor i1 %111, true
  %113 = or i1 true, %103
  %114 = and i1 %112, %113
  %115 = or i1 %110, %114
  %116 = or i1 %99, %100
  %117 = select i1 %115, i32 -848721312, i32 1473895465
  store i32 %117, i32* %19
  br label %154

; <label>:118:                                    ; preds = %20
  %119 = load volatile i64**, i64*** %5
  %120 = load i64*, i64** %119, align 8
  %121 = load volatile i64**, i64*** %6
  store i64* %120, i64** %121, align 8
  %122 = load i32, i32* @x.9
  %123 = load i32, i32* @y.10
  %124 = add i32 %122, -1394734591
  %125 = sub i32 %124, 1
  %126 = sub i32 %125, -1394734591
  %127 = sub i32 %122, 1
  %128 = mul i32 %122, %126
  %129 = urem i32 %128, 2
  %130 = icmp eq i32 %129, 0
  %131 = icmp slt i32 %123, 10
  %132 = and i1 %130, %131
  %133 = xor i1 %130, %131
  %134 = or i1 %132, %133
  %135 = or i1 %130, %131
  %136 = select i1 %134, i32 804645944, i32 1473895465
  store i32 %136, i32* %19
  br label %154

; <label>:137:                                    ; preds = %20
  store i32 -1039110441, i32* %19
  br label %154

; <label>:138:                                    ; preds = %20
  %139 = load volatile i64**, i64*** %6
  %140 = load i64*, i64** %139, align 8
  ret i64* %140

; <label>:141:                                    ; preds = %20
  %142 = alloca i64*, align 8
  %143 = alloca i64*, align 8
  %144 = alloca i64*, align 8
  store i64* %0, i64** %143, align 8
  store i64* %1, i64** %144, align 8
  %145 = load i64*, i64** %144, align 8
  %146 = load i64, i64* %145, align 8
  %147 = load i64*, i64** %143, align 8
  %148 = load i64, i64* %147, align 8
  %149 = icmp slt i64 %146, %148
  store i32 202328639, i32* %19
  br label %154

; <label>:150:                                    ; preds = %20
  %151 = load volatile i64**, i64*** %5
  %152 = load i64*, i64** %151, align 8
  %153 = load volatile i64**, i64*** %6
  store i64* %152, i64** %153, align 8
  store i32 -848721312, i32* %19
  br label %154

; <label>:154:                                    ; preds = %150, %141, %137, %118, %90, %86, %83, %43, %23, %22
  br label %20
}

attributes #0 = { noinline norecurse uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.ident = !{!0}

!0 = !{!"Obfuscator-LLVM clang version 4.0.1  (based on Obfuscator-LLVM 4.0.1)"}
