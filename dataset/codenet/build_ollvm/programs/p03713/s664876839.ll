; ModuleID = 'Project_CodeNet_C++1400/p03713/s664876839.cpp'
source_filename = "Project_CodeNet_C++1400/p03713/s664876839.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"class.std::ios_base::Init" = type { i8 }
%"class.std::basic_istream" = type { i32 (...)**, i64, %"class.std::basic_ios" }
%"class.std::basic_ios" = type { %"class.std::ios_base", %"class.std::basic_ostream"*, i8, i8, %"class.std::basic_streambuf"*, %"class.std::ctype"*, %"class.std::num_put"*, %"class.std::num_get"* }
%"class.std::ios_base" = type { i32 (...)**, i64, i64, i32, i32, i32, %"struct.std::ios_base::_Callback_list"*, %"struct.std::ios_base::_Words", [8 x %"struct.std::ios_base::_Words"], i32, %"struct.std::ios_base::_Words"*, %"class.std::locale" }
%"struct.std::ios_base::_Callback_list" = type { %"struct.std::ios_base::_Callback_list"*, void (i32, %"class.std::ios_base"*, i32)*, i32, i32 }
%"struct.std::ios_base::_Words" = type { i8*, i64 }
%"class.std::locale" = type { %"class.std::locale::_Impl"* }
%"class.std::locale::_Impl" = type { i32, %"class.std::locale::facet"**, i64, %"class.std::locale::facet"**, i8** }
%"class.std::locale::facet" = type <{ i32 (...)**, i32, [4 x i8] }>
%"class.std::basic_ostream" = type { i32 (...)**, %"class.std::basic_ios" }
%"class.std::basic_streambuf" = type { i32 (...)**, i8*, i8*, i8*, i8*, i8*, i8*, %"class.std::locale" }
%"class.std::ctype" = type <{ %"class.std::locale::facet.base", [4 x i8], %struct.__locale_struct*, i8, [7 x i8], i32*, i32*, i16*, i8, [256 x i8], [256 x i8], i8, [6 x i8] }>
%"class.std::locale::facet.base" = type <{ i32 (...)**, i32 }>
%struct.__locale_struct = type { [13 x %struct.__locale_data*], i16*, i32*, i32*, [13 x i8*] }
%struct.__locale_data = type opaque
%"class.std::num_put" = type { %"class.std::locale::facet.base", [4 x i8] }
%"class.std::num_get" = type { %"class.std::locale::facet.base", [4 x i8] }
%"class.std::initializer_list" = type { i64*, i64 }
%"struct.__gnu_cxx::__ops::_Iter_less_iter" = type { i8 }

$_ZSt4swapIiEvRT_S1_ = comdat any

$_ZSt3minIxERKT_S2_S2_ = comdat any

$_ZSt3maxIxET_St16initializer_listIS0_E = comdat any

$_ZSt3minIxET_St16initializer_listIS0_E = comdat any

$_ZSt4moveIRiEONSt16remove_referenceIT_E4typeEOS2_ = comdat any

$_ZSt11max_elementIPKxET_S2_S2_ = comdat any

$_ZNKSt16initializer_listIxE5beginEv = comdat any

$_ZNKSt16initializer_listIxE3endEv = comdat any

$_ZSt13__max_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_ = comdat any

$_ZN9__gnu_cxx5__ops16__iter_less_iterEv = comdat any

$_ZNK9__gnu_cxx5__ops15_Iter_less_iterclIPKxS4_EEbT_T0_ = comdat any

$_ZNKSt16initializer_listIxE4sizeEv = comdat any

$_ZSt11min_elementIPKxET_S2_S2_ = comdat any

$_ZSt13__min_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_ = comdat any

@_ZStL8__ioinit = internal global %"class.std::ios_base::Init" zeroinitializer, align 1
@__dso_handle = external global i8
@_ZSt3cin = external global %"class.std::basic_istream", align 8
@_ZSt4cout = external global %"class.std::basic_ostream", align 8
@.str = private unnamed_addr constant [5 x i8] c"%d%d\00", align 1
@.str.1 = private unnamed_addr constant [5 x i8] c"%lld\00", align 1
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 65535, void ()* @_GLOBAL__sub_I_s664876839.cpp, i8* null }]
@x = common global i32 0
@y = common global i32 0
@x.2 = common global i32 0
@y.3 = common global i32 0
@x.4 = common global i32 0
@y.5 = common global i32 0
@x.6 = common global i32 0
@y.7 = common global i32 0
@x.8 = common global i32 0
@y.9 = common global i32 0
@x.10 = common global i32 0
@y.11 = common global i32 0
@x.12 = common global i32 0
@y.13 = common global i32 0
@x.14 = common global i32 0
@y.15 = common global i32 0
@x.16 = common global i32 0
@y.17 = common global i32 0
@x.18 = common global i32 0
@y.19 = common global i32 0
@x.20 = common global i32 0
@y.21 = common global i32 0
@x.22 = common global i32 0
@y.23 = common global i32 0
@x.24 = common global i32 0
@y.25 = common global i32 0
@x.26 = common global i32 0
@y.27 = common global i32 0
@x.28 = common global i32 0
@y.29 = common global i32 0
@x.30 = common global i32 0
@y.31 = common global i32 0
@x.32 = common global i32 0
@y.33 = common global i32 0
@x.34 = common global i32 0
@y.35 = common global i32 0
@x.36 = common global i32 0
@y.37 = common global i32 0

; Function Attrs: noinline uwtable
define internal void @__cxx_global_var_init() #0 section ".text.startup" {
  %1 = alloca i1
  %2 = alloca i1
  %3 = load i32, i32* @x
  %4 = load i32, i32* @y
  %5 = sub i32 %3, -1956959757
  %6 = sub i32 %5, 1
  %7 = add i32 %6, -1956959757
  %8 = sub i32 %3, 1
  %9 = mul i32 %3, %7
  %10 = urem i32 %9, 2
  %11 = icmp eq i32 %10, 0
  store i1 %11, i1* %2
  %12 = icmp slt i32 %4, 10
  store i1 %12, i1* %1
  %13 = alloca i32
  store i32 1547623413, i32* %13
  br label %14

; <label>:14:                                     ; preds = %0, %69
  %15 = load i32, i32* %13
  switch i32 %15, label %16 [
    i32 1547623413, label %17
    i32 -936263738, label %37
    i32 803469350, label %66
    i32 -96154350, label %67
  ]

; <label>:16:                                     ; preds = %14
  br label %69

; <label>:17:                                     ; preds = %14
  %18 = load volatile i1, i1* %2
  %19 = load volatile i1, i1* %1
  %20 = xor i1 %18, true
  %21 = xor i1 %19, true
  %22 = xor i1 true, true
  %23 = and i1 %20, true
  %24 = and i1 %18, %22
  %25 = and i1 %21, true
  %26 = and i1 %19, %22
  %27 = or i1 %23, %24
  %28 = or i1 %25, %26
  %29 = xor i1 %27, %28
  %30 = or i1 %20, %21
  %31 = xor i1 %30, true
  %32 = or i1 true, %22
  %33 = and i1 %31, %32
  %34 = or i1 %29, %33
  %35 = or i1 %18, %19
  %36 = select i1 %34, i32 -936263738, i32 -96154350
  store i32 %36, i32* %13
  br label %69

; <label>:37:                                     ; preds = %14
  call void @_ZNSt8ios_base4InitC1Ev(%"class.std::ios_base::Init"* @_ZStL8__ioinit)
  %38 = call i32 @__cxa_atexit(void (i8*)* bitcast (void (%"class.std::ios_base::Init"*)* @_ZNSt8ios_base4InitD1Ev to void (i8*)*), i8* getelementptr inbounds (%"class.std::ios_base::Init", %"class.std::ios_base::Init"* @_ZStL8__ioinit, i32 0, i32 0), i8* @__dso_handle) #3
  %39 = load i32, i32* @x
  %40 = load i32, i32* @y
  %41 = add i32 %39, 1117161006
  %42 = sub i32 %41, 1
  %43 = sub i32 %42, 1117161006
  %44 = sub i32 %39, 1
  %45 = mul i32 %39, %43
  %46 = urem i32 %45, 2
  %47 = icmp eq i32 %46, 0
  %48 = icmp slt i32 %40, 10
  %49 = xor i1 %47, true
  %50 = xor i1 %48, true
  %51 = xor i1 true, true
  %52 = and i1 %49, true
  %53 = and i1 %47, %51
  %54 = and i1 %50, true
  %55 = and i1 %48, %51
  %56 = or i1 %52, %53
  %57 = or i1 %54, %55
  %58 = xor i1 %56, %57
  %59 = or i1 %49, %50
  %60 = xor i1 %59, true
  %61 = or i1 true, %51
  %62 = and i1 %60, %61
  %63 = or i1 %58, %62
  %64 = or i1 %47, %48
  %65 = select i1 %63, i32 803469350, i32 -96154350
  store i32 %65, i32* %13
  br label %69

; <label>:66:                                     ; preds = %14
  ret void

; <label>:67:                                     ; preds = %14
  call void @_ZNSt8ios_base4InitC1Ev(%"class.std::ios_base::Init"* @_ZStL8__ioinit)
  %68 = call i32 @__cxa_atexit(void (i8*)* bitcast (void (%"class.std::ios_base::Init"*)* @_ZNSt8ios_base4InitD1Ev to void (i8*)*), i8* getelementptr inbounds (%"class.std::ios_base::Init", %"class.std::ios_base::Init"* @_ZStL8__ioinit, i32 0, i32 0), i8* @__dso_handle) #3
  store i32 -936263738, i32* %13
  br label %69

; <label>:69:                                     ; preds = %67, %37, %17, %16
  br label %14
}

declare void @_ZNSt8ios_base4InitC1Ev(%"class.std::ios_base::Init"*) unnamed_addr #1

; Function Attrs: nounwind
declare void @_ZNSt8ios_base4InitD1Ev(%"class.std::ios_base::Init"*) unnamed_addr #2

; Function Attrs: nounwind
declare i32 @__cxa_atexit(void (i8*)*, i8*, i8*) #3

; Function Attrs: noinline uwtable
define void @_Z4initv() #0 {
  %1 = alloca i1
  %2 = alloca i1
  %3 = load i32, i32* @x.2
  %4 = load i32, i32* @y.3
  %5 = sub i32 %3, -628072395
  %6 = sub i32 %5, 1
  %7 = add i32 %6, -628072395
  %8 = sub i32 %3, 1
  %9 = mul i32 %3, %7
  %10 = urem i32 %9, 2
  %11 = icmp eq i32 %10, 0
  store i1 %11, i1* %2
  %12 = icmp slt i32 %4, 10
  store i1 %12, i1* %1
  %13 = alloca i32
  store i32 -1094357239, i32* %13
  br label %14

; <label>:14:                                     ; preds = %0, %85
  %15 = load i32, i32* %13
  switch i32 %15, label %16 [
    i32 -1094357239, label %17
    i32 -53817444, label %25
    i32 -1263156737, label %68
    i32 560832784, label %69
  ]

; <label>:16:                                     ; preds = %14
  br label %85

; <label>:17:                                     ; preds = %14
  %18 = load volatile i1, i1* %2
  %19 = load volatile i1, i1* %1
  %20 = and i1 %18, %19
  %21 = xor i1 %18, %19
  %22 = or i1 %20, %21
  %23 = or i1 %18, %19
  %24 = select i1 %22, i32 -53817444, i32 560832784
  store i32 %24, i32* %13
  br label %85

; <label>:25:                                     ; preds = %14
  %26 = call zeroext i1 @_ZNSt8ios_base15sync_with_stdioEb(i1 zeroext false)
  %27 = load i8*, i8** bitcast (%"class.std::basic_istream"* @_ZSt3cin to i8**), align 8
  %28 = getelementptr i8, i8* %27, i64 -24
  %29 = bitcast i8* %28 to i64*
  %30 = load i64, i64* %29, align 8
  %31 = getelementptr inbounds i8, i8* bitcast (%"class.std::basic_istream"* @_ZSt3cin to i8*), i64 %30
  %32 = bitcast i8* %31 to %"class.std::basic_ios"*
  %33 = call %"class.std::basic_ostream"* @_ZNSt9basic_iosIcSt11char_traitsIcEE3tieEPSo(%"class.std::basic_ios"* %32, %"class.std::basic_ostream"* null)
  %34 = load i8*, i8** bitcast (%"class.std::basic_ostream"* @_ZSt4cout to i8**), align 8
  %35 = getelementptr i8, i8* %34, i64 -24
  %36 = bitcast i8* %35 to i64*
  %37 = load i64, i64* %36, align 8
  %38 = getelementptr inbounds i8, i8* bitcast (%"class.std::basic_ostream"* @_ZSt4cout to i8*), i64 %37
  %39 = bitcast i8* %38 to %"class.std::basic_ios"*
  %40 = call %"class.std::basic_ostream"* @_ZNSt9basic_iosIcSt11char_traitsIcEE3tieEPSo(%"class.std::basic_ios"* %39, %"class.std::basic_ostream"* null)
  %41 = load i32, i32* @x.2
  %42 = load i32, i32* @y.3
  %43 = sub i32 %41, -117628939
  %44 = sub i32 %43, 1
  %45 = add i32 %44, -117628939
  %46 = sub i32 %41, 1
  %47 = mul i32 %41, %45
  %48 = urem i32 %47, 2
  %49 = icmp eq i32 %48, 0
  %50 = icmp slt i32 %42, 10
  %51 = xor i1 %49, true
  %52 = xor i1 %50, true
  %53 = xor i1 false, true
  %54 = and i1 %51, false
  %55 = and i1 %49, %53
  %56 = and i1 %52, false
  %57 = and i1 %50, %53
  %58 = or i1 %54, %55
  %59 = or i1 %56, %57
  %60 = xor i1 %58, %59
  %61 = or i1 %51, %52
  %62 = xor i1 %61, true
  %63 = or i1 false, %53
  %64 = and i1 %62, %63
  %65 = or i1 %60, %64
  %66 = or i1 %49, %50
  %67 = select i1 %65, i32 -1263156737, i32 560832784
  store i32 %67, i32* %13
  br label %85

; <label>:68:                                     ; preds = %14
  ret void

; <label>:69:                                     ; preds = %14
  %70 = call zeroext i1 @_ZNSt8ios_base15sync_with_stdioEb(i1 zeroext false)
  %71 = load i8*, i8** bitcast (%"class.std::basic_istream"* @_ZSt3cin to i8**), align 8
  %72 = getelementptr i8, i8* %71, i64 -24
  %73 = bitcast i8* %72 to i64*
  %74 = load i64, i64* %73, align 8
  %75 = getelementptr inbounds i8, i8* bitcast (%"class.std::basic_istream"* @_ZSt3cin to i8*), i64 %74
  %76 = bitcast i8* %75 to %"class.std::basic_ios"*
  %77 = call %"class.std::basic_ostream"* @_ZNSt9basic_iosIcSt11char_traitsIcEE3tieEPSo(%"class.std::basic_ios"* %76, %"class.std::basic_ostream"* null)
  %78 = load i8*, i8** bitcast (%"class.std::basic_ostream"* @_ZSt4cout to i8**), align 8
  %79 = getelementptr i8, i8* %78, i64 -24
  %80 = bitcast i8* %79 to i64*
  %81 = load i64, i64* %80, align 8
  %82 = getelementptr inbounds i8, i8* bitcast (%"class.std::basic_ostream"* @_ZSt4cout to i8*), i64 %81
  %83 = bitcast i8* %82 to %"class.std::basic_ios"*
  %84 = call %"class.std::basic_ostream"* @_ZNSt9basic_iosIcSt11char_traitsIcEE3tieEPSo(%"class.std::basic_ios"* %83, %"class.std::basic_ostream"* null)
  store i32 -53817444, i32* %13
  br label %85

; <label>:85:                                     ; preds = %69, %25, %17, %16
  br label %14
}

declare zeroext i1 @_ZNSt8ios_base15sync_with_stdioEb(i1 zeroext) #1

declare %"class.std::basic_ostream"* @_ZNSt9basic_iosIcSt11char_traitsIcEE3tieEPSo(%"class.std::basic_ios"*, %"class.std::basic_ostream"*) #1

; Function Attrs: noinline uwtable
define void @_Z5solvev() #0 {
  %1 = alloca i1
  %2 = alloca i1
  %3 = alloca i1
  %4 = alloca [3 x i64]*
  %5 = alloca %"class.std::initializer_list"*
  %6 = alloca [3 x i64]*
  %7 = alloca %"class.std::initializer_list"*
  %8 = alloca i64*
  %9 = alloca [3 x i64]*
  %10 = alloca %"class.std::initializer_list"*
  %11 = alloca [3 x i64]*
  %12 = alloca %"class.std::initializer_list"*
  %13 = alloca i64*
  %14 = alloca i64*
  %15 = alloca i64*
  %16 = alloca i64*
  %17 = alloca i64*
  %18 = alloca [3 x i64]*
  %19 = alloca %"class.std::initializer_list"*
  %20 = alloca [3 x i64]*
  %21 = alloca %"class.std::initializer_list"*
  %22 = alloca i64*
  %23 = alloca [3 x i64]*
  %24 = alloca %"class.std::initializer_list"*
  %25 = alloca [3 x i64]*
  %26 = alloca %"class.std::initializer_list"*
  %27 = alloca i64*
  %28 = alloca i64*
  %29 = alloca i64*
  %30 = alloca i64*
  %31 = alloca i64*
  %32 = alloca i64*
  %33 = alloca i32*
  %34 = alloca i32*
  %35 = alloca i1
  %36 = alloca i1
  %37 = load i32, i32* @x.4
  %38 = load i32, i32* @y.5
  %39 = add i32 %37, -1165809265
  %40 = sub i32 %39, 1
  %41 = sub i32 %40, -1165809265
  %42 = sub i32 %37, 1
  %43 = mul i32 %37, %41
  %44 = urem i32 %43, 2
  %45 = icmp eq i32 %44, 0
  store i1 %45, i1* %36
  %46 = icmp slt i32 %38, 10
  store i1 %46, i1* %35
  %47 = alloca i32
  store i32 1449873079, i32* %47
  br label %48

; <label>:48:                                     ; preds = %0, %2176
  %49 = load i32, i32* %47
  switch i32 %49, label %50 [
    i32 1449873079, label %51
    i32 -782625189, label %71
    i32 -271324769, label %137
    i32 966371809, label %140
    i32 1101486532, label %143
    i32 -1177852299, label %146
    i32 -1857806109, label %162
    i32 567999282, label %195
    i32 -763518124, label %198
    i32 1559057016, label %213
    i32 1686053946, label %439
    i32 -1538329707, label %440
    i32 1189556064, label %468
    i32 19128518, label %504
    i32 1686080504, label %505
    i32 -1048698264, label %507
    i32 -816599183, label %534
    i32 327614434, label %556
    i32 934277233, label %559
    i32 -2051328433, label %575
    i32 1388852960, label %789
    i32 -1003994075, label %790
    i32 -1426417184, label %798
    i32 -1213517535, label %802
    i32 -733051996, label %838
    i32 478054414, label %845
    i32 -414993108, label %1484
    i32 175418710, label %1507
    i32 559672549, label %1514
  ]

; <label>:50:                                     ; preds = %48
  br label %2176

; <label>:51:                                     ; preds = %48
  %52 = load volatile i1, i1* %36
  %53 = load volatile i1, i1* %35
  %54 = xor i1 %52, true
  %55 = xor i1 %53, true
  %56 = xor i1 false, true
  %57 = and i1 %54, false
  %58 = and i1 %52, %56
  %59 = and i1 %55, false
  %60 = and i1 %53, %56
  %61 = or i1 %57, %58
  %62 = or i1 %59, %60
  %63 = xor i1 %61, %62
  %64 = or i1 %54, %55
  %65 = xor i1 %64, true
  %66 = or i1 false, %56
  %67 = and i1 %65, %66
  %68 = or i1 %63, %67
  %69 = or i1 %52, %53
  %70 = select i1 %68, i32 -782625189, i32 -1213517535
  store i32 %70, i32* %47
  br label %2176

; <label>:71:                                     ; preds = %48
  %72 = alloca i32, align 4
  store i32* %72, i32** %34
  %73 = alloca i32, align 4
  store i32* %73, i32** %33
  %74 = alloca i64, align 8
  store i64* %74, i64** %32
  %75 = alloca i64, align 8
  store i64* %75, i64** %31
  %76 = alloca i64, align 8
  store i64* %76, i64** %30
  %77 = alloca i64, align 8
  store i64* %77, i64** %29
  %78 = alloca i64, align 8
  store i64* %78, i64** %28
  %79 = alloca i64, align 8
  store i64* %79, i64** %27
  %80 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %80, %"class.std::initializer_list"** %26
  %81 = alloca [3 x i64], align 8
  store [3 x i64]* %81, [3 x i64]** %25
  %82 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %82, %"class.std::initializer_list"** %24
  %83 = alloca [3 x i64], align 8
  store [3 x i64]* %83, [3 x i64]** %23
  %84 = alloca i64, align 8
  store i64* %84, i64** %22
  %85 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %85, %"class.std::initializer_list"** %21
  %86 = alloca [3 x i64], align 8
  store [3 x i64]* %86, [3 x i64]** %20
  %87 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %87, %"class.std::initializer_list"** %19
  %88 = alloca [3 x i64], align 8
  store [3 x i64]* %88, [3 x i64]** %18
  %89 = alloca i64, align 8
  store i64* %89, i64** %17
  %90 = alloca i64, align 8
  store i64* %90, i64** %16
  %91 = alloca i64, align 8
  store i64* %91, i64** %15
  %92 = alloca i64, align 8
  store i64* %92, i64** %14
  %93 = alloca i64, align 8
  store i64* %93, i64** %13
  %94 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %94, %"class.std::initializer_list"** %12
  %95 = alloca [3 x i64], align 8
  store [3 x i64]* %95, [3 x i64]** %11
  %96 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %96, %"class.std::initializer_list"** %10
  %97 = alloca [3 x i64], align 8
  store [3 x i64]* %97, [3 x i64]** %9
  %98 = alloca i64, align 8
  store i64* %98, i64** %8
  %99 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %99, %"class.std::initializer_list"** %7
  %100 = alloca [3 x i64], align 8
  store [3 x i64]* %100, [3 x i64]** %6
  %101 = alloca %"class.std::initializer_list", align 8
  store %"class.std::initializer_list"* %101, %"class.std::initializer_list"** %5
  %102 = alloca [3 x i64], align 8
  store [3 x i64]* %102, [3 x i64]** %4
  %103 = load volatile i32*, i32** %34
  %104 = load volatile i32*, i32** %33
  %105 = call i32 (i8*, ...) @scanf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i32 0, i32 0), i32* %103, i32* %104)
  %106 = load volatile i32*, i32** %34
  %107 = load i32, i32* %106, align 4
  %108 = load volatile i32*, i32** %33
  %109 = load i32, i32* %108, align 4
  %110 = icmp sgt i32 %107, %109
  store i1 %110, i1* %3
  %111 = load i32, i32* @x.4
  %112 = load i32, i32* @y.5
  %113 = sub i32 0, 1
  %114 = add i32 %111, %113
  %115 = sub i32 %111, 1
  %116 = mul i32 %111, %114
  %117 = urem i32 %116, 2
  %118 = icmp eq i32 %117, 0
  %119 = icmp slt i32 %112, 10
  %120 = xor i1 %118, true
  %121 = xor i1 %119, true
  %122 = xor i1 false, true
  %123 = and i1 %120, false
  %124 = and i1 %118, %122
  %125 = and i1 %121, false
  %126 = and i1 %119, %122
  %127 = or i1 %123, %124
  %128 = or i1 %125, %126
  %129 = xor i1 %127, %128
  %130 = or i1 %120, %121
  %131 = xor i1 %130, true
  %132 = or i1 false, %122
  %133 = and i1 %131, %132
  %134 = or i1 %129, %133
  %135 = or i1 %118, %119
  %136 = select i1 %134, i32 -271324769, i32 -1213517535
  store i32 %136, i32* %47
  br label %2176

; <label>:137:                                    ; preds = %48
  %138 = load volatile i1, i1* %3
  %139 = select i1 %138, i32 966371809, i32 1101486532
  store i32 %139, i32* %47
  br label %2176

; <label>:140:                                    ; preds = %48
  %141 = load volatile i32*, i32** %34
  %142 = load volatile i32*, i32** %33
  call void @_ZSt4swapIiEvRT_S1_(i32* dereferenceable(4) %141, i32* dereferenceable(4) %142) #3
  store i32 1101486532, i32* %47
  br label %2176

; <label>:143:                                    ; preds = %48
  %144 = load volatile i64*, i64** %32
  store i64 2000000000000000000, i64* %144, align 8
  %145 = load volatile i64*, i64** %31
  store i64 1, i64* %145, align 8
  store i32 -1177852299, i32* %47
  br label %2176

; <label>:146:                                    ; preds = %48
  %147 = load i32, i32* @x.4
  %148 = load i32, i32* @y.5
  %149 = add i32 %147, 1666045427
  %150 = sub i32 %149, 1
  %151 = sub i32 %150, 1666045427
  %152 = sub i32 %147, 1
  %153 = mul i32 %147, %151
  %154 = urem i32 %153, 2
  %155 = icmp eq i32 %154, 0
  %156 = icmp slt i32 %148, 10
  %157 = and i1 %155, %156
  %158 = xor i1 %155, %156
  %159 = or i1 %157, %158
  %160 = or i1 %155, %156
  %161 = select i1 %159, i32 -1857806109, i32 -733051996
  store i32 %161, i32* %47
  br label %2176

; <label>:162:                                    ; preds = %48
  %163 = load volatile i64*, i64** %31
  %164 = load i64, i64* %163, align 8
  %165 = load volatile i32*, i32** %34
  %166 = load i32, i32* %165, align 4
  %167 = sext i32 %166 to i64
  %168 = icmp slt i64 %164, %167
  store i1 %168, i1* %2
  %169 = load i32, i32* @x.4
  %170 = load i32, i32* @y.5
  %171 = sub i32 0, 1
  %172 = add i32 %169, %171
  %173 = sub i32 %169, 1
  %174 = mul i32 %169, %172
  %175 = urem i32 %174, 2
  %176 = icmp eq i32 %175, 0
  %177 = icmp slt i32 %170, 10
  %178 = xor i1 %176, true
  %179 = xor i1 %177, true
  %180 = xor i1 false, true
  %181 = and i1 %178, false
  %182 = and i1 %176, %180
  %183 = and i1 %179, false
  %184 = and i1 %177, %180
  %185 = or i1 %181, %182
  %186 = or i1 %183, %184
  %187 = xor i1 %185, %186
  %188 = or i1 %178, %179
  %189 = xor i1 %188, true
  %190 = or i1 false, %180
  %191 = and i1 %189, %190
  %192 = or i1 %187, %191
  %193 = or i1 %176, %177
  %194 = select i1 %192, i32 567999282, i32 -733051996
  store i32 %194, i32* %47
  br label %2176

; <label>:195:                                    ; preds = %48
  %196 = load volatile i1, i1* %2
  %197 = select i1 %196, i32 -763518124, i32 1686080504
  store i32 %197, i32* %47
  br label %2176

; <label>:198:                                    ; preds = %48
  %199 = load i32, i32* @x.4
  %200 = load i32, i32* @y.5
  %201 = sub i32 0, 1
  %202 = add i32 %199, %201
  %203 = sub i32 %199, 1
  %204 = mul i32 %199, %202
  %205 = urem i32 %204, 2
  %206 = icmp eq i32 %205, 0
  %207 = icmp slt i32 %200, 10
  %208 = and i1 %206, %207
  %209 = xor i1 %206, %207
  %210 = or i1 %208, %209
  %211 = or i1 %206, %207
  %212 = select i1 %210, i32 1559057016, i32 478054414
  store i32 %212, i32* %47
  br label %2176

; <label>:213:                                    ; preds = %48
  %214 = load volatile i64*, i64** %31
  %215 = load i64, i64* %214, align 8
  %216 = load volatile i32*, i32** %33
  %217 = load i32, i32* %216, align 4
  %218 = sext i32 %217 to i64
  %219 = mul nsw i64 %215, %218
  %220 = load volatile i64*, i64** %30
  store i64 %219, i64* %220, align 8
  %221 = load volatile i32*, i32** %34
  %222 = load i32, i32* %221, align 4
  %223 = sext i32 %222 to i64
  %224 = load volatile i64*, i64** %31
  %225 = load i64, i64* %224, align 8
  %226 = sub i64 %223, -2768891904346661203
  %227 = sub i64 %226, %225
  %228 = add i64 %227, -2768891904346661203
  %229 = sub nsw i64 %223, %225
  %230 = load volatile i32*, i32** %33
  %231 = load i32, i32* %230, align 4
  %232 = sdiv i32 %231, 2
  %233 = sext i32 %232 to i64
  %234 = mul nsw i64 %228, %233
  %235 = load volatile i64*, i64** %29
  store i64 %234, i64* %235, align 8
  %236 = load volatile i32*, i32** %34
  %237 = load i32, i32* %236, align 4
  %238 = sext i32 %237 to i64
  %239 = load volatile i64*, i64** %31
  %240 = load i64, i64* %239, align 8
  %241 = add i64 %238, 4924523048286639361
  %242 = sub i64 %241, %240
  %243 = sub i64 %242, 4924523048286639361
  %244 = sub nsw i64 %238, %240
  %245 = load volatile i32*, i32** %33
  %246 = load i32, i32* %245, align 4
  %247 = sdiv i32 %246, 2
  %248 = load volatile i32*, i32** %33
  %249 = load i32, i32* %248, align 4
  %250 = srem i32 %249, 2
  %251 = sub i32 %247, -795658253
  %252 = add i32 %251, %250
  %253 = add i32 %252, -795658253
  %254 = add nsw i32 %247, %250
  %255 = sext i32 %253 to i64
  %256 = mul nsw i64 %243, %255
  %257 = load volatile i64*, i64** %28
  store i64 %256, i64* %257, align 8
  %258 = load volatile [3 x i64]*, [3 x i64]** %25
  %259 = getelementptr inbounds [3 x i64], [3 x i64]* %258, i64 0, i64 0
  %260 = load volatile i64*, i64** %30
  %261 = load i64, i64* %260, align 8
  store i64 %261, i64* %259, align 8
  %262 = getelementptr inbounds i64, i64* %259, i64 1
  %263 = load volatile i64*, i64** %29
  %264 = load i64, i64* %263, align 8
  store i64 %264, i64* %262, align 8
  %265 = getelementptr inbounds i64, i64* %262, i64 1
  %266 = load volatile i64*, i64** %28
  %267 = load i64, i64* %266, align 8
  store i64 %267, i64* %265, align 8
  %268 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %26
  %269 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %268, i32 0, i32 0
  %270 = load volatile [3 x i64]*, [3 x i64]** %25
  %271 = getelementptr inbounds [3 x i64], [3 x i64]* %270, i64 0, i64 0
  store i64* %271, i64** %269, align 8
  %272 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %26
  %273 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %272, i32 0, i32 1
  store i64 3, i64* %273, align 8
  %274 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %26
  %275 = bitcast %"class.std::initializer_list"* %274 to { i64*, i64 }*
  %276 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %275, i32 0, i32 0
  %277 = load i64*, i64** %276, align 8
  %278 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %275, i32 0, i32 1
  %279 = load i64, i64* %278, align 8
  %280 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %277, i64 %279)
  %281 = load volatile [3 x i64]*, [3 x i64]** %23
  %282 = getelementptr inbounds [3 x i64], [3 x i64]* %281, i64 0, i64 0
  %283 = load volatile i64*, i64** %30
  %284 = load i64, i64* %283, align 8
  store i64 %284, i64* %282, align 8
  %285 = getelementptr inbounds i64, i64* %282, i64 1
  %286 = load volatile i64*, i64** %29
  %287 = load i64, i64* %286, align 8
  store i64 %287, i64* %285, align 8
  %288 = getelementptr inbounds i64, i64* %285, i64 1
  %289 = load volatile i64*, i64** %28
  %290 = load i64, i64* %289, align 8
  store i64 %290, i64* %288, align 8
  %291 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %24
  %292 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %291, i32 0, i32 0
  %293 = load volatile [3 x i64]*, [3 x i64]** %23
  %294 = getelementptr inbounds [3 x i64], [3 x i64]* %293, i64 0, i64 0
  store i64* %294, i64** %292, align 8
  %295 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %24
  %296 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %295, i32 0, i32 1
  store i64 3, i64* %296, align 8
  %297 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %24
  %298 = bitcast %"class.std::initializer_list"* %297 to { i64*, i64 }*
  %299 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %298, i32 0, i32 0
  %300 = load i64*, i64** %299, align 8
  %301 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %298, i32 0, i32 1
  %302 = load i64, i64* %301, align 8
  %303 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %300, i64 %302)
  %304 = sub i64 %280, 8740344479240392487
  %305 = sub i64 %304, %303
  %306 = add i64 %305, 8740344479240392487
  %307 = sub nsw i64 %280, %303
  %308 = load volatile i64*, i64** %27
  store i64 %306, i64* %308, align 8
  %309 = load volatile i64*, i64** %32
  %310 = load volatile i64*, i64** %27
  %311 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %309, i64* dereferenceable(8) %310)
  %312 = load i64, i64* %311, align 8
  %313 = load volatile i64*, i64** %32
  store i64 %312, i64* %313, align 8
  %314 = load volatile i32*, i32** %34
  %315 = load i32, i32* %314, align 4
  %316 = sext i32 %315 to i64
  %317 = load volatile i64*, i64** %31
  %318 = load i64, i64* %317, align 8
  %319 = add i64 %316, -6465726386796427551
  %320 = sub i64 %319, %318
  %321 = sub i64 %320, -6465726386796427551
  %322 = sub nsw i64 %316, %318
  %323 = sdiv i64 %321, 2
  %324 = load volatile i32*, i32** %33
  %325 = load i32, i32* %324, align 4
  %326 = sext i32 %325 to i64
  %327 = mul nsw i64 %323, %326
  %328 = load volatile i64*, i64** %29
  store i64 %327, i64* %328, align 8
  %329 = load volatile i32*, i32** %34
  %330 = load i32, i32* %329, align 4
  %331 = sext i32 %330 to i64
  %332 = load volatile i64*, i64** %31
  %333 = load i64, i64* %332, align 8
  %334 = sub i64 0, %333
  %335 = add i64 %331, %334
  %336 = sub nsw i64 %331, %333
  %337 = sdiv i64 %335, 2
  %338 = load volatile i32*, i32** %34
  %339 = load i32, i32* %338, align 4
  %340 = sext i32 %339 to i64
  %341 = load volatile i64*, i64** %31
  %342 = load i64, i64* %341, align 8
  %343 = add i64 %340, -2550069927807640612
  %344 = sub i64 %343, %342
  %345 = sub i64 %344, -2550069927807640612
  %346 = sub nsw i64 %340, %342
  %347 = srem i64 %345, 2
  %348 = add i64 %337, 324198837922784210
  %349 = add i64 %348, %347
  %350 = sub i64 %349, 324198837922784210
  %351 = add nsw i64 %337, %347
  %352 = load volatile i32*, i32** %33
  %353 = load i32, i32* %352, align 4
  %354 = sext i32 %353 to i64
  %355 = mul nsw i64 %350, %354
  %356 = load volatile i64*, i64** %28
  store i64 %355, i64* %356, align 8
  %357 = load volatile [3 x i64]*, [3 x i64]** %20
  %358 = getelementptr inbounds [3 x i64], [3 x i64]* %357, i64 0, i64 0
  %359 = load volatile i64*, i64** %30
  %360 = load i64, i64* %359, align 8
  store i64 %360, i64* %358, align 8
  %361 = getelementptr inbounds i64, i64* %358, i64 1
  %362 = load volatile i64*, i64** %29
  %363 = load i64, i64* %362, align 8
  store i64 %363, i64* %361, align 8
  %364 = getelementptr inbounds i64, i64* %361, i64 1
  %365 = load volatile i64*, i64** %28
  %366 = load i64, i64* %365, align 8
  store i64 %366, i64* %364, align 8
  %367 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %21
  %368 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %367, i32 0, i32 0
  %369 = load volatile [3 x i64]*, [3 x i64]** %20
  %370 = getelementptr inbounds [3 x i64], [3 x i64]* %369, i64 0, i64 0
  store i64* %370, i64** %368, align 8
  %371 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %21
  %372 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %371, i32 0, i32 1
  store i64 3, i64* %372, align 8
  %373 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %21
  %374 = bitcast %"class.std::initializer_list"* %373 to { i64*, i64 }*
  %375 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %374, i32 0, i32 0
  %376 = load i64*, i64** %375, align 8
  %377 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %374, i32 0, i32 1
  %378 = load i64, i64* %377, align 8
  %379 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %376, i64 %378)
  %380 = load volatile [3 x i64]*, [3 x i64]** %18
  %381 = getelementptr inbounds [3 x i64], [3 x i64]* %380, i64 0, i64 0
  %382 = load volatile i64*, i64** %30
  %383 = load i64, i64* %382, align 8
  store i64 %383, i64* %381, align 8
  %384 = getelementptr inbounds i64, i64* %381, i64 1
  %385 = load volatile i64*, i64** %29
  %386 = load i64, i64* %385, align 8
  store i64 %386, i64* %384, align 8
  %387 = getelementptr inbounds i64, i64* %384, i64 1
  %388 = load volatile i64*, i64** %28
  %389 = load i64, i64* %388, align 8
  store i64 %389, i64* %387, align 8
  %390 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %19
  %391 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %390, i32 0, i32 0
  %392 = load volatile [3 x i64]*, [3 x i64]** %18
  %393 = getelementptr inbounds [3 x i64], [3 x i64]* %392, i64 0, i64 0
  store i64* %393, i64** %391, align 8
  %394 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %19
  %395 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %394, i32 0, i32 1
  store i64 3, i64* %395, align 8
  %396 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %19
  %397 = bitcast %"class.std::initializer_list"* %396 to { i64*, i64 }*
  %398 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %397, i32 0, i32 0
  %399 = load i64*, i64** %398, align 8
  %400 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %397, i32 0, i32 1
  %401 = load i64, i64* %400, align 8
  %402 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %399, i64 %401)
  %403 = sub i64 0, %402
  %404 = add i64 %379, %403
  %405 = sub nsw i64 %379, %402
  %406 = load volatile i64*, i64** %22
  store i64 %404, i64* %406, align 8
  %407 = load volatile i64*, i64** %32
  %408 = load volatile i64*, i64** %22
  %409 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %407, i64* dereferenceable(8) %408)
  %410 = load i64, i64* %409, align 8
  %411 = load volatile i64*, i64** %32
  store i64 %410, i64* %411, align 8
  %412 = load i32, i32* @x.4
  %413 = load i32, i32* @y.5
  %414 = add i32 %412, 1631099552
  %415 = sub i32 %414, 1
  %416 = sub i32 %415, 1631099552
  %417 = sub i32 %412, 1
  %418 = mul i32 %412, %416
  %419 = urem i32 %418, 2
  %420 = icmp eq i32 %419, 0
  %421 = icmp slt i32 %413, 10
  %422 = xor i1 %420, true
  %423 = xor i1 %421, true
  %424 = xor i1 true, true
  %425 = and i1 %422, true
  %426 = and i1 %420, %424
  %427 = and i1 %423, true
  %428 = and i1 %421, %424
  %429 = or i1 %425, %426
  %430 = or i1 %427, %428
  %431 = xor i1 %429, %430
  %432 = or i1 %422, %423
  %433 = xor i1 %432, true
  %434 = or i1 true, %424
  %435 = and i1 %433, %434
  %436 = or i1 %431, %435
  %437 = or i1 %420, %421
  %438 = select i1 %436, i32 1686053946, i32 478054414
  store i32 %438, i32* %47
  br label %2176

; <label>:439:                                    ; preds = %48
  store i32 -1538329707, i32* %47
  br label %2176

; <label>:440:                                    ; preds = %48
  %441 = load i32, i32* @x.4
  %442 = load i32, i32* @y.5
  %443 = add i32 %441, -814434220
  %444 = sub i32 %443, 1
  %445 = sub i32 %444, -814434220
  %446 = sub i32 %441, 1
  %447 = mul i32 %441, %445
  %448 = urem i32 %447, 2
  %449 = icmp eq i32 %448, 0
  %450 = icmp slt i32 %442, 10
  %451 = xor i1 %449, true
  %452 = xor i1 %450, true
  %453 = xor i1 true, true
  %454 = and i1 %451, true
  %455 = and i1 %449, %453
  %456 = and i1 %452, true
  %457 = and i1 %450, %453
  %458 = or i1 %454, %455
  %459 = or i1 %456, %457
  %460 = xor i1 %458, %459
  %461 = or i1 %451, %452
  %462 = xor i1 %461, true
  %463 = or i1 true, %453
  %464 = and i1 %462, %463
  %465 = or i1 %460, %464
  %466 = or i1 %449, %450
  %467 = select i1 %465, i32 1189556064, i32 -414993108
  store i32 %467, i32* %47
  br label %2176

; <label>:468:                                    ; preds = %48
  %469 = load volatile i64*, i64** %31
  %470 = load i64, i64* %469, align 8
  %471 = sub i64 0, %470
  %472 = sub i64 0, 1
  %473 = add i64 %471, %472
  %474 = sub i64 0, %473
  %475 = add nsw i64 %470, 1
  %476 = load volatile i64*, i64** %31
  store i64 %474, i64* %476, align 8
  %477 = load i32, i32* @x.4
  %478 = load i32, i32* @y.5
  %479 = add i32 %477, 1770589969
  %480 = sub i32 %479, 1
  %481 = sub i32 %480, 1770589969
  %482 = sub i32 %477, 1
  %483 = mul i32 %477, %481
  %484 = urem i32 %483, 2
  %485 = icmp eq i32 %484, 0
  %486 = icmp slt i32 %478, 10
  %487 = xor i1 %485, true
  %488 = xor i1 %486, true
  %489 = xor i1 true, true
  %490 = and i1 %487, true
  %491 = and i1 %485, %489
  %492 = and i1 %488, true
  %493 = and i1 %486, %489
  %494 = or i1 %490, %491
  %495 = or i1 %492, %493
  %496 = xor i1 %494, %495
  %497 = or i1 %487, %488
  %498 = xor i1 %497, true
  %499 = or i1 true, %489
  %500 = and i1 %498, %499
  %501 = or i1 %496, %500
  %502 = or i1 %485, %486
  %503 = select i1 %501, i32 19128518, i32 -414993108
  store i32 %503, i32* %47
  br label %2176

; <label>:504:                                    ; preds = %48
  store i32 -1177852299, i32* %47
  br label %2176

; <label>:505:                                    ; preds = %48
  %506 = load volatile i64*, i64** %17
  store i64 1, i64* %506, align 8
  store i32 -1048698264, i32* %47
  br label %2176

; <label>:507:                                    ; preds = %48
  %508 = load i32, i32* @x.4
  %509 = load i32, i32* @y.5
  %510 = sub i32 0, 1
  %511 = add i32 %508, %510
  %512 = sub i32 %508, 1
  %513 = mul i32 %508, %511
  %514 = urem i32 %513, 2
  %515 = icmp eq i32 %514, 0
  %516 = icmp slt i32 %509, 10
  %517 = xor i1 %515, true
  %518 = xor i1 %516, true
  %519 = xor i1 false, true
  %520 = and i1 %517, false
  %521 = and i1 %515, %519
  %522 = and i1 %518, false
  %523 = and i1 %516, %519
  %524 = or i1 %520, %521
  %525 = or i1 %522, %523
  %526 = xor i1 %524, %525
  %527 = or i1 %517, %518
  %528 = xor i1 %527, true
  %529 = or i1 false, %519
  %530 = and i1 %528, %529
  %531 = or i1 %526, %530
  %532 = or i1 %515, %516
  %533 = select i1 %531, i32 -816599183, i32 175418710
  store i32 %533, i32* %47
  br label %2176

; <label>:534:                                    ; preds = %48
  %535 = load volatile i64*, i64** %17
  %536 = load i64, i64* %535, align 8
  %537 = load volatile i32*, i32** %33
  %538 = load i32, i32* %537, align 4
  %539 = sext i32 %538 to i64
  %540 = icmp slt i64 %536, %539
  store i1 %540, i1* %1
  %541 = load i32, i32* @x.4
  %542 = load i32, i32* @y.5
  %543 = sub i32 %541, 307999201
  %544 = sub i32 %543, 1
  %545 = add i32 %544, 307999201
  %546 = sub i32 %541, 1
  %547 = mul i32 %541, %545
  %548 = urem i32 %547, 2
  %549 = icmp eq i32 %548, 0
  %550 = icmp slt i32 %542, 10
  %551 = and i1 %549, %550
  %552 = xor i1 %549, %550
  %553 = or i1 %551, %552
  %554 = or i1 %549, %550
  %555 = select i1 %553, i32 327614434, i32 175418710
  store i32 %555, i32* %47
  br label %2176

; <label>:556:                                    ; preds = %48
  %557 = load volatile i1, i1* %1
  %558 = select i1 %557, i32 934277233, i32 -1426417184
  store i32 %558, i32* %47
  br label %2176

; <label>:559:                                    ; preds = %48
  %560 = load i32, i32* @x.4
  %561 = load i32, i32* @y.5
  %562 = sub i32 %560, -1627532789
  %563 = sub i32 %562, 1
  %564 = add i32 %563, -1627532789
  %565 = sub i32 %560, 1
  %566 = mul i32 %560, %564
  %567 = urem i32 %566, 2
  %568 = icmp eq i32 %567, 0
  %569 = icmp slt i32 %561, 10
  %570 = and i1 %568, %569
  %571 = xor i1 %568, %569
  %572 = or i1 %570, %571
  %573 = or i1 %568, %569
  %574 = select i1 %572, i32 -2051328433, i32 559672549
  store i32 %574, i32* %47
  br label %2176

; <label>:575:                                    ; preds = %48
  %576 = load volatile i64*, i64** %17
  %577 = load i64, i64* %576, align 8
  %578 = load volatile i32*, i32** %34
  %579 = load i32, i32* %578, align 4
  %580 = sext i32 %579 to i64
  %581 = mul nsw i64 %577, %580
  %582 = load volatile i64*, i64** %16
  store i64 %581, i64* %582, align 8
  %583 = load volatile i32*, i32** %33
  %584 = load i32, i32* %583, align 4
  %585 = sext i32 %584 to i64
  %586 = load volatile i64*, i64** %17
  %587 = load i64, i64* %586, align 8
  %588 = sub i64 0, %587
  %589 = add i64 %585, %588
  %590 = sub nsw i64 %585, %587
  %591 = load volatile i32*, i32** %34
  %592 = load i32, i32* %591, align 4
  %593 = sdiv i32 %592, 2
  %594 = sext i32 %593 to i64
  %595 = mul nsw i64 %589, %594
  %596 = load volatile i64*, i64** %15
  store i64 %595, i64* %596, align 8
  %597 = load volatile i32*, i32** %33
  %598 = load i32, i32* %597, align 4
  %599 = sext i32 %598 to i64
  %600 = load volatile i64*, i64** %17
  %601 = load i64, i64* %600, align 8
  %602 = add i64 %599, -7691136547776869074
  %603 = sub i64 %602, %601
  %604 = sub i64 %603, -7691136547776869074
  %605 = sub nsw i64 %599, %601
  %606 = load volatile i32*, i32** %34
  %607 = load i32, i32* %606, align 4
  %608 = sdiv i32 %607, 2
  %609 = load volatile i32*, i32** %34
  %610 = load i32, i32* %609, align 4
  %611 = srem i32 %610, 2
  %612 = sub i32 0, %608
  %613 = sub i32 0, %611
  %614 = add i32 %612, %613
  %615 = sub i32 0, %614
  %616 = add nsw i32 %608, %611
  %617 = sext i32 %615 to i64
  %618 = mul nsw i64 %604, %617
  %619 = load volatile i64*, i64** %14
  store i64 %618, i64* %619, align 8
  %620 = load volatile [3 x i64]*, [3 x i64]** %11
  %621 = getelementptr inbounds [3 x i64], [3 x i64]* %620, i64 0, i64 0
  %622 = load volatile i64*, i64** %16
  %623 = load i64, i64* %622, align 8
  store i64 %623, i64* %621, align 8
  %624 = getelementptr inbounds i64, i64* %621, i64 1
  %625 = load volatile i64*, i64** %15
  %626 = load i64, i64* %625, align 8
  store i64 %626, i64* %624, align 8
  %627 = getelementptr inbounds i64, i64* %624, i64 1
  %628 = load volatile i64*, i64** %14
  %629 = load i64, i64* %628, align 8
  store i64 %629, i64* %627, align 8
  %630 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %12
  %631 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %630, i32 0, i32 0
  %632 = load volatile [3 x i64]*, [3 x i64]** %11
  %633 = getelementptr inbounds [3 x i64], [3 x i64]* %632, i64 0, i64 0
  store i64* %633, i64** %631, align 8
  %634 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %12
  %635 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %634, i32 0, i32 1
  store i64 3, i64* %635, align 8
  %636 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %12
  %637 = bitcast %"class.std::initializer_list"* %636 to { i64*, i64 }*
  %638 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %637, i32 0, i32 0
  %639 = load i64*, i64** %638, align 8
  %640 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %637, i32 0, i32 1
  %641 = load i64, i64* %640, align 8
  %642 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %639, i64 %641)
  %643 = load volatile [3 x i64]*, [3 x i64]** %9
  %644 = getelementptr inbounds [3 x i64], [3 x i64]* %643, i64 0, i64 0
  %645 = load volatile i64*, i64** %16
  %646 = load i64, i64* %645, align 8
  store i64 %646, i64* %644, align 8
  %647 = getelementptr inbounds i64, i64* %644, i64 1
  %648 = load volatile i64*, i64** %15
  %649 = load i64, i64* %648, align 8
  store i64 %649, i64* %647, align 8
  %650 = getelementptr inbounds i64, i64* %647, i64 1
  %651 = load volatile i64*, i64** %14
  %652 = load i64, i64* %651, align 8
  store i64 %652, i64* %650, align 8
  %653 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %10
  %654 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %653, i32 0, i32 0
  %655 = load volatile [3 x i64]*, [3 x i64]** %9
  %656 = getelementptr inbounds [3 x i64], [3 x i64]* %655, i64 0, i64 0
  store i64* %656, i64** %654, align 8
  %657 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %10
  %658 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %657, i32 0, i32 1
  store i64 3, i64* %658, align 8
  %659 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %10
  %660 = bitcast %"class.std::initializer_list"* %659 to { i64*, i64 }*
  %661 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %660, i32 0, i32 0
  %662 = load i64*, i64** %661, align 8
  %663 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %660, i32 0, i32 1
  %664 = load i64, i64* %663, align 8
  %665 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %662, i64 %664)
  %666 = sub i64 %642, -2157967251323778047
  %667 = sub i64 %666, %665
  %668 = add i64 %667, -2157967251323778047
  %669 = sub nsw i64 %642, %665
  %670 = load volatile i64*, i64** %13
  store i64 %668, i64* %670, align 8
  %671 = load volatile i64*, i64** %32
  %672 = load volatile i64*, i64** %13
  %673 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %671, i64* dereferenceable(8) %672)
  %674 = load i64, i64* %673, align 8
  %675 = load volatile i64*, i64** %32
  store i64 %674, i64* %675, align 8
  %676 = load volatile i32*, i32** %33
  %677 = load i32, i32* %676, align 4
  %678 = sext i32 %677 to i64
  %679 = load volatile i64*, i64** %17
  %680 = load i64, i64* %679, align 8
  %681 = sub i64 %678, -1042029697104691922
  %682 = sub i64 %681, %680
  %683 = add i64 %682, -1042029697104691922
  %684 = sub nsw i64 %678, %680
  %685 = sdiv i64 %683, 2
  %686 = load volatile i32*, i32** %34
  %687 = load i32, i32* %686, align 4
  %688 = sext i32 %687 to i64
  %689 = mul nsw i64 %685, %688
  %690 = load volatile i64*, i64** %15
  store i64 %689, i64* %690, align 8
  %691 = load volatile i32*, i32** %33
  %692 = load i32, i32* %691, align 4
  %693 = sext i32 %692 to i64
  %694 = load volatile i64*, i64** %17
  %695 = load i64, i64* %694, align 8
  %696 = sub i64 %693, -7271211769650667634
  %697 = sub i64 %696, %695
  %698 = add i64 %697, -7271211769650667634
  %699 = sub nsw i64 %693, %695
  %700 = sdiv i64 %698, 2
  %701 = load volatile i32*, i32** %33
  %702 = load i32, i32* %701, align 4
  %703 = sext i32 %702 to i64
  %704 = load volatile i64*, i64** %17
  %705 = load i64, i64* %704, align 8
  %706 = sub i64 0, %705
  %707 = add i64 %703, %706
  %708 = sub nsw i64 %703, %705
  %709 = srem i64 %707, 2
  %710 = sub i64 %700, 6428517756111289427
  %711 = add i64 %710, %709
  %712 = add i64 %711, 6428517756111289427
  %713 = add nsw i64 %700, %709
  %714 = load volatile i32*, i32** %34
  %715 = load i32, i32* %714, align 4
  %716 = sext i32 %715 to i64
  %717 = mul nsw i64 %712, %716
  %718 = load volatile i64*, i64** %14
  store i64 %717, i64* %718, align 8
  %719 = load volatile [3 x i64]*, [3 x i64]** %6
  %720 = getelementptr inbounds [3 x i64], [3 x i64]* %719, i64 0, i64 0
  %721 = load volatile i64*, i64** %16
  %722 = load i64, i64* %721, align 8
  store i64 %722, i64* %720, align 8
  %723 = getelementptr inbounds i64, i64* %720, i64 1
  %724 = load volatile i64*, i64** %15
  %725 = load i64, i64* %724, align 8
  store i64 %725, i64* %723, align 8
  %726 = getelementptr inbounds i64, i64* %723, i64 1
  %727 = load volatile i64*, i64** %14
  %728 = load i64, i64* %727, align 8
  store i64 %728, i64* %726, align 8
  %729 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %7
  %730 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %729, i32 0, i32 0
  %731 = load volatile [3 x i64]*, [3 x i64]** %6
  %732 = getelementptr inbounds [3 x i64], [3 x i64]* %731, i64 0, i64 0
  store i64* %732, i64** %730, align 8
  %733 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %7
  %734 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %733, i32 0, i32 1
  store i64 3, i64* %734, align 8
  %735 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %7
  %736 = bitcast %"class.std::initializer_list"* %735 to { i64*, i64 }*
  %737 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %736, i32 0, i32 0
  %738 = load i64*, i64** %737, align 8
  %739 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %736, i32 0, i32 1
  %740 = load i64, i64* %739, align 8
  %741 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %738, i64 %740)
  %742 = load volatile [3 x i64]*, [3 x i64]** %4
  %743 = getelementptr inbounds [3 x i64], [3 x i64]* %742, i64 0, i64 0
  %744 = load volatile i64*, i64** %16
  %745 = load i64, i64* %744, align 8
  store i64 %745, i64* %743, align 8
  %746 = getelementptr inbounds i64, i64* %743, i64 1
  %747 = load volatile i64*, i64** %15
  %748 = load i64, i64* %747, align 8
  store i64 %748, i64* %746, align 8
  %749 = getelementptr inbounds i64, i64* %746, i64 1
  %750 = load volatile i64*, i64** %14
  %751 = load i64, i64* %750, align 8
  store i64 %751, i64* %749, align 8
  %752 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %5
  %753 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %752, i32 0, i32 0
  %754 = load volatile [3 x i64]*, [3 x i64]** %4
  %755 = getelementptr inbounds [3 x i64], [3 x i64]* %754, i64 0, i64 0
  store i64* %755, i64** %753, align 8
  %756 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %5
  %757 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %756, i32 0, i32 1
  store i64 3, i64* %757, align 8
  %758 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %5
  %759 = bitcast %"class.std::initializer_list"* %758 to { i64*, i64 }*
  %760 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %759, i32 0, i32 0
  %761 = load i64*, i64** %760, align 8
  %762 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %759, i32 0, i32 1
  %763 = load i64, i64* %762, align 8
  %764 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %761, i64 %763)
  %765 = sub i64 0, %764
  %766 = add i64 %741, %765
  %767 = sub nsw i64 %741, %764
  %768 = load volatile i64*, i64** %8
  store i64 %766, i64* %768, align 8
  %769 = load volatile i64*, i64** %32
  %770 = load volatile i64*, i64** %8
  %771 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %769, i64* dereferenceable(8) %770)
  %772 = load i64, i64* %771, align 8
  %773 = load volatile i64*, i64** %32
  store i64 %772, i64* %773, align 8
  %774 = load i32, i32* @x.4
  %775 = load i32, i32* @y.5
  %776 = add i32 %774, 8020351
  %777 = sub i32 %776, 1
  %778 = sub i32 %777, 8020351
  %779 = sub i32 %774, 1
  %780 = mul i32 %774, %778
  %781 = urem i32 %780, 2
  %782 = icmp eq i32 %781, 0
  %783 = icmp slt i32 %775, 10
  %784 = and i1 %782, %783
  %785 = xor i1 %782, %783
  %786 = or i1 %784, %785
  %787 = or i1 %782, %783
  %788 = select i1 %786, i32 1388852960, i32 559672549
  store i32 %788, i32* %47
  br label %2176

; <label>:789:                                    ; preds = %48
  store i32 -1003994075, i32* %47
  br label %2176

; <label>:790:                                    ; preds = %48
  %791 = load volatile i64*, i64** %17
  %792 = load i64, i64* %791, align 8
  %793 = sub i64 %792, 2825064602668476
  %794 = add i64 %793, 1
  %795 = add i64 %794, 2825064602668476
  %796 = add nsw i64 %792, 1
  %797 = load volatile i64*, i64** %17
  store i64 %795, i64* %797, align 8
  store i32 -1048698264, i32* %47
  br label %2176

; <label>:798:                                    ; preds = %48
  %799 = load volatile i64*, i64** %32
  %800 = load i64, i64* %799, align 8
  %801 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.1, i32 0, i32 0), i64 %800)
  ret void

; <label>:802:                                    ; preds = %48
  %803 = alloca i32, align 4
  %804 = alloca i32, align 4
  %805 = alloca i64, align 8
  %806 = alloca i64, align 8
  %807 = alloca i64, align 8
  %808 = alloca i64, align 8
  %809 = alloca i64, align 8
  %810 = alloca i64, align 8
  %811 = alloca %"class.std::initializer_list", align 8
  %812 = alloca [3 x i64], align 8
  %813 = alloca %"class.std::initializer_list", align 8
  %814 = alloca [3 x i64], align 8
  %815 = alloca i64, align 8
  %816 = alloca %"class.std::initializer_list", align 8
  %817 = alloca [3 x i64], align 8
  %818 = alloca %"class.std::initializer_list", align 8
  %819 = alloca [3 x i64], align 8
  %820 = alloca i64, align 8
  %821 = alloca i64, align 8
  %822 = alloca i64, align 8
  %823 = alloca i64, align 8
  %824 = alloca i64, align 8
  %825 = alloca %"class.std::initializer_list", align 8
  %826 = alloca [3 x i64], align 8
  %827 = alloca %"class.std::initializer_list", align 8
  %828 = alloca [3 x i64], align 8
  %829 = alloca i64, align 8
  %830 = alloca %"class.std::initializer_list", align 8
  %831 = alloca [3 x i64], align 8
  %832 = alloca %"class.std::initializer_list", align 8
  %833 = alloca [3 x i64], align 8
  %834 = call i32 (i8*, ...) @scanf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i32 0, i32 0), i32* %803, i32* %804)
  %835 = load i32, i32* %803, align 4
  %836 = load i32, i32* %804, align 4
  %837 = icmp sgt i32 %835, %836
  store i32 -782625189, i32* %47
  br label %2176

; <label>:838:                                    ; preds = %48
  %839 = load volatile i64*, i64** %31
  %840 = load i64, i64* %839, align 8
  %841 = load volatile i32*, i32** %34
  %842 = load i32, i32* %841, align 4
  %843 = sext i32 %842 to i64
  %844 = icmp slt i64 %840, %843
  store i32 -1857806109, i32* %47
  br label %2176

; <label>:845:                                    ; preds = %48
  %846 = load volatile i64*, i64** %31
  %847 = load i64, i64* %846, align 8
  %848 = load volatile i32*, i32** %33
  %849 = load i32, i32* %848, align 4
  %850 = sext i32 %849 to i64
  %851 = sub i64 0, -6669012502381442800
  %852 = sub i64 %851, %847
  %853 = add i64 %852, -6669012502381442800
  %854 = sub i64 0, %847
  %855 = sub i64 0, %853
  %856 = sub i64 0, %850
  %857 = add i64 %855, %856
  %858 = sub i64 0, %857
  %859 = add i64 %853, %850
  %860 = sub i64 %847, 984925067411752539
  %861 = sub i64 %860, %850
  %862 = add i64 %861, 984925067411752539
  %863 = sub i64 %847, %850
  %864 = mul i64 %862, %850
  %865 = add i64 0, 3811450148318506847
  %866 = sub i64 %865, %847
  %867 = sub i64 %866, 3811450148318506847
  %868 = sub i64 0, %847
  %869 = sub i64 0, %850
  %870 = sub i64 %867, %869
  %871 = add i64 %867, %850
  %872 = shl i64 %847, %850
  %873 = shl i64 %847, %850
  %874 = add i64 %847, -8177757918395142124
  %875 = sub i64 %874, %850
  %876 = sub i64 %875, -8177757918395142124
  %877 = sub i64 %847, %850
  %878 = mul i64 %876, %850
  %879 = mul nsw i64 %847, %850
  %880 = load volatile i64*, i64** %30
  store i64 %879, i64* %880, align 8
  %881 = load volatile i32*, i32** %34
  %882 = load i32, i32* %881, align 4
  %883 = sext i32 %882 to i64
  %884 = load volatile i64*, i64** %31
  %885 = load i64, i64* %884, align 8
  %886 = add i64 %883, 279518756912160410
  %887 = sub i64 %886, %885
  %888 = sub i64 %887, 279518756912160410
  %889 = sub i64 %883, %885
  %890 = mul i64 %888, %885
  %891 = shl i64 %883, %885
  %892 = add i64 %883, -2581243925429644343
  %893 = sub i64 %892, %885
  %894 = sub i64 %893, -2581243925429644343
  %895 = sub i64 %883, %885
  %896 = mul i64 %894, %885
  %897 = shl i64 %883, %885
  %898 = shl i64 %883, %885
  %899 = sub i64 0, -2774692776497187714
  %900 = sub i64 %899, %883
  %901 = add i64 %900, -2774692776497187714
  %902 = sub i64 0, %883
  %903 = sub i64 %901, 5904420324848404140
  %904 = add i64 %903, %885
  %905 = add i64 %904, 5904420324848404140
  %906 = add i64 %901, %885
  %907 = sub i64 0, %883
  %908 = add i64 0, %907
  %909 = sub i64 0, %883
  %910 = sub i64 0, %885
  %911 = sub i64 %908, %910
  %912 = add i64 %908, %885
  %913 = sub i64 %883, -763302848299966676
  %914 = sub i64 %913, %885
  %915 = add i64 %914, -763302848299966676
  %916 = sub nsw i64 %883, %885
  %917 = load volatile i32*, i32** %33
  %918 = load i32, i32* %917, align 4
  %919 = sub i32 0, 557455604
  %920 = sub i32 %919, %918
  %921 = add i32 %920, 557455604
  %922 = sub i32 0, %918
  %923 = add i32 %921, 219558743
  %924 = add i32 %923, 2
  %925 = sub i32 %924, 219558743
  %926 = add i32 %921, 2
  %927 = sdiv i32 %918, 2
  %928 = sext i32 %927 to i64
  %929 = shl i64 %915, %928
  %930 = shl i64 %915, %928
  %931 = sub i64 0, -7177472240961827713
  %932 = sub i64 %931, %915
  %933 = add i64 %932, -7177472240961827713
  %934 = sub i64 0, %915
  %935 = sub i64 %933, 3332879044206428759
  %936 = add i64 %935, %928
  %937 = add i64 %936, 3332879044206428759
  %938 = add i64 %933, %928
  %939 = add i64 0, -5357543133908607567
  %940 = sub i64 %939, %915
  %941 = sub i64 %940, -5357543133908607567
  %942 = sub i64 0, %915
  %943 = add i64 %941, 5656935493159541087
  %944 = add i64 %943, %928
  %945 = sub i64 %944, 5656935493159541087
  %946 = add i64 %941, %928
  %947 = sub i64 0, %928
  %948 = add i64 %915, %947
  %949 = sub i64 %915, %928
  %950 = mul i64 %948, %928
  %951 = add i64 %915, 7945053217217108982
  %952 = sub i64 %951, %928
  %953 = sub i64 %952, 7945053217217108982
  %954 = sub i64 %915, %928
  %955 = mul i64 %953, %928
  %956 = mul nsw i64 %915, %928
  %957 = load volatile i64*, i64** %29
  store i64 %956, i64* %957, align 8
  %958 = load volatile i32*, i32** %34
  %959 = load i32, i32* %958, align 4
  %960 = sext i32 %959 to i64
  %961 = load volatile i64*, i64** %31
  %962 = load i64, i64* %961, align 8
  %963 = sub i64 0, 3488091521167650844
  %964 = sub i64 %963, %960
  %965 = add i64 %964, 3488091521167650844
  %966 = sub i64 0, %960
  %967 = sub i64 0, %962
  %968 = sub i64 %965, %967
  %969 = add i64 %965, %962
  %970 = sub i64 0, %960
  %971 = add i64 0, %970
  %972 = sub i64 0, %960
  %973 = sub i64 %971, 2041333638825229279
  %974 = add i64 %973, %962
  %975 = add i64 %974, 2041333638825229279
  %976 = add i64 %971, %962
  %977 = shl i64 %960, %962
  %978 = shl i64 %960, %962
  %979 = shl i64 %960, %962
  %980 = add i64 0, -8566570572675934210
  %981 = sub i64 %980, %960
  %982 = sub i64 %981, -8566570572675934210
  %983 = sub i64 0, %960
  %984 = sub i64 %982, 4413975544424759045
  %985 = add i64 %984, %962
  %986 = add i64 %985, 4413975544424759045
  %987 = add i64 %982, %962
  %988 = sub i64 0, %962
  %989 = add i64 %960, %988
  %990 = sub nsw i64 %960, %962
  %991 = load volatile i32*, i32** %33
  %992 = load i32, i32* %991, align 4
  %993 = add i32 0, 840487143
  %994 = sub i32 %993, %992
  %995 = sub i32 %994, 840487143
  %996 = sub i32 0, %992
  %997 = sub i32 0, %995
  %998 = sub i32 0, 2
  %999 = add i32 %997, %998
  %1000 = sub i32 0, %999
  %1001 = add i32 %995, 2
  %1002 = add i32 0, 2053584379
  %1003 = sub i32 %1002, %992
  %1004 = sub i32 %1003, 2053584379
  %1005 = sub i32 0, %992
  %1006 = sub i32 %1004, -1513507387
  %1007 = add i32 %1006, 2
  %1008 = add i32 %1007, -1513507387
  %1009 = add i32 %1004, 2
  %1010 = sdiv i32 %992, 2
  %1011 = load volatile i32*, i32** %33
  %1012 = load i32, i32* %1011, align 4
  %1013 = shl i32 %1012, 2
  %1014 = shl i32 %1012, 2
  %1015 = sub i32 %1012, 1329450712
  %1016 = sub i32 %1015, 2
  %1017 = add i32 %1016, 1329450712
  %1018 = sub i32 %1012, 2
  %1019 = mul i32 %1017, 2
  %1020 = sub i32 0, 2
  %1021 = add i32 %1012, %1020
  %1022 = sub i32 %1012, 2
  %1023 = mul i32 %1021, 2
  %1024 = shl i32 %1012, 2
  %1025 = sub i32 0, 219489809
  %1026 = sub i32 %1025, %1012
  %1027 = add i32 %1026, 219489809
  %1028 = sub i32 0, %1012
  %1029 = add i32 %1027, 811077340
  %1030 = add i32 %1029, 2
  %1031 = sub i32 %1030, 811077340
  %1032 = add i32 %1027, 2
  %1033 = shl i32 %1012, 2
  %1034 = srem i32 %1012, 2
  %1035 = sub i32 0, %1010
  %1036 = add i32 0, %1035
  %1037 = sub i32 0, %1010
  %1038 = add i32 %1036, 1049756053
  %1039 = add i32 %1038, %1034
  %1040 = sub i32 %1039, 1049756053
  %1041 = add i32 %1036, %1034
  %1042 = shl i32 %1010, %1034
  %1043 = sub i32 0, %1010
  %1044 = add i32 0, %1043
  %1045 = sub i32 0, %1010
  %1046 = add i32 %1044, 1807038688
  %1047 = add i32 %1046, %1034
  %1048 = sub i32 %1047, 1807038688
  %1049 = add i32 %1044, %1034
  %1050 = sub i32 0, -556627399
  %1051 = sub i32 %1050, %1010
  %1052 = add i32 %1051, -556627399
  %1053 = sub i32 0, %1010
  %1054 = sub i32 %1052, -1579474031
  %1055 = add i32 %1054, %1034
  %1056 = add i32 %1055, -1579474031
  %1057 = add i32 %1052, %1034
  %1058 = add i32 %1010, -1713435365
  %1059 = sub i32 %1058, %1034
  %1060 = sub i32 %1059, -1713435365
  %1061 = sub i32 %1010, %1034
  %1062 = mul i32 %1060, %1034
  %1063 = sub i32 0, %1010
  %1064 = add i32 0, %1063
  %1065 = sub i32 0, %1010
  %1066 = sub i32 0, %1064
  %1067 = sub i32 0, %1034
  %1068 = add i32 %1066, %1067
  %1069 = sub i32 0, %1068
  %1070 = add i32 %1064, %1034
  %1071 = sub i32 0, %1010
  %1072 = sub i32 0, %1034
  %1073 = add i32 %1071, %1072
  %1074 = sub i32 0, %1073
  %1075 = add nsw i32 %1010, %1034
  %1076 = sext i32 %1074 to i64
  %1077 = add i64 0, 5771778764487400837
  %1078 = sub i64 %1077, %989
  %1079 = sub i64 %1078, 5771778764487400837
  %1080 = sub i64 0, %989
  %1081 = add i64 %1079, -8865966187216251393
  %1082 = add i64 %1081, %1076
  %1083 = sub i64 %1082, -8865966187216251393
  %1084 = add i64 %1079, %1076
  %1085 = add i64 0, -4551593661090363326
  %1086 = sub i64 %1085, %989
  %1087 = sub i64 %1086, -4551593661090363326
  %1088 = sub i64 0, %989
  %1089 = add i64 %1087, -4895490348959072582
  %1090 = add i64 %1089, %1076
  %1091 = sub i64 %1090, -4895490348959072582
  %1092 = add i64 %1087, %1076
  %1093 = add i64 %989, 303776982433314174
  %1094 = sub i64 %1093, %1076
  %1095 = sub i64 %1094, 303776982433314174
  %1096 = sub i64 %989, %1076
  %1097 = mul i64 %1095, %1076
  %1098 = add i64 %989, 2074558681545020267
  %1099 = sub i64 %1098, %1076
  %1100 = sub i64 %1099, 2074558681545020267
  %1101 = sub i64 %989, %1076
  %1102 = mul i64 %1100, %1076
  %1103 = add i64 0, -6235247925983578951
  %1104 = sub i64 %1103, %989
  %1105 = sub i64 %1104, -6235247925983578951
  %1106 = sub i64 0, %989
  %1107 = add i64 %1105, 3792088435246606987
  %1108 = add i64 %1107, %1076
  %1109 = sub i64 %1108, 3792088435246606987
  %1110 = add i64 %1105, %1076
  %1111 = add i64 0, -7871786085866376786
  %1112 = sub i64 %1111, %989
  %1113 = sub i64 %1112, -7871786085866376786
  %1114 = sub i64 0, %989
  %1115 = sub i64 0, %1076
  %1116 = sub i64 %1113, %1115
  %1117 = add i64 %1113, %1076
  %1118 = mul nsw i64 %989, %1076
  %1119 = load volatile i64*, i64** %28
  store i64 %1118, i64* %1119, align 8
  %1120 = load volatile [3 x i64]*, [3 x i64]** %25
  %1121 = getelementptr inbounds [3 x i64], [3 x i64]* %1120, i64 0, i64 0
  %1122 = load volatile i64*, i64** %30
  %1123 = load i64, i64* %1122, align 8
  store i64 %1123, i64* %1121, align 8
  %1124 = getelementptr inbounds i64, i64* %1121, i64 1
  %1125 = load volatile i64*, i64** %29
  %1126 = load i64, i64* %1125, align 8
  store i64 %1126, i64* %1124, align 8
  %1127 = getelementptr inbounds i64, i64* %1124, i64 1
  %1128 = load volatile i64*, i64** %28
  %1129 = load i64, i64* %1128, align 8
  store i64 %1129, i64* %1127, align 8
  %1130 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %26
  %1131 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1130, i32 0, i32 0
  %1132 = load volatile [3 x i64]*, [3 x i64]** %25
  %1133 = getelementptr inbounds [3 x i64], [3 x i64]* %1132, i64 0, i64 0
  store i64* %1133, i64** %1131, align 8
  %1134 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %26
  %1135 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1134, i32 0, i32 1
  store i64 3, i64* %1135, align 8
  %1136 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %26
  %1137 = bitcast %"class.std::initializer_list"* %1136 to { i64*, i64 }*
  %1138 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1137, i32 0, i32 0
  %1139 = load i64*, i64** %1138, align 8
  %1140 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1137, i32 0, i32 1
  %1141 = load i64, i64* %1140, align 8
  %1142 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %1139, i64 %1141)
  %1143 = load volatile [3 x i64]*, [3 x i64]** %23
  %1144 = getelementptr inbounds [3 x i64], [3 x i64]* %1143, i64 0, i64 0
  %1145 = load volatile i64*, i64** %30
  %1146 = load i64, i64* %1145, align 8
  store i64 %1146, i64* %1144, align 8
  %1147 = getelementptr inbounds i64, i64* %1144, i64 1
  %1148 = load volatile i64*, i64** %29
  %1149 = load i64, i64* %1148, align 8
  store i64 %1149, i64* %1147, align 8
  %1150 = getelementptr inbounds i64, i64* %1147, i64 1
  %1151 = load volatile i64*, i64** %28
  %1152 = load i64, i64* %1151, align 8
  store i64 %1152, i64* %1150, align 8
  %1153 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %24
  %1154 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1153, i32 0, i32 0
  %1155 = load volatile [3 x i64]*, [3 x i64]** %23
  %1156 = getelementptr inbounds [3 x i64], [3 x i64]* %1155, i64 0, i64 0
  store i64* %1156, i64** %1154, align 8
  %1157 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %24
  %1158 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1157, i32 0, i32 1
  store i64 3, i64* %1158, align 8
  %1159 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %24
  %1160 = bitcast %"class.std::initializer_list"* %1159 to { i64*, i64 }*
  %1161 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1160, i32 0, i32 0
  %1162 = load i64*, i64** %1161, align 8
  %1163 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1160, i32 0, i32 1
  %1164 = load i64, i64* %1163, align 8
  %1165 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %1162, i64 %1164)
  %1166 = add i64 0, -5407730794102522305
  %1167 = sub i64 %1166, %1142
  %1168 = sub i64 %1167, -5407730794102522305
  %1169 = sub i64 0, %1142
  %1170 = add i64 %1168, -358505413595664896
  %1171 = add i64 %1170, %1165
  %1172 = sub i64 %1171, -358505413595664896
  %1173 = add i64 %1168, %1165
  %1174 = sub i64 %1142, -289376678078256227
  %1175 = sub i64 %1174, %1165
  %1176 = add i64 %1175, -289376678078256227
  %1177 = sub i64 %1142, %1165
  %1178 = mul i64 %1176, %1165
  %1179 = shl i64 %1142, %1165
  %1180 = sub i64 0, %1142
  %1181 = add i64 0, %1180
  %1182 = sub i64 0, %1142
  %1183 = sub i64 0, %1181
  %1184 = sub i64 0, %1165
  %1185 = add i64 %1183, %1184
  %1186 = sub i64 0, %1185
  %1187 = add i64 %1181, %1165
  %1188 = sub i64 %1142, 1440919130975154703
  %1189 = sub i64 %1188, %1165
  %1190 = add i64 %1189, 1440919130975154703
  %1191 = sub i64 %1142, %1165
  %1192 = mul i64 %1190, %1165
  %1193 = add i64 %1142, -8434401556510328829
  %1194 = sub i64 %1193, %1165
  %1195 = sub i64 %1194, -8434401556510328829
  %1196 = sub i64 %1142, %1165
  %1197 = mul i64 %1195, %1165
  %1198 = sub i64 %1142, 5480650878443045278
  %1199 = sub i64 %1198, %1165
  %1200 = add i64 %1199, 5480650878443045278
  %1201 = sub nsw i64 %1142, %1165
  %1202 = load volatile i64*, i64** %27
  store i64 %1200, i64* %1202, align 8
  %1203 = load volatile i64*, i64** %32
  %1204 = load volatile i64*, i64** %27
  %1205 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %1203, i64* dereferenceable(8) %1204)
  %1206 = load i64, i64* %1205, align 8
  %1207 = load volatile i64*, i64** %32
  store i64 %1206, i64* %1207, align 8
  %1208 = load volatile i32*, i32** %34
  %1209 = load i32, i32* %1208, align 4
  %1210 = sext i32 %1209 to i64
  %1211 = load volatile i64*, i64** %31
  %1212 = load i64, i64* %1211, align 8
  %1213 = add i64 %1210, 1658802348809972916
  %1214 = sub i64 %1213, %1212
  %1215 = sub i64 %1214, 1658802348809972916
  %1216 = sub nsw i64 %1210, %1212
  %1217 = sub i64 0, %1215
  %1218 = add i64 0, %1217
  %1219 = sub i64 0, %1215
  %1220 = sub i64 0, %1218
  %1221 = sub i64 0, 2
  %1222 = add i64 %1220, %1221
  %1223 = sub i64 0, %1222
  %1224 = add i64 %1218, 2
  %1225 = add i64 0, 5357505951676413465
  %1226 = sub i64 %1225, %1215
  %1227 = sub i64 %1226, 5357505951676413465
  %1228 = sub i64 0, %1215
  %1229 = add i64 %1227, -7275140198567422817
  %1230 = add i64 %1229, 2
  %1231 = sub i64 %1230, -7275140198567422817
  %1232 = add i64 %1227, 2
  %1233 = add i64 0, 7190170472616551128
  %1234 = sub i64 %1233, %1215
  %1235 = sub i64 %1234, 7190170472616551128
  %1236 = sub i64 0, %1215
  %1237 = sub i64 0, 2
  %1238 = sub i64 %1235, %1237
  %1239 = add i64 %1235, 2
  %1240 = sub i64 0, -1131300417129893742
  %1241 = sub i64 %1240, %1215
  %1242 = add i64 %1241, -1131300417129893742
  %1243 = sub i64 0, %1215
  %1244 = sub i64 0, 2
  %1245 = sub i64 %1242, %1244
  %1246 = add i64 %1242, 2
  %1247 = add i64 0, -3401808276323396831
  %1248 = sub i64 %1247, %1215
  %1249 = sub i64 %1248, -3401808276323396831
  %1250 = sub i64 0, %1215
  %1251 = sub i64 %1249, 8449716055520623031
  %1252 = add i64 %1251, 2
  %1253 = add i64 %1252, 8449716055520623031
  %1254 = add i64 %1249, 2
  %1255 = shl i64 %1215, 2
  %1256 = add i64 0, 1696000632219417605
  %1257 = sub i64 %1256, %1215
  %1258 = sub i64 %1257, 1696000632219417605
  %1259 = sub i64 0, %1215
  %1260 = sub i64 0, 2
  %1261 = sub i64 %1258, %1260
  %1262 = add i64 %1258, 2
  %1263 = sdiv i64 %1215, 2
  %1264 = load volatile i32*, i32** %33
  %1265 = load i32, i32* %1264, align 4
  %1266 = sext i32 %1265 to i64
  %1267 = shl i64 %1263, %1266
  %1268 = sub i64 %1263, 7002258648372195414
  %1269 = sub i64 %1268, %1266
  %1270 = add i64 %1269, 7002258648372195414
  %1271 = sub i64 %1263, %1266
  %1272 = mul i64 %1270, %1266
  %1273 = shl i64 %1263, %1266
  %1274 = add i64 0, -8331051194191770212
  %1275 = sub i64 %1274, %1263
  %1276 = sub i64 %1275, -8331051194191770212
  %1277 = sub i64 0, %1263
  %1278 = add i64 %1276, 199127174191400483
  %1279 = add i64 %1278, %1266
  %1280 = sub i64 %1279, 199127174191400483
  %1281 = add i64 %1276, %1266
  %1282 = sub i64 0, %1266
  %1283 = add i64 %1263, %1282
  %1284 = sub i64 %1263, %1266
  %1285 = mul i64 %1283, %1266
  %1286 = mul nsw i64 %1263, %1266
  %1287 = load volatile i64*, i64** %29
  store i64 %1286, i64* %1287, align 8
  %1288 = load volatile i32*, i32** %34
  %1289 = load i32, i32* %1288, align 4
  %1290 = sext i32 %1289 to i64
  %1291 = load volatile i64*, i64** %31
  %1292 = load i64, i64* %1291, align 8
  %1293 = sub i64 0, -7294531609356832191
  %1294 = sub i64 %1293, %1290
  %1295 = add i64 %1294, -7294531609356832191
  %1296 = sub i64 0, %1290
  %1297 = sub i64 0, %1295
  %1298 = sub i64 0, %1292
  %1299 = add i64 %1297, %1298
  %1300 = sub i64 0, %1299
  %1301 = add i64 %1295, %1292
  %1302 = shl i64 %1290, %1292
  %1303 = shl i64 %1290, %1292
  %1304 = sub i64 %1290, 896827835422688613
  %1305 = sub i64 %1304, %1292
  %1306 = add i64 %1305, 896827835422688613
  %1307 = sub nsw i64 %1290, %1292
  %1308 = shl i64 %1306, 2
  %1309 = sub i64 0, 4402639991459665928
  %1310 = sub i64 %1309, %1306
  %1311 = add i64 %1310, 4402639991459665928
  %1312 = sub i64 0, %1306
  %1313 = sub i64 0, %1311
  %1314 = sub i64 0, 2
  %1315 = add i64 %1313, %1314
  %1316 = sub i64 0, %1315
  %1317 = add i64 %1311, 2
  %1318 = sub i64 %1306, 8938824918071029103
  %1319 = sub i64 %1318, 2
  %1320 = add i64 %1319, 8938824918071029103
  %1321 = sub i64 %1306, 2
  %1322 = mul i64 %1320, 2
  %1323 = sdiv i64 %1306, 2
  %1324 = load volatile i32*, i32** %34
  %1325 = load i32, i32* %1324, align 4
  %1326 = sext i32 %1325 to i64
  %1327 = load volatile i64*, i64** %31
  %1328 = load i64, i64* %1327, align 8
  %1329 = shl i64 %1326, %1328
  %1330 = sub i64 0, %1328
  %1331 = add i64 %1326, %1330
  %1332 = sub i64 %1326, %1328
  %1333 = mul i64 %1331, %1328
  %1334 = sub i64 0, %1328
  %1335 = add i64 %1326, %1334
  %1336 = sub i64 %1326, %1328
  %1337 = mul i64 %1335, %1328
  %1338 = shl i64 %1326, %1328
  %1339 = sub i64 %1326, 263333421141975453
  %1340 = sub i64 %1339, %1328
  %1341 = add i64 %1340, 263333421141975453
  %1342 = sub nsw i64 %1326, %1328
  %1343 = shl i64 %1341, 2
  %1344 = add i64 0, 8240808159708687860
  %1345 = sub i64 %1344, %1341
  %1346 = sub i64 %1345, 8240808159708687860
  %1347 = sub i64 0, %1341
  %1348 = sub i64 0, %1346
  %1349 = sub i64 0, 2
  %1350 = add i64 %1348, %1349
  %1351 = sub i64 0, %1350
  %1352 = add i64 %1346, 2
  %1353 = sub i64 0, %1341
  %1354 = add i64 0, %1353
  %1355 = sub i64 0, %1341
  %1356 = sub i64 0, %1354
  %1357 = sub i64 0, 2
  %1358 = add i64 %1356, %1357
  %1359 = sub i64 0, %1358
  %1360 = add i64 %1354, 2
  %1361 = sub i64 0, -3892179226055249153
  %1362 = sub i64 %1361, %1341
  %1363 = add i64 %1362, -3892179226055249153
  %1364 = sub i64 0, %1341
  %1365 = sub i64 0, %1363
  %1366 = sub i64 0, 2
  %1367 = add i64 %1365, %1366
  %1368 = sub i64 0, %1367
  %1369 = add i64 %1363, 2
  %1370 = srem i64 %1341, 2
  %1371 = sub i64 0, %1323
  %1372 = add i64 0, %1371
  %1373 = sub i64 0, %1323
  %1374 = sub i64 0, %1370
  %1375 = sub i64 %1372, %1374
  %1376 = add i64 %1372, %1370
  %1377 = sub i64 %1323, 6635783470251977478
  %1378 = sub i64 %1377, %1370
  %1379 = add i64 %1378, 6635783470251977478
  %1380 = sub i64 %1323, %1370
  %1381 = mul i64 %1379, %1370
  %1382 = sub i64 0, %1370
  %1383 = add i64 %1323, %1382
  %1384 = sub i64 %1323, %1370
  %1385 = mul i64 %1383, %1370
  %1386 = add i64 %1323, 4698427659102907849
  %1387 = add i64 %1386, %1370
  %1388 = sub i64 %1387, 4698427659102907849
  %1389 = add nsw i64 %1323, %1370
  %1390 = load volatile i32*, i32** %33
  %1391 = load i32, i32* %1390, align 4
  %1392 = sext i32 %1391 to i64
  %1393 = add i64 %1388, 8845134418897337134
  %1394 = sub i64 %1393, %1392
  %1395 = sub i64 %1394, 8845134418897337134
  %1396 = sub i64 %1388, %1392
  %1397 = mul i64 %1395, %1392
  %1398 = sub i64 0, 6234099448513277355
  %1399 = sub i64 %1398, %1388
  %1400 = add i64 %1399, 6234099448513277355
  %1401 = sub i64 0, %1388
  %1402 = add i64 %1400, -4751273329713160279
  %1403 = add i64 %1402, %1392
  %1404 = sub i64 %1403, -4751273329713160279
  %1405 = add i64 %1400, %1392
  %1406 = shl i64 %1388, %1392
  %1407 = mul nsw i64 %1388, %1392
  %1408 = load volatile i64*, i64** %28
  store i64 %1407, i64* %1408, align 8
  %1409 = load volatile [3 x i64]*, [3 x i64]** %20
  %1410 = getelementptr inbounds [3 x i64], [3 x i64]* %1409, i64 0, i64 0
  %1411 = load volatile i64*, i64** %30
  %1412 = load i64, i64* %1411, align 8
  store i64 %1412, i64* %1410, align 8
  %1413 = getelementptr inbounds i64, i64* %1410, i64 1
  %1414 = load volatile i64*, i64** %29
  %1415 = load i64, i64* %1414, align 8
  store i64 %1415, i64* %1413, align 8
  %1416 = getelementptr inbounds i64, i64* %1413, i64 1
  %1417 = load volatile i64*, i64** %28
  %1418 = load i64, i64* %1417, align 8
  store i64 %1418, i64* %1416, align 8
  %1419 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %21
  %1420 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1419, i32 0, i32 0
  %1421 = load volatile [3 x i64]*, [3 x i64]** %20
  %1422 = getelementptr inbounds [3 x i64], [3 x i64]* %1421, i64 0, i64 0
  store i64* %1422, i64** %1420, align 8
  %1423 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %21
  %1424 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1423, i32 0, i32 1
  store i64 3, i64* %1424, align 8
  %1425 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %21
  %1426 = bitcast %"class.std::initializer_list"* %1425 to { i64*, i64 }*
  %1427 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1426, i32 0, i32 0
  %1428 = load i64*, i64** %1427, align 8
  %1429 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1426, i32 0, i32 1
  %1430 = load i64, i64* %1429, align 8
  %1431 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %1428, i64 %1430)
  %1432 = load volatile [3 x i64]*, [3 x i64]** %18
  %1433 = getelementptr inbounds [3 x i64], [3 x i64]* %1432, i64 0, i64 0
  %1434 = load volatile i64*, i64** %30
  %1435 = load i64, i64* %1434, align 8
  store i64 %1435, i64* %1433, align 8
  %1436 = getelementptr inbounds i64, i64* %1433, i64 1
  %1437 = load volatile i64*, i64** %29
  %1438 = load i64, i64* %1437, align 8
  store i64 %1438, i64* %1436, align 8
  %1439 = getelementptr inbounds i64, i64* %1436, i64 1
  %1440 = load volatile i64*, i64** %28
  %1441 = load i64, i64* %1440, align 8
  store i64 %1441, i64* %1439, align 8
  %1442 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %19
  %1443 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1442, i32 0, i32 0
  %1444 = load volatile [3 x i64]*, [3 x i64]** %18
  %1445 = getelementptr inbounds [3 x i64], [3 x i64]* %1444, i64 0, i64 0
  store i64* %1445, i64** %1443, align 8
  %1446 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %19
  %1447 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1446, i32 0, i32 1
  store i64 3, i64* %1447, align 8
  %1448 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %19
  %1449 = bitcast %"class.std::initializer_list"* %1448 to { i64*, i64 }*
  %1450 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1449, i32 0, i32 0
  %1451 = load i64*, i64** %1450, align 8
  %1452 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1449, i32 0, i32 1
  %1453 = load i64, i64* %1452, align 8
  %1454 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %1451, i64 %1453)
  %1455 = sub i64 0, %1431
  %1456 = add i64 0, %1455
  %1457 = sub i64 0, %1431
  %1458 = add i64 %1456, -2386705129315868645
  %1459 = add i64 %1458, %1454
  %1460 = sub i64 %1459, -2386705129315868645
  %1461 = add i64 %1456, %1454
  %1462 = sub i64 %1431, -1420641430301620757
  %1463 = sub i64 %1462, %1454
  %1464 = add i64 %1463, -1420641430301620757
  %1465 = sub i64 %1431, %1454
  %1466 = mul i64 %1464, %1454
  %1467 = sub i64 0, %1431
  %1468 = add i64 0, %1467
  %1469 = sub i64 0, %1431
  %1470 = add i64 %1468, 3543579700486598710
  %1471 = add i64 %1470, %1454
  %1472 = sub i64 %1471, 3543579700486598710
  %1473 = add i64 %1468, %1454
  %1474 = sub i64 %1431, -587820251673107069
  %1475 = sub i64 %1474, %1454
  %1476 = add i64 %1475, -587820251673107069
  %1477 = sub nsw i64 %1431, %1454
  %1478 = load volatile i64*, i64** %22
  store i64 %1476, i64* %1478, align 8
  %1479 = load volatile i64*, i64** %32
  %1480 = load volatile i64*, i64** %22
  %1481 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %1479, i64* dereferenceable(8) %1480)
  %1482 = load i64, i64* %1481, align 8
  %1483 = load volatile i64*, i64** %32
  store i64 %1482, i64* %1483, align 8
  store i32 1559057016, i32* %47
  br label %2176

; <label>:1484:                                   ; preds = %48
  %1485 = load volatile i64*, i64** %31
  %1486 = load i64, i64* %1485, align 8
  %1487 = sub i64 0, 1
  %1488 = add i64 %1486, %1487
  %1489 = sub i64 %1486, 1
  %1490 = mul i64 %1488, 1
  %1491 = sub i64 %1486, -3308074259877918786
  %1492 = sub i64 %1491, 1
  %1493 = add i64 %1492, -3308074259877918786
  %1494 = sub i64 %1486, 1
  %1495 = mul i64 %1493, 1
  %1496 = sub i64 %1486, -6270172769461784951
  %1497 = sub i64 %1496, 1
  %1498 = add i64 %1497, -6270172769461784951
  %1499 = sub i64 %1486, 1
  %1500 = mul i64 %1498, 1
  %1501 = shl i64 %1486, 1
  %1502 = sub i64 %1486, 8644856568833976290
  %1503 = add i64 %1502, 1
  %1504 = add i64 %1503, 8644856568833976290
  %1505 = add nsw i64 %1486, 1
  %1506 = load volatile i64*, i64** %31
  store i64 %1504, i64* %1506, align 8
  store i32 1189556064, i32* %47
  br label %2176

; <label>:1507:                                   ; preds = %48
  %1508 = load volatile i64*, i64** %17
  %1509 = load i64, i64* %1508, align 8
  %1510 = load volatile i32*, i32** %33
  %1511 = load i32, i32* %1510, align 4
  %1512 = sext i32 %1511 to i64
  %1513 = icmp slt i64 %1509, %1512
  store i32 -816599183, i32* %47
  br label %2176

; <label>:1514:                                   ; preds = %48
  %1515 = load volatile i64*, i64** %17
  %1516 = load i64, i64* %1515, align 8
  %1517 = load volatile i32*, i32** %34
  %1518 = load i32, i32* %1517, align 4
  %1519 = sext i32 %1518 to i64
  %1520 = sub i64 0, %1516
  %1521 = add i64 0, %1520
  %1522 = sub i64 0, %1516
  %1523 = sub i64 0, %1519
  %1524 = sub i64 %1521, %1523
  %1525 = add i64 %1521, %1519
  %1526 = add i64 0, 5522560167385040130
  %1527 = sub i64 %1526, %1516
  %1528 = sub i64 %1527, 5522560167385040130
  %1529 = sub i64 0, %1516
  %1530 = sub i64 %1528, -3241834478654423917
  %1531 = add i64 %1530, %1519
  %1532 = add i64 %1531, -3241834478654423917
  %1533 = add i64 %1528, %1519
  %1534 = shl i64 %1516, %1519
  %1535 = sub i64 0, %1516
  %1536 = add i64 0, %1535
  %1537 = sub i64 0, %1516
  %1538 = sub i64 0, %1519
  %1539 = sub i64 %1536, %1538
  %1540 = add i64 %1536, %1519
  %1541 = mul nsw i64 %1516, %1519
  %1542 = load volatile i64*, i64** %16
  store i64 %1541, i64* %1542, align 8
  %1543 = load volatile i32*, i32** %33
  %1544 = load i32, i32* %1543, align 4
  %1545 = sext i32 %1544 to i64
  %1546 = load volatile i64*, i64** %17
  %1547 = load i64, i64* %1546, align 8
  %1548 = sub i64 0, -1015588380430766518
  %1549 = sub i64 %1548, %1545
  %1550 = add i64 %1549, -1015588380430766518
  %1551 = sub i64 0, %1545
  %1552 = sub i64 0, %1550
  %1553 = sub i64 0, %1547
  %1554 = add i64 %1552, %1553
  %1555 = sub i64 0, %1554
  %1556 = add i64 %1550, %1547
  %1557 = sub i64 0, %1547
  %1558 = add i64 %1545, %1557
  %1559 = sub i64 %1545, %1547
  %1560 = mul i64 %1558, %1547
  %1561 = sub i64 0, %1545
  %1562 = add i64 0, %1561
  %1563 = sub i64 0, %1545
  %1564 = sub i64 %1562, -6566921981210813666
  %1565 = add i64 %1564, %1547
  %1566 = add i64 %1565, -6566921981210813666
  %1567 = add i64 %1562, %1547
  %1568 = shl i64 %1545, %1547
  %1569 = sub i64 %1545, -5811479765633550079
  %1570 = sub i64 %1569, %1547
  %1571 = add i64 %1570, -5811479765633550079
  %1572 = sub i64 %1545, %1547
  %1573 = mul i64 %1571, %1547
  %1574 = sub i64 0, %1547
  %1575 = add i64 %1545, %1574
  %1576 = sub i64 %1545, %1547
  %1577 = mul i64 %1575, %1547
  %1578 = add i64 %1545, 2486205374960087511
  %1579 = sub i64 %1578, %1547
  %1580 = sub i64 %1579, 2486205374960087511
  %1581 = sub nsw i64 %1545, %1547
  %1582 = load volatile i32*, i32** %34
  %1583 = load i32, i32* %1582, align 4
  %1584 = sub i32 0, %1583
  %1585 = add i32 0, %1584
  %1586 = sub i32 0, %1583
  %1587 = add i32 %1585, -1648721669
  %1588 = add i32 %1587, 2
  %1589 = sub i32 %1588, -1648721669
  %1590 = add i32 %1585, 2
  %1591 = sub i32 0, 2
  %1592 = add i32 %1583, %1591
  %1593 = sub i32 %1583, 2
  %1594 = mul i32 %1592, 2
  %1595 = add i32 0, 1375851499
  %1596 = sub i32 %1595, %1583
  %1597 = sub i32 %1596, 1375851499
  %1598 = sub i32 0, %1583
  %1599 = sub i32 0, %1597
  %1600 = sub i32 0, 2
  %1601 = add i32 %1599, %1600
  %1602 = sub i32 0, %1601
  %1603 = add i32 %1597, 2
  %1604 = sub i32 %1583, 1938557495
  %1605 = sub i32 %1604, 2
  %1606 = add i32 %1605, 1938557495
  %1607 = sub i32 %1583, 2
  %1608 = mul i32 %1606, 2
  %1609 = sub i32 %1583, 1296873900
  %1610 = sub i32 %1609, 2
  %1611 = add i32 %1610, 1296873900
  %1612 = sub i32 %1583, 2
  %1613 = mul i32 %1611, 2
  %1614 = sub i32 0, 1327267388
  %1615 = sub i32 %1614, %1583
  %1616 = add i32 %1615, 1327267388
  %1617 = sub i32 0, %1583
  %1618 = sub i32 %1616, 893743915
  %1619 = add i32 %1618, 2
  %1620 = add i32 %1619, 893743915
  %1621 = add i32 %1616, 2
  %1622 = shl i32 %1583, 2
  %1623 = sdiv i32 %1583, 2
  %1624 = sext i32 %1623 to i64
  %1625 = sub i64 0, %1624
  %1626 = add i64 %1580, %1625
  %1627 = sub i64 %1580, %1624
  %1628 = mul i64 %1626, %1624
  %1629 = shl i64 %1580, %1624
  %1630 = mul nsw i64 %1580, %1624
  %1631 = load volatile i64*, i64** %15
  store i64 %1630, i64* %1631, align 8
  %1632 = load volatile i32*, i32** %33
  %1633 = load i32, i32* %1632, align 4
  %1634 = sext i32 %1633 to i64
  %1635 = load volatile i64*, i64** %17
  %1636 = load i64, i64* %1635, align 8
  %1637 = add i64 %1634, 7760718291557354908
  %1638 = sub i64 %1637, %1636
  %1639 = sub i64 %1638, 7760718291557354908
  %1640 = sub i64 %1634, %1636
  %1641 = mul i64 %1639, %1636
  %1642 = add i64 0, -2853526985215232335
  %1643 = sub i64 %1642, %1634
  %1644 = sub i64 %1643, -2853526985215232335
  %1645 = sub i64 0, %1634
  %1646 = add i64 %1644, 8951725935757717652
  %1647 = add i64 %1646, %1636
  %1648 = sub i64 %1647, 8951725935757717652
  %1649 = add i64 %1644, %1636
  %1650 = sub i64 %1634, -3508853732350677036
  %1651 = sub i64 %1650, %1636
  %1652 = add i64 %1651, -3508853732350677036
  %1653 = sub i64 %1634, %1636
  %1654 = mul i64 %1652, %1636
  %1655 = sub i64 0, %1634
  %1656 = add i64 0, %1655
  %1657 = sub i64 0, %1634
  %1658 = sub i64 %1656, 4001061331955043628
  %1659 = add i64 %1658, %1636
  %1660 = add i64 %1659, 4001061331955043628
  %1661 = add i64 %1656, %1636
  %1662 = sub i64 0, %1636
  %1663 = add i64 %1634, %1662
  %1664 = sub nsw i64 %1634, %1636
  %1665 = load volatile i32*, i32** %34
  %1666 = load i32, i32* %1665, align 4
  %1667 = sub i32 0, 2
  %1668 = add i32 %1666, %1667
  %1669 = sub i32 %1666, 2
  %1670 = mul i32 %1668, 2
  %1671 = sub i32 0, %1666
  %1672 = add i32 0, %1671
  %1673 = sub i32 0, %1666
  %1674 = sub i32 0, %1672
  %1675 = sub i32 0, 2
  %1676 = add i32 %1674, %1675
  %1677 = sub i32 0, %1676
  %1678 = add i32 %1672, 2
  %1679 = sub i32 0, %1666
  %1680 = add i32 0, %1679
  %1681 = sub i32 0, %1666
  %1682 = sub i32 0, %1680
  %1683 = sub i32 0, 2
  %1684 = add i32 %1682, %1683
  %1685 = sub i32 0, %1684
  %1686 = add i32 %1680, 2
  %1687 = shl i32 %1666, 2
  %1688 = sub i32 0, 2137041816
  %1689 = sub i32 %1688, %1666
  %1690 = add i32 %1689, 2137041816
  %1691 = sub i32 0, %1666
  %1692 = add i32 %1690, -81099783
  %1693 = add i32 %1692, 2
  %1694 = sub i32 %1693, -81099783
  %1695 = add i32 %1690, 2
  %1696 = sdiv i32 %1666, 2
  %1697 = load volatile i32*, i32** %34
  %1698 = load i32, i32* %1697, align 4
  %1699 = sub i32 0, %1698
  %1700 = add i32 0, %1699
  %1701 = sub i32 0, %1698
  %1702 = sub i32 0, 2
  %1703 = sub i32 %1700, %1702
  %1704 = add i32 %1700, 2
  %1705 = shl i32 %1698, 2
  %1706 = sub i32 %1698, 1607875816
  %1707 = sub i32 %1706, 2
  %1708 = add i32 %1707, 1607875816
  %1709 = sub i32 %1698, 2
  %1710 = mul i32 %1708, 2
  %1711 = sub i32 0, %1698
  %1712 = add i32 0, %1711
  %1713 = sub i32 0, %1698
  %1714 = sub i32 0, %1712
  %1715 = sub i32 0, 2
  %1716 = add i32 %1714, %1715
  %1717 = sub i32 0, %1716
  %1718 = add i32 %1712, 2
  %1719 = sub i32 0, %1698
  %1720 = add i32 0, %1719
  %1721 = sub i32 0, %1698
  %1722 = sub i32 0, 2
  %1723 = sub i32 %1720, %1722
  %1724 = add i32 %1720, 2
  %1725 = srem i32 %1698, 2
  %1726 = add i32 0, 205566785
  %1727 = sub i32 %1726, %1696
  %1728 = sub i32 %1727, 205566785
  %1729 = sub i32 0, %1696
  %1730 = sub i32 0, %1728
  %1731 = sub i32 0, %1725
  %1732 = add i32 %1730, %1731
  %1733 = sub i32 0, %1732
  %1734 = add i32 %1728, %1725
  %1735 = shl i32 %1696, %1725
  %1736 = add i32 %1696, 1669479384
  %1737 = sub i32 %1736, %1725
  %1738 = sub i32 %1737, 1669479384
  %1739 = sub i32 %1696, %1725
  %1740 = mul i32 %1738, %1725
  %1741 = add i32 %1696, 324102152
  %1742 = add i32 %1741, %1725
  %1743 = sub i32 %1742, 324102152
  %1744 = add nsw i32 %1696, %1725
  %1745 = sext i32 %1743 to i64
  %1746 = sub i64 0, %1745
  %1747 = add i64 %1663, %1746
  %1748 = sub i64 %1663, %1745
  %1749 = mul i64 %1747, %1745
  %1750 = sub i64 0, 4311871581395265870
  %1751 = sub i64 %1750, %1663
  %1752 = add i64 %1751, 4311871581395265870
  %1753 = sub i64 0, %1663
  %1754 = sub i64 %1752, 2690229527515770803
  %1755 = add i64 %1754, %1745
  %1756 = add i64 %1755, 2690229527515770803
  %1757 = add i64 %1752, %1745
  %1758 = add i64 %1663, 9123258595843875215
  %1759 = sub i64 %1758, %1745
  %1760 = sub i64 %1759, 9123258595843875215
  %1761 = sub i64 %1663, %1745
  %1762 = mul i64 %1760, %1745
  %1763 = add i64 0, -6932935673462202277
  %1764 = sub i64 %1763, %1663
  %1765 = sub i64 %1764, -6932935673462202277
  %1766 = sub i64 0, %1663
  %1767 = add i64 %1765, -4246396893732713943
  %1768 = add i64 %1767, %1745
  %1769 = sub i64 %1768, -4246396893732713943
  %1770 = add i64 %1765, %1745
  %1771 = sub i64 0, %1663
  %1772 = add i64 0, %1771
  %1773 = sub i64 0, %1663
  %1774 = sub i64 %1772, -952531878781193108
  %1775 = add i64 %1774, %1745
  %1776 = add i64 %1775, -952531878781193108
  %1777 = add i64 %1772, %1745
  %1778 = sub i64 0, %1663
  %1779 = add i64 0, %1778
  %1780 = sub i64 0, %1663
  %1781 = add i64 %1779, -6860792264770292326
  %1782 = add i64 %1781, %1745
  %1783 = sub i64 %1782, -6860792264770292326
  %1784 = add i64 %1779, %1745
  %1785 = mul nsw i64 %1663, %1745
  %1786 = load volatile i64*, i64** %14
  store i64 %1785, i64* %1786, align 8
  %1787 = load volatile [3 x i64]*, [3 x i64]** %11
  %1788 = getelementptr inbounds [3 x i64], [3 x i64]* %1787, i64 0, i64 0
  %1789 = load volatile i64*, i64** %16
  %1790 = load i64, i64* %1789, align 8
  store i64 %1790, i64* %1788, align 8
  %1791 = getelementptr inbounds i64, i64* %1788, i64 1
  %1792 = load volatile i64*, i64** %15
  %1793 = load i64, i64* %1792, align 8
  store i64 %1793, i64* %1791, align 8
  %1794 = getelementptr inbounds i64, i64* %1791, i64 1
  %1795 = load volatile i64*, i64** %14
  %1796 = load i64, i64* %1795, align 8
  store i64 %1796, i64* %1794, align 8
  %1797 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %12
  %1798 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1797, i32 0, i32 0
  %1799 = load volatile [3 x i64]*, [3 x i64]** %11
  %1800 = getelementptr inbounds [3 x i64], [3 x i64]* %1799, i64 0, i64 0
  store i64* %1800, i64** %1798, align 8
  %1801 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %12
  %1802 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1801, i32 0, i32 1
  store i64 3, i64* %1802, align 8
  %1803 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %12
  %1804 = bitcast %"class.std::initializer_list"* %1803 to { i64*, i64 }*
  %1805 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1804, i32 0, i32 0
  %1806 = load i64*, i64** %1805, align 8
  %1807 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1804, i32 0, i32 1
  %1808 = load i64, i64* %1807, align 8
  %1809 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %1806, i64 %1808)
  %1810 = load volatile [3 x i64]*, [3 x i64]** %9
  %1811 = getelementptr inbounds [3 x i64], [3 x i64]* %1810, i64 0, i64 0
  %1812 = load volatile i64*, i64** %16
  %1813 = load i64, i64* %1812, align 8
  store i64 %1813, i64* %1811, align 8
  %1814 = getelementptr inbounds i64, i64* %1811, i64 1
  %1815 = load volatile i64*, i64** %15
  %1816 = load i64, i64* %1815, align 8
  store i64 %1816, i64* %1814, align 8
  %1817 = getelementptr inbounds i64, i64* %1814, i64 1
  %1818 = load volatile i64*, i64** %14
  %1819 = load i64, i64* %1818, align 8
  store i64 %1819, i64* %1817, align 8
  %1820 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %10
  %1821 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1820, i32 0, i32 0
  %1822 = load volatile [3 x i64]*, [3 x i64]** %9
  %1823 = getelementptr inbounds [3 x i64], [3 x i64]* %1822, i64 0, i64 0
  store i64* %1823, i64** %1821, align 8
  %1824 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %10
  %1825 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %1824, i32 0, i32 1
  store i64 3, i64* %1825, align 8
  %1826 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %10
  %1827 = bitcast %"class.std::initializer_list"* %1826 to { i64*, i64 }*
  %1828 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1827, i32 0, i32 0
  %1829 = load i64*, i64** %1828, align 8
  %1830 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %1827, i32 0, i32 1
  %1831 = load i64, i64* %1830, align 8
  %1832 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %1829, i64 %1831)
  %1833 = sub i64 %1809, 5902547460765432031
  %1834 = sub i64 %1833, %1832
  %1835 = add i64 %1834, 5902547460765432031
  %1836 = sub i64 %1809, %1832
  %1837 = mul i64 %1835, %1832
  %1838 = sub i64 0, %1809
  %1839 = add i64 0, %1838
  %1840 = sub i64 0, %1809
  %1841 = sub i64 %1839, -8678950284544525133
  %1842 = add i64 %1841, %1832
  %1843 = add i64 %1842, -8678950284544525133
  %1844 = add i64 %1839, %1832
  %1845 = sub i64 0, %1832
  %1846 = add i64 %1809, %1845
  %1847 = sub nsw i64 %1809, %1832
  %1848 = load volatile i64*, i64** %13
  store i64 %1846, i64* %1848, align 8
  %1849 = load volatile i64*, i64** %32
  %1850 = load volatile i64*, i64** %13
  %1851 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %1849, i64* dereferenceable(8) %1850)
  %1852 = load i64, i64* %1851, align 8
  %1853 = load volatile i64*, i64** %32
  store i64 %1852, i64* %1853, align 8
  %1854 = load volatile i32*, i32** %33
  %1855 = load i32, i32* %1854, align 4
  %1856 = sext i32 %1855 to i64
  %1857 = load volatile i64*, i64** %17
  %1858 = load i64, i64* %1857, align 8
  %1859 = shl i64 %1856, %1858
  %1860 = sub i64 0, %1858
  %1861 = add i64 %1856, %1860
  %1862 = sub i64 %1856, %1858
  %1863 = mul i64 %1861, %1858
  %1864 = shl i64 %1856, %1858
  %1865 = shl i64 %1856, %1858
  %1866 = sub i64 0, 3512375483481604432
  %1867 = sub i64 %1866, %1856
  %1868 = add i64 %1867, 3512375483481604432
  %1869 = sub i64 0, %1856
  %1870 = add i64 %1868, -1459357261159661125
  %1871 = add i64 %1870, %1858
  %1872 = sub i64 %1871, -1459357261159661125
  %1873 = add i64 %1868, %1858
  %1874 = add i64 0, 6802932744923707998
  %1875 = sub i64 %1874, %1856
  %1876 = sub i64 %1875, 6802932744923707998
  %1877 = sub i64 0, %1856
  %1878 = sub i64 0, %1876
  %1879 = sub i64 0, %1858
  %1880 = add i64 %1878, %1879
  %1881 = sub i64 0, %1880
  %1882 = add i64 %1876, %1858
  %1883 = add i64 %1856, -8626657587583196286
  %1884 = sub i64 %1883, %1858
  %1885 = sub i64 %1884, -8626657587583196286
  %1886 = sub nsw i64 %1856, %1858
  %1887 = sub i64 0, 8645302711270747939
  %1888 = sub i64 %1887, %1885
  %1889 = add i64 %1888, 8645302711270747939
  %1890 = sub i64 0, %1885
  %1891 = add i64 %1889, 5078347569900477691
  %1892 = add i64 %1891, 2
  %1893 = sub i64 %1892, 5078347569900477691
  %1894 = add i64 %1889, 2
  %1895 = add i64 0, -3753819973220420293
  %1896 = sub i64 %1895, %1885
  %1897 = sub i64 %1896, -3753819973220420293
  %1898 = sub i64 0, %1885
  %1899 = sub i64 0, 2
  %1900 = sub i64 %1897, %1899
  %1901 = add i64 %1897, 2
  %1902 = sub i64 0, %1885
  %1903 = add i64 0, %1902
  %1904 = sub i64 0, %1885
  %1905 = sub i64 0, 2
  %1906 = sub i64 %1903, %1905
  %1907 = add i64 %1903, 2
  %1908 = sub i64 0, %1885
  %1909 = add i64 0, %1908
  %1910 = sub i64 0, %1885
  %1911 = sub i64 0, 2
  %1912 = sub i64 %1909, %1911
  %1913 = add i64 %1909, 2
  %1914 = sdiv i64 %1885, 2
  %1915 = load volatile i32*, i32** %34
  %1916 = load i32, i32* %1915, align 4
  %1917 = sext i32 %1916 to i64
  %1918 = shl i64 %1914, %1917
  %1919 = add i64 0, -6951297245386922019
  %1920 = sub i64 %1919, %1914
  %1921 = sub i64 %1920, -6951297245386922019
  %1922 = sub i64 0, %1914
  %1923 = sub i64 0, %1917
  %1924 = sub i64 %1921, %1923
  %1925 = add i64 %1921, %1917
  %1926 = sub i64 0, %1917
  %1927 = add i64 %1914, %1926
  %1928 = sub i64 %1914, %1917
  %1929 = mul i64 %1927, %1917
  %1930 = add i64 0, 8597273412176820070
  %1931 = sub i64 %1930, %1914
  %1932 = sub i64 %1931, 8597273412176820070
  %1933 = sub i64 0, %1914
  %1934 = sub i64 0, %1917
  %1935 = sub i64 %1932, %1934
  %1936 = add i64 %1932, %1917
  %1937 = shl i64 %1914, %1917
  %1938 = sub i64 0, 729370904874418781
  %1939 = sub i64 %1938, %1914
  %1940 = add i64 %1939, 729370904874418781
  %1941 = sub i64 0, %1914
  %1942 = sub i64 0, %1940
  %1943 = sub i64 0, %1917
  %1944 = add i64 %1942, %1943
  %1945 = sub i64 0, %1944
  %1946 = add i64 %1940, %1917
  %1947 = sub i64 %1914, 5491555057031945209
  %1948 = sub i64 %1947, %1917
  %1949 = add i64 %1948, 5491555057031945209
  %1950 = sub i64 %1914, %1917
  %1951 = mul i64 %1949, %1917
  %1952 = add i64 %1914, -1673885669708673954
  %1953 = sub i64 %1952, %1917
  %1954 = sub i64 %1953, -1673885669708673954
  %1955 = sub i64 %1914, %1917
  %1956 = mul i64 %1954, %1917
  %1957 = shl i64 %1914, %1917
  %1958 = mul nsw i64 %1914, %1917
  %1959 = load volatile i64*, i64** %15
  store i64 %1958, i64* %1959, align 8
  %1960 = load volatile i32*, i32** %33
  %1961 = load i32, i32* %1960, align 4
  %1962 = sext i32 %1961 to i64
  %1963 = load volatile i64*, i64** %17
  %1964 = load i64, i64* %1963, align 8
  %1965 = sub i64 %1962, 3390233819494558999
  %1966 = sub i64 %1965, %1964
  %1967 = add i64 %1966, 3390233819494558999
  %1968 = sub i64 %1962, %1964
  %1969 = mul i64 %1967, %1964
  %1970 = add i64 %1962, -273864170901226139
  %1971 = sub i64 %1970, %1964
  %1972 = sub i64 %1971, -273864170901226139
  %1973 = sub i64 %1962, %1964
  %1974 = mul i64 %1972, %1964
  %1975 = sub i64 0, %1964
  %1976 = add i64 %1962, %1975
  %1977 = sub i64 %1962, %1964
  %1978 = mul i64 %1976, %1964
  %1979 = sub i64 0, 8807598559294372746
  %1980 = sub i64 %1979, %1962
  %1981 = add i64 %1980, 8807598559294372746
  %1982 = sub i64 0, %1962
  %1983 = add i64 %1981, -7415771355221575810
  %1984 = add i64 %1983, %1964
  %1985 = sub i64 %1984, -7415771355221575810
  %1986 = add i64 %1981, %1964
  %1987 = add i64 %1962, -4832691014533180698
  %1988 = sub i64 %1987, %1964
  %1989 = sub i64 %1988, -4832691014533180698
  %1990 = sub i64 %1962, %1964
  %1991 = mul i64 %1989, %1964
  %1992 = shl i64 %1962, %1964
  %1993 = sub i64 0, 8543992726215018748
  %1994 = sub i64 %1993, %1962
  %1995 = add i64 %1994, 8543992726215018748
  %1996 = sub i64 0, %1962
  %1997 = sub i64 %1995, 3991169015928833110
  %1998 = add i64 %1997, %1964
  %1999 = add i64 %1998, 3991169015928833110
  %2000 = add i64 %1995, %1964
  %2001 = sub i64 %1962, 4940698235601093287
  %2002 = sub i64 %2001, %1964
  %2003 = add i64 %2002, 4940698235601093287
  %2004 = sub nsw i64 %1962, %1964
  %2005 = sub i64 %2003, 3429894393062438078
  %2006 = sub i64 %2005, 2
  %2007 = add i64 %2006, 3429894393062438078
  %2008 = sub i64 %2003, 2
  %2009 = mul i64 %2007, 2
  %2010 = sub i64 0, -858264688324192122
  %2011 = sub i64 %2010, %2003
  %2012 = add i64 %2011, -858264688324192122
  %2013 = sub i64 0, %2003
  %2014 = sub i64 %2012, -5274577855935929467
  %2015 = add i64 %2014, 2
  %2016 = add i64 %2015, -5274577855935929467
  %2017 = add i64 %2012, 2
  %2018 = sdiv i64 %2003, 2
  %2019 = load volatile i32*, i32** %33
  %2020 = load i32, i32* %2019, align 4
  %2021 = sext i32 %2020 to i64
  %2022 = load volatile i64*, i64** %17
  %2023 = load i64, i64* %2022, align 8
  %2024 = sub i64 0, %2023
  %2025 = add i64 %2021, %2024
  %2026 = sub i64 %2021, %2023
  %2027 = mul i64 %2025, %2023
  %2028 = sub i64 %2021, -8144006030254799831
  %2029 = sub i64 %2028, %2023
  %2030 = add i64 %2029, -8144006030254799831
  %2031 = sub i64 %2021, %2023
  %2032 = mul i64 %2030, %2023
  %2033 = sub i64 0, %2021
  %2034 = add i64 0, %2033
  %2035 = sub i64 0, %2021
  %2036 = sub i64 0, %2034
  %2037 = sub i64 0, %2023
  %2038 = add i64 %2036, %2037
  %2039 = sub i64 0, %2038
  %2040 = add i64 %2034, %2023
  %2041 = sub i64 %2021, -5018849011269122199
  %2042 = sub i64 %2041, %2023
  %2043 = add i64 %2042, -5018849011269122199
  %2044 = sub nsw i64 %2021, %2023
  %2045 = add i64 %2043, -5754821085475872476
  %2046 = sub i64 %2045, 2
  %2047 = sub i64 %2046, -5754821085475872476
  %2048 = sub i64 %2043, 2
  %2049 = mul i64 %2047, 2
  %2050 = sub i64 0, -2607906559148814856
  %2051 = sub i64 %2050, %2043
  %2052 = add i64 %2051, -2607906559148814856
  %2053 = sub i64 0, %2043
  %2054 = sub i64 0, 2
  %2055 = sub i64 %2052, %2054
  %2056 = add i64 %2052, 2
  %2057 = sub i64 %2043, 7867166113107190822
  %2058 = sub i64 %2057, 2
  %2059 = add i64 %2058, 7867166113107190822
  %2060 = sub i64 %2043, 2
  %2061 = mul i64 %2059, 2
  %2062 = shl i64 %2043, 2
  %2063 = shl i64 %2043, 2
  %2064 = srem i64 %2043, 2
  %2065 = sub i64 %2018, 6164990002510757575
  %2066 = sub i64 %2065, %2064
  %2067 = add i64 %2066, 6164990002510757575
  %2068 = sub i64 %2018, %2064
  %2069 = mul i64 %2067, %2064
  %2070 = shl i64 %2018, %2064
  %2071 = shl i64 %2018, %2064
  %2072 = add i64 0, 8620061921380036611
  %2073 = sub i64 %2072, %2018
  %2074 = sub i64 %2073, 8620061921380036611
  %2075 = sub i64 0, %2018
  %2076 = add i64 %2074, -5812771406153683311
  %2077 = add i64 %2076, %2064
  %2078 = sub i64 %2077, -5812771406153683311
  %2079 = add i64 %2074, %2064
  %2080 = shl i64 %2018, %2064
  %2081 = sub i64 %2018, -3709879958151357505
  %2082 = add i64 %2081, %2064
  %2083 = add i64 %2082, -3709879958151357505
  %2084 = add nsw i64 %2018, %2064
  %2085 = load volatile i32*, i32** %34
  %2086 = load i32, i32* %2085, align 4
  %2087 = sext i32 %2086 to i64
  %2088 = sub i64 %2083, 2773261454557603949
  %2089 = sub i64 %2088, %2087
  %2090 = add i64 %2089, 2773261454557603949
  %2091 = sub i64 %2083, %2087
  %2092 = mul i64 %2090, %2087
  %2093 = shl i64 %2083, %2087
  %2094 = shl i64 %2083, %2087
  %2095 = sub i64 0, 4729860709896730174
  %2096 = sub i64 %2095, %2083
  %2097 = add i64 %2096, 4729860709896730174
  %2098 = sub i64 0, %2083
  %2099 = sub i64 0, %2097
  %2100 = sub i64 0, %2087
  %2101 = add i64 %2099, %2100
  %2102 = sub i64 0, %2101
  %2103 = add i64 %2097, %2087
  %2104 = shl i64 %2083, %2087
  %2105 = add i64 0, -207220094469983839
  %2106 = sub i64 %2105, %2083
  %2107 = sub i64 %2106, -207220094469983839
  %2108 = sub i64 0, %2083
  %2109 = sub i64 0, %2107
  %2110 = sub i64 0, %2087
  %2111 = add i64 %2109, %2110
  %2112 = sub i64 0, %2111
  %2113 = add i64 %2107, %2087
  %2114 = mul nsw i64 %2083, %2087
  %2115 = load volatile i64*, i64** %14
  store i64 %2114, i64* %2115, align 8
  %2116 = load volatile [3 x i64]*, [3 x i64]** %6
  %2117 = getelementptr inbounds [3 x i64], [3 x i64]* %2116, i64 0, i64 0
  %2118 = load volatile i64*, i64** %16
  %2119 = load i64, i64* %2118, align 8
  store i64 %2119, i64* %2117, align 8
  %2120 = getelementptr inbounds i64, i64* %2117, i64 1
  %2121 = load volatile i64*, i64** %15
  %2122 = load i64, i64* %2121, align 8
  store i64 %2122, i64* %2120, align 8
  %2123 = getelementptr inbounds i64, i64* %2120, i64 1
  %2124 = load volatile i64*, i64** %14
  %2125 = load i64, i64* %2124, align 8
  store i64 %2125, i64* %2123, align 8
  %2126 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %7
  %2127 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %2126, i32 0, i32 0
  %2128 = load volatile [3 x i64]*, [3 x i64]** %6
  %2129 = getelementptr inbounds [3 x i64], [3 x i64]* %2128, i64 0, i64 0
  store i64* %2129, i64** %2127, align 8
  %2130 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %7
  %2131 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %2130, i32 0, i32 1
  store i64 3, i64* %2131, align 8
  %2132 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %7
  %2133 = bitcast %"class.std::initializer_list"* %2132 to { i64*, i64 }*
  %2134 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %2133, i32 0, i32 0
  %2135 = load i64*, i64** %2134, align 8
  %2136 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %2133, i32 0, i32 1
  %2137 = load i64, i64* %2136, align 8
  %2138 = call i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64* %2135, i64 %2137)
  %2139 = load volatile [3 x i64]*, [3 x i64]** %4
  %2140 = getelementptr inbounds [3 x i64], [3 x i64]* %2139, i64 0, i64 0
  %2141 = load volatile i64*, i64** %16
  %2142 = load i64, i64* %2141, align 8
  store i64 %2142, i64* %2140, align 8
  %2143 = getelementptr inbounds i64, i64* %2140, i64 1
  %2144 = load volatile i64*, i64** %15
  %2145 = load i64, i64* %2144, align 8
  store i64 %2145, i64* %2143, align 8
  %2146 = getelementptr inbounds i64, i64* %2143, i64 1
  %2147 = load volatile i64*, i64** %14
  %2148 = load i64, i64* %2147, align 8
  store i64 %2148, i64* %2146, align 8
  %2149 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %5
  %2150 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %2149, i32 0, i32 0
  %2151 = load volatile [3 x i64]*, [3 x i64]** %4
  %2152 = getelementptr inbounds [3 x i64], [3 x i64]* %2151, i64 0, i64 0
  store i64* %2152, i64** %2150, align 8
  %2153 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %5
  %2154 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %2153, i32 0, i32 1
  store i64 3, i64* %2154, align 8
  %2155 = load volatile %"class.std::initializer_list"*, %"class.std::initializer_list"** %5
  %2156 = bitcast %"class.std::initializer_list"* %2155 to { i64*, i64 }*
  %2157 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %2156, i32 0, i32 0
  %2158 = load i64*, i64** %2157, align 8
  %2159 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %2156, i32 0, i32 1
  %2160 = load i64, i64* %2159, align 8
  %2161 = call i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64* %2158, i64 %2160)
  %2162 = add i64 %2138, 9151755991846777349
  %2163 = sub i64 %2162, %2161
  %2164 = sub i64 %2163, 9151755991846777349
  %2165 = sub i64 %2138, %2161
  %2166 = mul i64 %2164, %2161
  %2167 = sub i64 0, %2161
  %2168 = add i64 %2138, %2167
  %2169 = sub nsw i64 %2138, %2161
  %2170 = load volatile i64*, i64** %8
  store i64 %2168, i64* %2170, align 8
  %2171 = load volatile i64*, i64** %32
  %2172 = load volatile i64*, i64** %8
  %2173 = call dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8) %2171, i64* dereferenceable(8) %2172)
  %2174 = load i64, i64* %2173, align 8
  %2175 = load volatile i64*, i64** %32
  store i64 %2174, i64* %2175, align 8
  store i32 -2051328433, i32* %47
  br label %2176

; <label>:2176:                                   ; preds = %1514, %1507, %1484, %845, %838, %802, %790, %789, %575, %559, %556, %534, %507, %505, %504, %468, %440, %439, %213, %198, %195, %162, %146, %143, %140, %137, %71, %51, %50
  br label %48
}

declare i32 @scanf(i8*, ...) #1

; Function Attrs: noinline nounwind uwtable
define linkonce_odr void @_ZSt4swapIiEvRT_S1_(i32* dereferenceable(4), i32* dereferenceable(4)) #4 comdat {
  %3 = alloca i32*, align 8
  %4 = alloca i32*, align 8
  %5 = alloca i32, align 4
  store i32* %0, i32** %3, align 8
  store i32* %1, i32** %4, align 8
  %6 = load i32*, i32** %3, align 8
  %7 = call dereferenceable(4) i32* @_ZSt4moveIRiEONSt16remove_referenceIT_E4typeEOS2_(i32* dereferenceable(4) %6) #3
  %8 = load i32, i32* %7, align 4
  store i32 %8, i32* %5, align 4
  %9 = load i32*, i32** %4, align 8
  %10 = call dereferenceable(4) i32* @_ZSt4moveIRiEONSt16remove_referenceIT_E4typeEOS2_(i32* dereferenceable(4) %9) #3
  %11 = load i32, i32* %10, align 4
  %12 = load i32*, i32** %3, align 8
  store i32 %11, i32* %12, align 4
  %13 = call dereferenceable(4) i32* @_ZSt4moveIRiEONSt16remove_referenceIT_E4typeEOS2_(i32* dereferenceable(4) %5) #3
  %14 = load i32, i32* %13, align 4
  %15 = load i32*, i32** %4, align 8
  store i32 %14, i32* %15, align 4
  ret void
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr dereferenceable(8) i64* @_ZSt3minIxERKT_S2_S2_(i64* dereferenceable(8), i64* dereferenceable(8)) #4 comdat {
  %3 = alloca i64*
  %4 = alloca i64
  %5 = alloca i64
  %6 = alloca i64*, align 8
  %7 = alloca i64*, align 8
  %8 = alloca i64*, align 8
  store i64* %0, i64** %7, align 8
  store i64* %1, i64** %8, align 8
  %9 = load i64*, i64** %8, align 8
  %10 = load i64, i64* %9, align 8
  store i64 %10, i64* %5
  %11 = load i64*, i64** %7, align 8
  %12 = load i64, i64* %11, align 8
  store i64 %12, i64* %4
  %13 = alloca i32
  store i32 1136989602, i32* %13
  br label %14

; <label>:14:                                     ; preds = %2, %74
  %15 = load i32, i32* %13
  switch i32 %15, label %16 [
    i32 1136989602, label %17
    i32 -937565992, label %22
    i32 1517389403, label %24
    i32 1304431366, label %26
    i32 1330628767, label %42
    i32 744099208, label %70
    i32 -1761899182, label %72
  ]

; <label>:16:                                     ; preds = %14
  br label %74

; <label>:17:                                     ; preds = %14
  %18 = load volatile i64, i64* %5
  %19 = load volatile i64, i64* %4
  %20 = icmp slt i64 %18, %19
  %21 = select i1 %20, i32 -937565992, i32 1517389403
  store i32 %21, i32* %13
  br label %74

; <label>:22:                                     ; preds = %14
  %23 = load i64*, i64** %8, align 8
  store i64* %23, i64** %6, align 8
  store i32 1304431366, i32* %13
  br label %74

; <label>:24:                                     ; preds = %14
  %25 = load i64*, i64** %7, align 8
  store i64* %25, i64** %6, align 8
  store i32 1304431366, i32* %13
  br label %74

; <label>:26:                                     ; preds = %14
  %27 = load i32, i32* @x.8
  %28 = load i32, i32* @y.9
  %29 = add i32 %27, 439215046
  %30 = sub i32 %29, 1
  %31 = sub i32 %30, 439215046
  %32 = sub i32 %27, 1
  %33 = mul i32 %27, %31
  %34 = urem i32 %33, 2
  %35 = icmp eq i32 %34, 0
  %36 = icmp slt i32 %28, 10
  %37 = and i1 %35, %36
  %38 = xor i1 %35, %36
  %39 = or i1 %37, %38
  %40 = or i1 %35, %36
  %41 = select i1 %39, i32 1330628767, i32 -1761899182
  store i32 %41, i32* %13
  br label %74

; <label>:42:                                     ; preds = %14
  %43 = load i64*, i64** %6, align 8
  store i64* %43, i64** %3
  %44 = load i32, i32* @x.8
  %45 = load i32, i32* @y.9
  %46 = sub i32 0, 1
  %47 = add i32 %44, %46
  %48 = sub i32 %44, 1
  %49 = mul i32 %44, %47
  %50 = urem i32 %49, 2
  %51 = icmp eq i32 %50, 0
  %52 = icmp slt i32 %45, 10
  %53 = xor i1 %51, true
  %54 = xor i1 %52, true
  %55 = xor i1 false, true
  %56 = and i1 %53, false
  %57 = and i1 %51, %55
  %58 = and i1 %54, false
  %59 = and i1 %52, %55
  %60 = or i1 %56, %57
  %61 = or i1 %58, %59
  %62 = xor i1 %60, %61
  %63 = or i1 %53, %54
  %64 = xor i1 %63, true
  %65 = or i1 false, %55
  %66 = and i1 %64, %65
  %67 = or i1 %62, %66
  %68 = or i1 %51, %52
  %69 = select i1 %67, i32 744099208, i32 -1761899182
  store i32 %69, i32* %13
  br label %74

; <label>:70:                                     ; preds = %14
  %71 = load volatile i64*, i64** %3
  ret i64* %71

; <label>:72:                                     ; preds = %14
  %73 = load i64*, i64** %6, align 8
  store i32 1330628767, i32* %13
  br label %74

; <label>:74:                                     ; preds = %72, %42, %26, %24, %22, %17, %16
  br label %14
}

; Function Attrs: noinline uwtable
define linkonce_odr i64 @_ZSt3maxIxET_St16initializer_listIS0_E(i64*, i64) #0 comdat {
  %3 = alloca %"class.std::initializer_list", align 8
  %4 = bitcast %"class.std::initializer_list"* %3 to { i64*, i64 }*
  %5 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %4, i32 0, i32 0
  store i64* %0, i64** %5, align 8
  %6 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %4, i32 0, i32 1
  store i64 %1, i64* %6, align 8
  %7 = call i64* @_ZNKSt16initializer_listIxE5beginEv(%"class.std::initializer_list"* %3) #3
  %8 = call i64* @_ZNKSt16initializer_listIxE3endEv(%"class.std::initializer_list"* %3) #3
  %9 = call i64* @_ZSt11max_elementIPKxET_S2_S2_(i64* %7, i64* %8)
  %10 = load i64, i64* %9, align 8
  ret i64 %10
}

; Function Attrs: noinline uwtable
define linkonce_odr i64 @_ZSt3minIxET_St16initializer_listIS0_E(i64*, i64) #0 comdat {
  %3 = alloca i64
  %4 = alloca i1
  %5 = alloca i1
  %6 = load i32, i32* @x.12
  %7 = load i32, i32* @y.13
  %8 = sub i32 %6, 1661535915
  %9 = sub i32 %8, 1
  %10 = add i32 %9, 1661535915
  %11 = sub i32 %6, 1
  %12 = mul i32 %6, %10
  %13 = urem i32 %12, 2
  %14 = icmp eq i32 %13, 0
  store i1 %14, i1* %5
  %15 = icmp slt i32 %7, 10
  store i1 %15, i1* %4
  %16 = alloca i32
  store i32 588533733, i32* %16
  br label %17

; <label>:17:                                     ; preds = %2, %87
  %18 = load i32, i32* %16
  switch i32 %18, label %19 [
    i32 588533733, label %20
    i32 -493704505, label %40
    i32 -1341484798, label %76
    i32 573876216, label %78
  ]

; <label>:19:                                     ; preds = %17
  br label %87

; <label>:20:                                     ; preds = %17
  %21 = load volatile i1, i1* %5
  %22 = load volatile i1, i1* %4
  %23 = xor i1 %21, true
  %24 = xor i1 %22, true
  %25 = xor i1 true, true
  %26 = and i1 %23, true
  %27 = and i1 %21, %25
  %28 = and i1 %24, true
  %29 = and i1 %22, %25
  %30 = or i1 %26, %27
  %31 = or i1 %28, %29
  %32 = xor i1 %30, %31
  %33 = or i1 %23, %24
  %34 = xor i1 %33, true
  %35 = or i1 true, %25
  %36 = and i1 %34, %35
  %37 = or i1 %32, %36
  %38 = or i1 %21, %22
  %39 = select i1 %37, i32 -493704505, i32 573876216
  store i32 %39, i32* %16
  br label %87

; <label>:40:                                     ; preds = %17
  %41 = alloca %"class.std::initializer_list", align 8
  %42 = bitcast %"class.std::initializer_list"* %41 to { i64*, i64 }*
  %43 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %42, i32 0, i32 0
  store i64* %0, i64** %43, align 8
  %44 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %42, i32 0, i32 1
  store i64 %1, i64* %44, align 8
  %45 = call i64* @_ZNKSt16initializer_listIxE5beginEv(%"class.std::initializer_list"* %41) #3
  %46 = call i64* @_ZNKSt16initializer_listIxE3endEv(%"class.std::initializer_list"* %41) #3
  %47 = call i64* @_ZSt11min_elementIPKxET_S2_S2_(i64* %45, i64* %46)
  %48 = load i64, i64* %47, align 8
  store i64 %48, i64* %3
  %49 = load i32, i32* @x.12
  %50 = load i32, i32* @y.13
  %51 = add i32 %49, -1610616193
  %52 = sub i32 %51, 1
  %53 = sub i32 %52, -1610616193
  %54 = sub i32 %49, 1
  %55 = mul i32 %49, %53
  %56 = urem i32 %55, 2
  %57 = icmp eq i32 %56, 0
  %58 = icmp slt i32 %50, 10
  %59 = xor i1 %57, true
  %60 = xor i1 %58, true
  %61 = xor i1 true, true
  %62 = and i1 %59, true
  %63 = and i1 %57, %61
  %64 = and i1 %60, true
  %65 = and i1 %58, %61
  %66 = or i1 %62, %63
  %67 = or i1 %64, %65
  %68 = xor i1 %66, %67
  %69 = or i1 %59, %60
  %70 = xor i1 %69, true
  %71 = or i1 true, %61
  %72 = and i1 %70, %71
  %73 = or i1 %68, %72
  %74 = or i1 %57, %58
  %75 = select i1 %73, i32 -1341484798, i32 573876216
  store i32 %75, i32* %16
  br label %87

; <label>:76:                                     ; preds = %17
  %77 = load volatile i64, i64* %3
  ret i64 %77

; <label>:78:                                     ; preds = %17
  %79 = alloca %"class.std::initializer_list", align 8
  %80 = bitcast %"class.std::initializer_list"* %79 to { i64*, i64 }*
  %81 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %80, i32 0, i32 0
  store i64* %0, i64** %81, align 8
  %82 = getelementptr inbounds { i64*, i64 }, { i64*, i64 }* %80, i32 0, i32 1
  store i64 %1, i64* %82, align 8
  %83 = call i64* @_ZNKSt16initializer_listIxE5beginEv(%"class.std::initializer_list"* %79) #3
  %84 = call i64* @_ZNKSt16initializer_listIxE3endEv(%"class.std::initializer_list"* %79) #3
  %85 = call i64* @_ZSt11min_elementIPKxET_S2_S2_(i64* %83, i64* %84)
  %86 = load i64, i64* %85, align 8
  store i32 -493704505, i32* %16
  br label %87

; <label>:87:                                     ; preds = %78, %40, %20, %19
  br label %17
}

declare i32 @printf(i8*, ...) #1

; Function Attrs: noinline norecurse uwtable
define i32 @main() #5 {
  %1 = alloca i1
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  store i32 0, i32* %2, align 4
  call void @_Z4initv()
  store i32 1, i32* %3, align 4
  %4 = alloca i32
  store i32 940096987, i32* %4
  br label %5

; <label>:5:                                      ; preds = %0, %86
  %6 = load i32, i32* %4
  switch i32 %6, label %7 [
    i32 940096987, label %8
    i32 -2130504332, label %36
    i32 -1070281742, label %59
    i32 -153373129, label %62
    i32 -1089314917, label %63
    i32 -1908704877, label %64
  ]

; <label>:7:                                      ; preds = %5
  br label %86

; <label>:8:                                      ; preds = %5
  %9 = load i32, i32* @x.14
  %10 = load i32, i32* @y.15
  %11 = add i32 %9, -1244763562
  %12 = sub i32 %11, 1
  %13 = sub i32 %12, -1244763562
  %14 = sub i32 %9, 1
  %15 = mul i32 %9, %13
  %16 = urem i32 %15, 2
  %17 = icmp eq i32 %16, 0
  %18 = icmp slt i32 %10, 10
  %19 = xor i1 %17, true
  %20 = xor i1 %18, true
  %21 = xor i1 true, true
  %22 = and i1 %19, true
  %23 = and i1 %17, %21
  %24 = and i1 %20, true
  %25 = and i1 %18, %21
  %26 = or i1 %22, %23
  %27 = or i1 %24, %25
  %28 = xor i1 %26, %27
  %29 = or i1 %19, %20
  %30 = xor i1 %29, true
  %31 = or i1 true, %21
  %32 = and i1 %30, %31
  %33 = or i1 %28, %32
  %34 = or i1 %17, %18
  %35 = select i1 %33, i32 -2130504332, i32 -1908704877
  store i32 %35, i32* %4
  br label %86

; <label>:36:                                     ; preds = %5
  %37 = load i32, i32* %3, align 4
  %38 = sub i32 0, %37
  %39 = sub i32 0, -1
  %40 = add i32 %38, %39
  %41 = sub i32 0, %40
  %42 = add nsw i32 %37, -1
  store i32 %41, i32* %3, align 4
  %43 = icmp ne i32 %37, 0
  store i1 %43, i1* %1
  %44 = load i32, i32* @x.14
  %45 = load i32, i32* @y.15
  %46 = add i32 %44, 2000879665
  %47 = sub i32 %46, 1
  %48 = sub i32 %47, 2000879665
  %49 = sub i32 %44, 1
  %50 = mul i32 %44, %48
  %51 = urem i32 %50, 2
  %52 = icmp eq i32 %51, 0
  %53 = icmp slt i32 %45, 10
  %54 = and i1 %52, %53
  %55 = xor i1 %52, %53
  %56 = or i1 %54, %55
  %57 = or i1 %52, %53
  %58 = select i1 %56, i32 -1070281742, i32 -1908704877
  store i32 %58, i32* %4
  br label %86

; <label>:59:                                     ; preds = %5
  %60 = load volatile i1, i1* %1
  %61 = select i1 %60, i32 -153373129, i32 -1089314917
  store i32 %61, i32* %4
  br label %86

; <label>:62:                                     ; preds = %5
  call void @_Z5solvev()
  store i32 940096987, i32* %4
  br label %86

; <label>:63:                                     ; preds = %5
  ret i32 0

; <label>:64:                                     ; preds = %5
  %65 = load i32, i32* %3, align 4
  %66 = shl i32 %65, -1
  %67 = shl i32 %65, -1
  %68 = sub i32 0, %65
  %69 = add i32 0, %68
  %70 = sub i32 0, %65
  %71 = sub i32 0, %69
  %72 = sub i32 0, -1
  %73 = add i32 %71, %72
  %74 = sub i32 0, %73
  %75 = add i32 %69, -1
  %76 = shl i32 %65, -1
  %77 = add i32 %65, -2102816476
  %78 = sub i32 %77, -1
  %79 = sub i32 %78, -2102816476
  %80 = sub i32 %65, -1
  %81 = mul i32 %79, -1
  %82 = sub i32 0, -1
  %83 = sub i32 %65, %82
  %84 = add nsw i32 %65, -1
  store i32 %83, i32* %3, align 4
  %85 = icmp ne i32 %65, 0
  store i32 -2130504332, i32* %4
  br label %86

; <label>:86:                                     ; preds = %64, %62, %59, %36, %8, %7
  br label %5
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr dereferenceable(4) i32* @_ZSt4moveIRiEONSt16remove_referenceIT_E4typeEOS2_(i32* dereferenceable(4)) #4 comdat {
  %2 = alloca i32*, align 8
  store i32* %0, i32** %2, align 8
  %3 = load i32*, i32** %2, align 8
  ret i32* %3
}

; Function Attrs: noinline uwtable
define linkonce_odr i64* @_ZSt11max_elementIPKxET_S2_S2_(i64*, i64*) #0 comdat {
  %3 = alloca i64*
  %4 = alloca i1
  %5 = alloca i1
  %6 = load i32, i32* @x.18
  %7 = load i32, i32* @y.19
  %8 = sub i32 %6, -349921458
  %9 = sub i32 %8, 1
  %10 = add i32 %9, -349921458
  %11 = sub i32 %6, 1
  %12 = mul i32 %6, %10
  %13 = urem i32 %12, 2
  %14 = icmp eq i32 %13, 0
  store i1 %14, i1* %5
  %15 = icmp slt i32 %7, 10
  store i1 %15, i1* %4
  %16 = alloca i32
  store i32 -1475921861, i32* %16
  br label %17

; <label>:17:                                     ; preds = %2, %85
  %18 = load i32, i32* %16
  switch i32 %18, label %19 [
    i32 -1475921861, label %20
    i32 -1875512666, label %40
    i32 1019937833, label %75
    i32 863318804, label %77
  ]

; <label>:19:                                     ; preds = %17
  br label %85

; <label>:20:                                     ; preds = %17
  %21 = load volatile i1, i1* %5
  %22 = load volatile i1, i1* %4
  %23 = xor i1 %21, true
  %24 = xor i1 %22, true
  %25 = xor i1 false, true
  %26 = and i1 %23, false
  %27 = and i1 %21, %25
  %28 = and i1 %24, false
  %29 = and i1 %22, %25
  %30 = or i1 %26, %27
  %31 = or i1 %28, %29
  %32 = xor i1 %30, %31
  %33 = or i1 %23, %24
  %34 = xor i1 %33, true
  %35 = or i1 false, %25
  %36 = and i1 %34, %35
  %37 = or i1 %32, %36
  %38 = or i1 %21, %22
  %39 = select i1 %37, i32 -1875512666, i32 863318804
  store i32 %39, i32* %16
  br label %85

; <label>:40:                                     ; preds = %17
  %41 = alloca i64*, align 8
  %42 = alloca i64*, align 8
  %43 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  %44 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  store i64* %0, i64** %41, align 8
  store i64* %1, i64** %42, align 8
  %45 = load i64*, i64** %41, align 8
  %46 = load i64*, i64** %42, align 8
  call void @_ZN9__gnu_cxx5__ops16__iter_less_iterEv()
  %47 = call i64* @_ZSt13__max_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_(i64* %45, i64* %46)
  store i64* %47, i64** %3
  %48 = load i32, i32* @x.18
  %49 = load i32, i32* @y.19
  %50 = sub i32 %48, -2049971878
  %51 = sub i32 %50, 1
  %52 = add i32 %51, -2049971878
  %53 = sub i32 %48, 1
  %54 = mul i32 %48, %52
  %55 = urem i32 %54, 2
  %56 = icmp eq i32 %55, 0
  %57 = icmp slt i32 %49, 10
  %58 = xor i1 %56, true
  %59 = xor i1 %57, true
  %60 = xor i1 true, true
  %61 = and i1 %58, true
  %62 = and i1 %56, %60
  %63 = and i1 %59, true
  %64 = and i1 %57, %60
  %65 = or i1 %61, %62
  %66 = or i1 %63, %64
  %67 = xor i1 %65, %66
  %68 = or i1 %58, %59
  %69 = xor i1 %68, true
  %70 = or i1 true, %60
  %71 = and i1 %69, %70
  %72 = or i1 %67, %71
  %73 = or i1 %56, %57
  %74 = select i1 %72, i32 1019937833, i32 863318804
  store i32 %74, i32* %16
  br label %85

; <label>:75:                                     ; preds = %17
  %76 = load volatile i64*, i64** %3
  ret i64* %76

; <label>:77:                                     ; preds = %17
  %78 = alloca i64*, align 8
  %79 = alloca i64*, align 8
  %80 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  %81 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  store i64* %0, i64** %78, align 8
  store i64* %1, i64** %79, align 8
  %82 = load i64*, i64** %78, align 8
  %83 = load i64*, i64** %79, align 8
  call void @_ZN9__gnu_cxx5__ops16__iter_less_iterEv()
  %84 = call i64* @_ZSt13__max_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_(i64* %82, i64* %83)
  store i32 -1875512666, i32* %16
  br label %85

; <label>:85:                                     ; preds = %77, %40, %20, %19
  br label %17
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr i64* @_ZNKSt16initializer_listIxE5beginEv(%"class.std::initializer_list"*) #4 comdat align 2 {
  %2 = alloca %"class.std::initializer_list"*, align 8
  store %"class.std::initializer_list"* %0, %"class.std::initializer_list"** %2, align 8
  %3 = load %"class.std::initializer_list"*, %"class.std::initializer_list"** %2, align 8
  %4 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %3, i32 0, i32 0
  %5 = load i64*, i64** %4, align 8
  ret i64* %5
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr i64* @_ZNKSt16initializer_listIxE3endEv(%"class.std::initializer_list"*) #4 comdat align 2 {
  %2 = alloca %"class.std::initializer_list"*, align 8
  store %"class.std::initializer_list"* %0, %"class.std::initializer_list"** %2, align 8
  %3 = load %"class.std::initializer_list"*, %"class.std::initializer_list"** %2, align 8
  %4 = call i64* @_ZNKSt16initializer_listIxE5beginEv(%"class.std::initializer_list"* %3) #3
  %5 = call i64 @_ZNKSt16initializer_listIxE4sizeEv(%"class.std::initializer_list"* %3) #3
  %6 = getelementptr inbounds i64, i64* %4, i64 %5
  ret i64* %6
}

; Function Attrs: noinline uwtable
define linkonce_odr i64* @_ZSt13__max_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_(i64*, i64*) #0 comdat {
  %3 = alloca i1
  %4 = alloca i1
  %5 = alloca i64**
  %6 = alloca i64**
  %7 = alloca i64**
  %8 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter"*
  %9 = alloca i64**
  %10 = alloca i1
  %11 = alloca i1
  %12 = load i32, i32* @x.24
  %13 = load i32, i32* @y.25
  %14 = sub i32 %12, -1404730882
  %15 = sub i32 %14, 1
  %16 = add i32 %15, -1404730882
  %17 = sub i32 %12, 1
  %18 = mul i32 %12, %16
  %19 = urem i32 %18, 2
  %20 = icmp eq i32 %19, 0
  store i1 %20, i1* %11
  %21 = icmp slt i32 %13, 10
  store i1 %21, i1* %10
  %22 = alloca i32
  store i32 -1176169990, i32* %22
  br label %23

; <label>:23:                                     ; preds = %2, %211
  %24 = load i32, i32* %22
  switch i32 %24, label %25 [
    i32 -1176169990, label %26
    i32 -1778709403, label %34
    i32 -128500280, label %73
    i32 -563267398, label %76
    i32 1640716141, label %92
    i32 -730439413, label %111
    i32 1094554359, label %112
    i32 909094885, label %116
    i32 1936373887, label %132
    i32 1688852272, label %167
    i32 1996955189, label %170
    i32 -1379313190, label %178
    i32 724482578, label %182
    i32 1979657608, label %183
    i32 1232711693, label %187
    i32 1471777866, label %190
    i32 167545040, label %199
    i32 -893960284, label %203
  ]

; <label>:25:                                     ; preds = %23
  br label %211

; <label>:26:                                     ; preds = %23
  %27 = load volatile i1, i1* %11
  %28 = load volatile i1, i1* %10
  %29 = and i1 %27, %28
  %30 = xor i1 %27, %28
  %31 = or i1 %29, %30
  %32 = or i1 %27, %28
  %33 = select i1 %31, i32 -1778709403, i32 1471777866
  store i32 %33, i32* %22
  br label %211

; <label>:34:                                     ; preds = %23
  %35 = alloca i64*, align 8
  store i64** %35, i64*** %9
  %36 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  store %"struct.__gnu_cxx::__ops::_Iter_less_iter"* %36, %"struct.__gnu_cxx::__ops::_Iter_less_iter"** %8
  %37 = alloca i64*, align 8
  store i64** %37, i64*** %7
  %38 = alloca i64*, align 8
  store i64** %38, i64*** %6
  %39 = alloca i64*, align 8
  store i64** %39, i64*** %5
  %40 = load volatile i64**, i64*** %7
  store i64* %0, i64** %40, align 8
  %41 = load volatile i64**, i64*** %6
  store i64* %1, i64** %41, align 8
  %42 = load volatile i64**, i64*** %7
  %43 = load i64*, i64** %42, align 8
  %44 = load volatile i64**, i64*** %6
  %45 = load i64*, i64** %44, align 8
  %46 = icmp eq i64* %43, %45
  store i1 %46, i1* %4
  %47 = load i32, i32* @x.24
  %48 = load i32, i32* @y.25
  %49 = sub i32 0, 1
  %50 = add i32 %47, %49
  %51 = sub i32 %47, 1
  %52 = mul i32 %47, %50
  %53 = urem i32 %52, 2
  %54 = icmp eq i32 %53, 0
  %55 = icmp slt i32 %48, 10
  %56 = xor i1 %54, true
  %57 = xor i1 %55, true
  %58 = xor i1 false, true
  %59 = and i1 %56, false
  %60 = and i1 %54, %58
  %61 = and i1 %57, false
  %62 = and i1 %55, %58
  %63 = or i1 %59, %60
  %64 = or i1 %61, %62
  %65 = xor i1 %63, %64
  %66 = or i1 %56, %57
  %67 = xor i1 %66, true
  %68 = or i1 false, %58
  %69 = and i1 %67, %68
  %70 = or i1 %65, %69
  %71 = or i1 %54, %55
  %72 = select i1 %70, i32 -128500280, i32 1471777866
  store i32 %72, i32* %22
  br label %211

; <label>:73:                                     ; preds = %23
  %74 = load volatile i1, i1* %4
  %75 = select i1 %74, i32 -563267398, i32 1094554359
  store i32 %75, i32* %22
  br label %211

; <label>:76:                                     ; preds = %23
  %77 = load i32, i32* @x.24
  %78 = load i32, i32* @y.25
  %79 = add i32 %77, 1698677778
  %80 = sub i32 %79, 1
  %81 = sub i32 %80, 1698677778
  %82 = sub i32 %77, 1
  %83 = mul i32 %77, %81
  %84 = urem i32 %83, 2
  %85 = icmp eq i32 %84, 0
  %86 = icmp slt i32 %78, 10
  %87 = and i1 %85, %86
  %88 = xor i1 %85, %86
  %89 = or i1 %87, %88
  %90 = or i1 %85, %86
  %91 = select i1 %89, i32 1640716141, i32 167545040
  store i32 %91, i32* %22
  br label %211

; <label>:92:                                     ; preds = %23
  %93 = load volatile i64**, i64*** %7
  %94 = load i64*, i64** %93, align 8
  %95 = load volatile i64**, i64*** %9
  store i64* %94, i64** %95, align 8
  %96 = load i32, i32* @x.24
  %97 = load i32, i32* @y.25
  %98 = sub i32 %96, 83476403
  %99 = sub i32 %98, 1
  %100 = add i32 %99, 83476403
  %101 = sub i32 %96, 1
  %102 = mul i32 %96, %100
  %103 = urem i32 %102, 2
  %104 = icmp eq i32 %103, 0
  %105 = icmp slt i32 %97, 10
  %106 = and i1 %104, %105
  %107 = xor i1 %104, %105
  %108 = or i1 %106, %107
  %109 = or i1 %104, %105
  %110 = select i1 %108, i32 -730439413, i32 167545040
  store i32 %110, i32* %22
  br label %211

; <label>:111:                                    ; preds = %23
  store i32 1232711693, i32* %22
  br label %211

; <label>:112:                                    ; preds = %23
  %113 = load volatile i64**, i64*** %7
  %114 = load i64*, i64** %113, align 8
  %115 = load volatile i64**, i64*** %5
  store i64* %114, i64** %115, align 8
  store i32 909094885, i32* %22
  br label %211

; <label>:116:                                    ; preds = %23
  %117 = load i32, i32* @x.24
  %118 = load i32, i32* @y.25
  %119 = sub i32 %117, 2137752697
  %120 = sub i32 %119, 1
  %121 = add i32 %120, 2137752697
  %122 = sub i32 %117, 1
  %123 = mul i32 %117, %121
  %124 = urem i32 %123, 2
  %125 = icmp eq i32 %124, 0
  %126 = icmp slt i32 %118, 10
  %127 = and i1 %125, %126
  %128 = xor i1 %125, %126
  %129 = or i1 %127, %128
  %130 = or i1 %125, %126
  %131 = select i1 %129, i32 1936373887, i32 -893960284
  store i32 %131, i32* %22
  br label %211

; <label>:132:                                    ; preds = %23
  %133 = load volatile i64**, i64*** %7
  %134 = load i64*, i64** %133, align 8
  %135 = getelementptr inbounds i64, i64* %134, i32 1
  %136 = load volatile i64**, i64*** %7
  store i64* %135, i64** %136, align 8
  %137 = load volatile i64**, i64*** %6
  %138 = load i64*, i64** %137, align 8
  %139 = icmp ne i64* %135, %138
  store i1 %139, i1* %3
  %140 = load i32, i32* @x.24
  %141 = load i32, i32* @y.25
  %142 = sub i32 %140, 255577751
  %143 = sub i32 %142, 1
  %144 = add i32 %143, 255577751
  %145 = sub i32 %140, 1
  %146 = mul i32 %140, %144
  %147 = urem i32 %146, 2
  %148 = icmp eq i32 %147, 0
  %149 = icmp slt i32 %141, 10
  %150 = xor i1 %148, true
  %151 = xor i1 %149, true
  %152 = xor i1 false, true
  %153 = and i1 %150, false
  %154 = and i1 %148, %152
  %155 = and i1 %151, false
  %156 = and i1 %149, %152
  %157 = or i1 %153, %154
  %158 = or i1 %155, %156
  %159 = xor i1 %157, %158
  %160 = or i1 %150, %151
  %161 = xor i1 %160, true
  %162 = or i1 false, %152
  %163 = and i1 %161, %162
  %164 = or i1 %159, %163
  %165 = or i1 %148, %149
  %166 = select i1 %164, i32 1688852272, i32 -893960284
  store i32 %166, i32* %22
  br label %211

; <label>:167:                                    ; preds = %23
  %168 = load volatile i1, i1* %3
  %169 = select i1 %168, i32 1996955189, i32 1979657608
  store i32 %169, i32* %22
  br label %211

; <label>:170:                                    ; preds = %23
  %171 = load volatile i64**, i64*** %5
  %172 = load i64*, i64** %171, align 8
  %173 = load volatile i64**, i64*** %7
  %174 = load i64*, i64** %173, align 8
  %175 = load volatile %"struct.__gnu_cxx::__ops::_Iter_less_iter"*, %"struct.__gnu_cxx::__ops::_Iter_less_iter"** %8
  %176 = call zeroext i1 @_ZNK9__gnu_cxx5__ops15_Iter_less_iterclIPKxS4_EEbT_T0_(%"struct.__gnu_cxx::__ops::_Iter_less_iter"* %175, i64* %172, i64* %174)
  %177 = select i1 %176, i32 -1379313190, i32 724482578
  store i32 %177, i32* %22
  br label %211

; <label>:178:                                    ; preds = %23
  %179 = load volatile i64**, i64*** %7
  %180 = load i64*, i64** %179, align 8
  %181 = load volatile i64**, i64*** %5
  store i64* %180, i64** %181, align 8
  store i32 724482578, i32* %22
  br label %211

; <label>:182:                                    ; preds = %23
  store i32 909094885, i32* %22
  br label %211

; <label>:183:                                    ; preds = %23
  %184 = load volatile i64**, i64*** %5
  %185 = load i64*, i64** %184, align 8
  %186 = load volatile i64**, i64*** %9
  store i64* %185, i64** %186, align 8
  store i32 1232711693, i32* %22
  br label %211

; <label>:187:                                    ; preds = %23
  %188 = load volatile i64**, i64*** %9
  %189 = load i64*, i64** %188, align 8
  ret i64* %189

; <label>:190:                                    ; preds = %23
  %191 = alloca i64*, align 8
  %192 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  %193 = alloca i64*, align 8
  %194 = alloca i64*, align 8
  %195 = alloca i64*, align 8
  store i64* %0, i64** %193, align 8
  store i64* %1, i64** %194, align 8
  %196 = load i64*, i64** %193, align 8
  %197 = load i64*, i64** %194, align 8
  %198 = icmp eq i64* %196, %197
  store i32 -1778709403, i32* %22
  br label %211

; <label>:199:                                    ; preds = %23
  %200 = load volatile i64**, i64*** %7
  %201 = load i64*, i64** %200, align 8
  %202 = load volatile i64**, i64*** %9
  store i64* %201, i64** %202, align 8
  store i32 1640716141, i32* %22
  br label %211

; <label>:203:                                    ; preds = %23
  %204 = load volatile i64**, i64*** %7
  %205 = load i64*, i64** %204, align 8
  %206 = getelementptr inbounds i64, i64* %205, i32 1
  %207 = load volatile i64**, i64*** %7
  store i64* %206, i64** %207, align 8
  %208 = load volatile i64**, i64*** %6
  %209 = load i64*, i64** %208, align 8
  %210 = icmp ne i64* %206, %209
  store i32 1936373887, i32* %22
  br label %211

; <label>:211:                                    ; preds = %203, %199, %190, %183, %182, %178, %170, %167, %132, %116, %112, %111, %92, %76, %73, %34, %26, %25
  br label %23
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr void @_ZN9__gnu_cxx5__ops16__iter_less_iterEv() #4 comdat {
  %1 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  ret void
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr zeroext i1 @_ZNK9__gnu_cxx5__ops15_Iter_less_iterclIPKxS4_EEbT_T0_(%"struct.__gnu_cxx::__ops::_Iter_less_iter"*, i64*, i64*) #4 comdat align 2 {
  %4 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter"*, align 8
  %5 = alloca i64*, align 8
  %6 = alloca i64*, align 8
  store %"struct.__gnu_cxx::__ops::_Iter_less_iter"* %0, %"struct.__gnu_cxx::__ops::_Iter_less_iter"** %4, align 8
  store i64* %1, i64** %5, align 8
  store i64* %2, i64** %6, align 8
  %7 = load %"struct.__gnu_cxx::__ops::_Iter_less_iter"*, %"struct.__gnu_cxx::__ops::_Iter_less_iter"** %4, align 8
  %8 = load i64*, i64** %5, align 8
  %9 = load i64, i64* %8, align 8
  %10 = load i64*, i64** %6, align 8
  %11 = load i64, i64* %10, align 8
  %12 = icmp slt i64 %9, %11
  ret i1 %12
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr i64 @_ZNKSt16initializer_listIxE4sizeEv(%"class.std::initializer_list"*) #4 comdat align 2 {
  %2 = alloca %"class.std::initializer_list"*, align 8
  store %"class.std::initializer_list"* %0, %"class.std::initializer_list"** %2, align 8
  %3 = load %"class.std::initializer_list"*, %"class.std::initializer_list"** %2, align 8
  %4 = getelementptr inbounds %"class.std::initializer_list", %"class.std::initializer_list"* %3, i32 0, i32 1
  %5 = load i64, i64* %4, align 8
  ret i64 %5
}

; Function Attrs: noinline uwtable
define linkonce_odr i64* @_ZSt11min_elementIPKxET_S2_S2_(i64*, i64*) #0 comdat {
  %3 = alloca i64*, align 8
  %4 = alloca i64*, align 8
  %5 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  %6 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  store i64* %0, i64** %3, align 8
  store i64* %1, i64** %4, align 8
  %7 = load i64*, i64** %3, align 8
  %8 = load i64*, i64** %4, align 8
  call void @_ZN9__gnu_cxx5__ops16__iter_less_iterEv()
  %9 = call i64* @_ZSt13__min_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_(i64* %7, i64* %8)
  ret i64* %9
}

; Function Attrs: noinline nounwind uwtable
define linkonce_odr i64* @_ZSt13__min_elementIPKxN9__gnu_cxx5__ops15_Iter_less_iterEET_S5_S5_T0_(i64*, i64*) #4 comdat {
  %3 = alloca i1
  %4 = alloca i64*
  %5 = alloca i64*
  %6 = alloca i64*, align 8
  %7 = alloca %"struct.__gnu_cxx::__ops::_Iter_less_iter", align 1
  %8 = alloca i64*, align 8
  %9 = alloca i64*, align 8
  %10 = alloca i64*, align 8
  store i64* %0, i64** %8, align 8
  store i64* %1, i64** %9, align 8
  %11 = load i64*, i64** %8, align 8
  store i64* %11, i64** %5
  %12 = load i64*, i64** %9, align 8
  store i64* %12, i64** %4
  %13 = alloca i32
  store i32 -763029889, i32* %13
  br label %14

; <label>:14:                                     ; preds = %2, %126
  %15 = load i32, i32* %13
  switch i32 %15, label %16 [
    i32 -763029889, label %17
    i32 202257275, label %22
    i32 1465235355, label %24
    i32 -1335279805, label %26
    i32 -1548302258, label %32
    i32 -65038665, label %47
    i32 861139804, label %66
    i32 -1905666834, label %69
    i32 1765133264, label %85
    i32 303082041, label %114
    i32 568157535, label %115
    i32 -1557477556, label %116
    i32 198288122, label %118
    i32 -1019670317, label %120
    i32 -417990192, label %124
  ]

; <label>:16:                                     ; preds = %14
  br label %126

; <label>:17:                                     ; preds = %14
  %18 = load volatile i64*, i64** %5
  %19 = load volatile i64*, i64** %4
  %20 = icmp eq i64* %18, %19
  %21 = select i1 %20, i32 202257275, i32 1465235355
  store i32 %21, i32* %13
  br label %126

; <label>:22:                                     ; preds = %14
  %23 = load i64*, i64** %8, align 8
  store i64* %23, i64** %6, align 8
  store i32 198288122, i32* %13
  br label %126

; <label>:24:                                     ; preds = %14
  %25 = load i64*, i64** %8, align 8
  store i64* %25, i64** %10, align 8
  store i32 -1335279805, i32* %13
  br label %126

; <label>:26:                                     ; preds = %14
  %27 = load i64*, i64** %8, align 8
  %28 = getelementptr inbounds i64, i64* %27, i32 1
  store i64* %28, i64** %8, align 8
  %29 = load i64*, i64** %9, align 8
  %30 = icmp ne i64* %28, %29
  %31 = select i1 %30, i32 -1548302258, i32 -1557477556
  store i32 %31, i32* %13
  br label %126

; <label>:32:                                     ; preds = %14
  %33 = load i32, i32* @x.34
  %34 = load i32, i32* @y.35
  %35 = sub i32 0, 1
  %36 = add i32 %33, %35
  %37 = sub i32 %33, 1
  %38 = mul i32 %33, %36
  %39 = urem i32 %38, 2
  %40 = icmp eq i32 %39, 0
  %41 = icmp slt i32 %34, 10
  %42 = and i1 %40, %41
  %43 = xor i1 %40, %41
  %44 = or i1 %42, %43
  %45 = or i1 %40, %41
  %46 = select i1 %44, i32 -65038665, i32 -1019670317
  store i32 %46, i32* %13
  br label %126

; <label>:47:                                     ; preds = %14
  %48 = load i64*, i64** %8, align 8
  %49 = load i64*, i64** %10, align 8
  %50 = call zeroext i1 @_ZNK9__gnu_cxx5__ops15_Iter_less_iterclIPKxS4_EEbT_T0_(%"struct.__gnu_cxx::__ops::_Iter_less_iter"* %7, i64* %48, i64* %49)
  store i1 %50, i1* %3
  %51 = load i32, i32* @x.34
  %52 = load i32, i32* @y.35
  %53 = add i32 %51, 1637852670
  %54 = sub i32 %53, 1
  %55 = sub i32 %54, 1637852670
  %56 = sub i32 %51, 1
  %57 = mul i32 %51, %55
  %58 = urem i32 %57, 2
  %59 = icmp eq i32 %58, 0
  %60 = icmp slt i32 %52, 10
  %61 = and i1 %59, %60
  %62 = xor i1 %59, %60
  %63 = or i1 %61, %62
  %64 = or i1 %59, %60
  %65 = select i1 %63, i32 861139804, i32 -1019670317
  store i32 %65, i32* %13
  br label %126

; <label>:66:                                     ; preds = %14
  %67 = load volatile i1, i1* %3
  %68 = select i1 %67, i32 -1905666834, i32 568157535
  store i32 %68, i32* %13
  br label %126

; <label>:69:                                     ; preds = %14
  %70 = load i32, i32* @x.34
  %71 = load i32, i32* @y.35
  %72 = sub i32 %70, -1551541272
  %73 = sub i32 %72, 1
  %74 = add i32 %73, -1551541272
  %75 = sub i32 %70, 1
  %76 = mul i32 %70, %74
  %77 = urem i32 %76, 2
  %78 = icmp eq i32 %77, 0
  %79 = icmp slt i32 %71, 10
  %80 = and i1 %78, %79
  %81 = xor i1 %78, %79
  %82 = or i1 %80, %81
  %83 = or i1 %78, %79
  %84 = select i1 %82, i32 1765133264, i32 -417990192
  store i32 %84, i32* %13
  br label %126

; <label>:85:                                     ; preds = %14
  %86 = load i64*, i64** %8, align 8
  store i64* %86, i64** %10, align 8
  %87 = load i32, i32* @x.34
  %88 = load i32, i32* @y.35
  %89 = sub i32 %87, 1786091944
  %90 = sub i32 %89, 1
  %91 = add i32 %90, 1786091944
  %92 = sub i32 %87, 1
  %93 = mul i32 %87, %91
  %94 = urem i32 %93, 2
  %95 = icmp eq i32 %94, 0
  %96 = icmp slt i32 %88, 10
  %97 = xor i1 %95, true
  %98 = xor i1 %96, true
  %99 = xor i1 true, true
  %100 = and i1 %97, true
  %101 = and i1 %95, %99
  %102 = and i1 %98, true
  %103 = and i1 %96, %99
  %104 = or i1 %100, %101
  %105 = or i1 %102, %103
  %106 = xor i1 %104, %105
  %107 = or i1 %97, %98
  %108 = xor i1 %107, true
  %109 = or i1 true, %99
  %110 = and i1 %108, %109
  %111 = or i1 %106, %110
  %112 = or i1 %95, %96
  %113 = select i1 %111, i32 303082041, i32 -417990192
  store i32 %113, i32* %13
  br label %126

; <label>:114:                                    ; preds = %14
  store i32 568157535, i32* %13
  br label %126

; <label>:115:                                    ; preds = %14
  store i32 -1335279805, i32* %13
  br label %126

; <label>:116:                                    ; preds = %14
  %117 = load i64*, i64** %10, align 8
  store i64* %117, i64** %6, align 8
  store i32 198288122, i32* %13
  br label %126

; <label>:118:                                    ; preds = %14
  %119 = load i64*, i64** %6, align 8
  ret i64* %119

; <label>:120:                                    ; preds = %14
  %121 = load i64*, i64** %8, align 8
  %122 = load i64*, i64** %10, align 8
  %123 = call zeroext i1 @_ZNK9__gnu_cxx5__ops15_Iter_less_iterclIPKxS4_EEbT_T0_(%"struct.__gnu_cxx::__ops::_Iter_less_iter"* %7, i64* %121, i64* %122)
  store i32 -65038665, i32* %13
  br label %126

; <label>:124:                                    ; preds = %14
  %125 = load i64*, i64** %8, align 8
  store i64* %125, i64** %10, align 8
  store i32 1765133264, i32* %13
  br label %126

; <label>:126:                                    ; preds = %124, %120, %116, %115, %114, %85, %69, %66, %47, %32, %26, %24, %22, %17, %16
  br label %14
}

; Function Attrs: noinline uwtable
define internal void @_GLOBAL__sub_I_s664876839.cpp() #0 section ".text.startup" {
  call void @__cxx_global_var_init()
  ret void
}

attributes #0 = { noinline uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind }
attributes #4 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noinline norecurse uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.ident = !{!0}

!0 = !{!"Obfuscator-LLVM clang version 4.0.1  (based on Obfuscator-LLVM 4.0.1)"}
